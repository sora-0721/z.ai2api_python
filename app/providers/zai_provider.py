#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Z.AI æä¾›å•†é€‚é…å™¨
"""

import json
import time
import uuid
import httpx
import hmac
import hashlib
import base64
import asyncio
from urllib.parse import urlencode
import os
import uuid
import random
from datetime import datetime
from typing import Dict, List, Any, Optional, AsyncGenerator, Union
from app.utils.user_agent import get_random_user_agent
from app.providers.base import BaseProvider, ProviderConfig
from app.models.schemas import OpenAIRequest, Message
from app.core.config import settings
from app.utils.logger import get_logger
from app.utils.token_pool import get_token_pool
from app.utils.tool_call_handler import (
    process_messages_with_tools,
    parse_and_extract_tool_calls,
)

logger = get_logger()

def generate_uuid() -> str:
    """ç”ŸæˆUUID v4"""
    return str(uuid.uuid4())

def get_zai_dynamic_headers(chat_id: str = "") -> Dict[str, str]:
    """ç”Ÿæˆ Z.AI ç‰¹å®šçš„åŠ¨æ€æµè§ˆå™¨ headers"""
    browser_choices = ["chrome", "chrome", "chrome", "edge", "edge", "firefox", "safari"]
    browser_type = random.choice(browser_choices)
    user_agent = get_random_user_agent(browser_type)

    chrome_version = "139"
    edge_version = "139"

    if "Chrome/" in user_agent:
        try:
            chrome_version = user_agent.split("Chrome/")[1].split(".")[0]
        except:
            pass

    if "Edg/" in user_agent:
        try:
            edge_version = user_agent.split("Edg/")[1].split(".")[0]
            sec_ch_ua = f'"Microsoft Edge";v="{edge_version}", "Chromium";v="{chrome_version}", "Not_A Brand";v="24"'
        except:
            sec_ch_ua = f'"Not_A Brand";v="8", "Chromium";v="{chrome_version}", "Google Chrome";v="{chrome_version}"'
    elif "Firefox/" in user_agent:
        sec_ch_ua = None
    else:
        sec_ch_ua = f'"Not_A Brand";v="8", "Chromium";v="{chrome_version}", "Google Chrome";v="{chrome_version}"'

    headers = {
        "Content-Type": "application/json",
        "Accept": "application/json, text/event-stream",
        "Connection": "keep-alive",
        "Cache-Control": "no-cache",
        "User-Agent": user_agent,
        "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
        "X-FE-Version": "prod-fe-1.0.98",
        "Origin": "https://chat.z.ai",
    }

    if sec_ch_ua:
        headers["sec-ch-ua"] = sec_ch_ua
        headers["sec-ch-ua-mobile"] = "?0"
        headers["sec-ch-ua-platform"] = '"Windows"'

    if chat_id:
        headers["Referer"] = f"https://chat.z.ai/c/{chat_id}"
    else:
        headers["Referer"] = "https://chat.z.ai/"

    return headers

def _urlsafe_b64decode(data: str) -> bytes:
    """Decode a URL-safe base64 string with proper padding."""
    if isinstance(data, str):
        data_bytes = data.encode("utf-8")
    else:
        data_bytes = data
    padding = b"=" * (-len(data_bytes) % 4)
    return base64.urlsafe_b64decode(data_bytes + padding)


def _decode_jwt_payload(token: str) -> Dict[str, Any]:
    """Decode JWT payload without verification to extract metadata."""
    try:
        parts = token.split(".")
        if len(parts) < 2:
            return {}
        payload_raw = _urlsafe_b64decode(parts[1])
        return json.loads(payload_raw.decode("utf-8", errors="ignore"))
    except Exception:
        return {}


def _extract_user_id_from_token(token: str) -> str:
    """Extract user_id from a JWT's payload. Fallback to 'guest'."""
    payload = _decode_jwt_payload(token) if token else {}
    for key in ("id", "user_id", "uid", "sub"):
        val = payload.get(key)
        if isinstance(val, (str, int)) and str(val):
            return str(val)
    return "guest"


def generate_signature(message_text: str, request_id: str, timestamp_ms: int, user_id: str, secret: str = "junjie") -> str:
    """Dual-layer HMAC-SHA256 signature.

    Layer1: derived key = HMAC(secret, window_index)
    Layer2: signature = HMAC(derived_key, canonical_string)
    canonical_string = "requestId,<id>,timestamp,<ts>,user_id,<uid>|<msg>|<ts>"
    """
    r = str(timestamp_ms)
    e = f"requestId,{request_id},timestamp,{timestamp_ms},user_id,{user_id}"
    t = message_text or ""
    # Add content_base64 processing for new signature algorithm
    content_base64 = base64.b64encode(t.encode('utf-8')).decode('ascii')
    i = f"{e}|{content_base64}|{r}"

    window_index = timestamp_ms // (5 * 60 * 1000)
    root_key = (secret or "junjie").encode("utf-8")
    derived_hex = hmac.new(root_key, str(window_index).encode("utf-8"), hashlib.sha256).hexdigest()
    signature = hmac.new(derived_hex.encode("utf-8"), i.encode("utf-8"), hashlib.sha256).hexdigest()
    return signature


class ZAIProvider(BaseProvider):
    """Z.AI æä¾›å•†"""
    
    def __init__(self):
        config = ProviderConfig(
            name="zai",
            api_endpoint=settings.API_ENDPOINT,
            timeout=30,
            headers=get_zai_dynamic_headers()
        )
        super().__init__(config)
        
        # Z.AI ç‰¹å®šé…ç½®
        self.base_url = "https://chat.z.ai"
        self.auth_url = f"{self.base_url}/api/v1/auths/"
        
        # æ¨¡å‹æ˜ å°„
        self.model_mapping = {
            settings.GLM45_MODEL: "0727-360B-API",  # GLM-4.5
            settings.GLM45_THINKING_MODEL: "0727-360B-API",  # GLM-4.5-Thinking
            settings.GLM45_SEARCH_MODEL: "0727-360B-API",  # GLM-4.5-Search
            settings.GLM45_AIR_MODEL: "0727-106B-API",  # GLM-4.5-Air
            settings.GLM45V_MODEL: "glm-4.5v",  # GLM-4.5Vå¤šæ¨¡æ€
            settings.GLM46_MODEL: "GLM-4-6-API-V1",  # GLM-4.6
            settings.GLM46_THINKING_MODEL: "GLM-4-6-API-V1",  # GLM-4.6-Thinking
            settings.GLM46_SEARCH_MODEL: "GLM-4-6-API-V1",  # GLM-4.6-Search
            settings.GLM46_ADVANCED_SEARCH_MODEL: "GLM-4-6-API-V1",  # GLM-4.6-advanced-search
        }
    
    def get_supported_models(self) -> List[str]:
        """è·å–æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨"""
        return [
            settings.GLM45_MODEL,
            settings.GLM45_THINKING_MODEL,
            settings.GLM45_SEARCH_MODEL,
            settings.GLM45_AIR_MODEL,
            settings.GLM45V_MODEL,
            settings.GLM46_MODEL,
            settings.GLM46_THINKING_MODEL,
            settings.GLM46_SEARCH_MODEL,
            settings.GLM46_ADVANCED_SEARCH_MODEL,
        ]

    def _get_proxy_config(self) -> Optional[Dict[str, str]]:
        """Get proxy configuration from settings"""
        proxies = {}

        # Support HTTP_PROXY, HTTPS_PROXY and SOCKS5_PROXY
        if settings.HTTP_PROXY:
            proxies["http://"] = settings.HTTP_PROXY
            self.logger.info(f"ğŸ”„ ä½¿ç”¨HTTPä»£ç†: {settings.HTTP_PROXY}")

        if settings.HTTPS_PROXY:
            proxies["https://"] = settings.HTTPS_PROXY
            self.logger.info(f"ğŸ”„ ä½¿ç”¨HTTPSä»£ç†: {settings.HTTPS_PROXY}")

        if settings.SOCKS5_PROXY:
            # SOCKS5 proxy for both HTTP and HTTPS
            proxies["http://"] = settings.SOCKS5_PROXY
            proxies["https://"] = settings.SOCKS5_PROXY
            self.logger.info(f"ğŸ”„ ä½¿ç”¨SOCKS5ä»£ç†: {settings.SOCKS5_PROXY}")

        return proxies if proxies else None

    async def get_token(self) -> str:
        """è·å–è®¤è¯ä»¤ç‰Œ"""
        # å¦‚æœå¯ç”¨åŒ¿åæ¨¡å¼ï¼Œåªå°è¯•è·å–è®¿å®¢ä»¤ç‰Œ
        if settings.ANONYMOUS_MODE:
            max_retries = 3
            retry_count = 0
            
            while retry_count < max_retries:
                try:
                    headers = get_zai_dynamic_headers()
                    self.logger.debug(f"å°è¯•è·å–è®¿å®¢ä»¤ç‰Œ (ç¬¬{retry_count + 1}æ¬¡): {self.auth_url}")
                    self.logger.debug(f"è¯·æ±‚å¤´: {headers}")

                    # Get proxy configuration
                    proxies = self._get_proxy_config()

                    async with httpx.AsyncClient(timeout=30.0, follow_redirects=True, proxies=proxies) as client:
                        response = await client.get(self.auth_url, headers=headers)
                        
                        self.logger.debug(f"å“åº”çŠ¶æ€ç : {response.status_code}")
                        self.logger.debug(f"å“åº”å¤´: {dict(response.headers)}")
                        
                        if response.status_code == 200:
                            data = response.json()
                            self.logger.debug(f"å“åº”æ•°æ®: {data}")
                            
                            token = data.get("token", "")
                            if token:
                                # åˆ¤æ–­ä»¤ç‰Œç±»å‹ï¼ˆé€šè¿‡æ£€æŸ¥é‚®ç®±æˆ–user_idï¼‰
                                email = data.get("email", "")
                                is_guest = "@guest.com" in email or "Guest-" in email
                                token_type = "åŒ¿åç”¨æˆ·" if is_guest else "è®¤è¯ç”¨æˆ·"
                                self.logger.info(f"âœ… è·å–ä»¤ç‰ŒæˆåŠŸ ({token_type}): {token[:20]}...")
                                return token
                            else:
                                self.logger.warning(f"å“åº”ä¸­æœªæ‰¾åˆ°tokenå­—æ®µ: {data}")
                        elif response.status_code == 405:
                            # WAFæ‹¦æˆª
                            self.logger.error(f"ğŸš« è¯·æ±‚è¢«WAFæ‹¦æˆª (çŠ¶æ€ç 405),è¯·æ±‚å¤´å¯èƒ½è¢«è¯†åˆ«ä¸ºå¼‚å¸¸,è¯·ç¨åé‡è¯•...")
                            break
                        else:
                            self.logger.warning(f"HTTPè¯·æ±‚å¤±è´¥,çŠ¶æ€ç : {response.status_code}")
                            try:
                                error_data = response.json()
                                self.logger.warning(f"é”™è¯¯å“åº”: {error_data}")
                            except:
                                self.logger.warning(f"é”™è¯¯å“åº”æ–‡æœ¬: {response.text}")
                                
                except httpx.TimeoutException as e:
                    self.logger.warning(f"è¯·æ±‚è¶…æ—¶ (ç¬¬{retry_count + 1}æ¬¡): {e}")
                except httpx.ConnectError as e:
                    self.logger.warning(f"è¿æ¥é”™è¯¯ (ç¬¬{retry_count + 1}æ¬¡): {e}")
                except httpx.HTTPStatusError as e:
                    self.logger.warning(f"HTTPçŠ¶æ€é”™è¯¯ (ç¬¬{retry_count + 1}æ¬¡): {e}")
                except json.JSONDecodeError as e:
                    self.logger.warning(f"JSONè§£æé”™è¯¯ (ç¬¬{retry_count + 1}æ¬¡): {e}")
                except Exception as e:
                    self.logger.warning(f"å¼‚æ­¥è·å–è®¿å®¢ä»¤ç‰Œå¤±è´¥ (ç¬¬{retry_count + 1}æ¬¡): {e}")
                    import traceback
                    self.logger.debug(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
                
                retry_count += 1
                if retry_count < max_retries:
                    self.logger.info(f"ç­‰å¾…2ç§’åé‡è¯•...")
                    await asyncio.sleep(2)

            # åŒ¿åæ¨¡å¼ä¸‹ï¼Œå¦‚æœè·å–è®¿å®¢ä»¤ç‰Œå¤±è´¥ï¼Œç›´æ¥è¿”å›ç©º
            self.logger.error("âŒ åŒ¿åæ¨¡å¼ä¸‹è·å–è®¿å®¢ä»¤ç‰Œå¤±è´¥ï¼Œå·²é‡è¯•3æ¬¡")
            return ""

        # éåŒ¿åæ¨¡å¼ï¼šé¦–å…ˆä½¿ç”¨tokenæ± è·å–å¤‡ä»½ä»¤ç‰Œ
        token_pool = get_token_pool()
        if token_pool:
            token = token_pool.get_next_token()
            if token:
                self.logger.debug(f"ä»tokenæ± è·å–ä»¤ç‰Œ: {token[:20]}...")
                return token

        # å¦‚æœtokenæ± ä¸ºç©ºæˆ–æ²¡æœ‰å¯ç”¨tokenï¼Œä½¿ç”¨é…ç½®çš„AUTH_TOKEN
        if settings.AUTH_TOKEN and settings.AUTH_TOKEN != "sk-your-api-key":
            self.logger.debug(f"ä½¿ç”¨é…ç½®çš„AUTH_TOKEN")
            return settings.AUTH_TOKEN

        self.logger.error("âŒ æ— æ³•è·å–æœ‰æ•ˆçš„è®¤è¯ä»¤ç‰Œ")
        return ""
    
    def mark_token_failure(self, token: str, error: Exception = None):
        """æ ‡è®°tokenä½¿ç”¨å¤±è´¥"""
        token_pool = get_token_pool()
        if token_pool:
            token_pool.mark_token_failure(token, error)

    async def upload_image(self, data_url: str, chat_id: str, token: str, user_id: str) -> Optional[Dict]:
        """ä¸Šä¼  base64 ç¼–ç çš„å›¾ç‰‡åˆ° Z.AI æœåŠ¡å™¨

        Args:
            data_url: data:image/xxx;base64,... æ ¼å¼çš„å›¾ç‰‡æ•°æ®
            chat_id: å½“å‰å¯¹è¯ID
            token: è®¤è¯ä»¤ç‰Œ
            user_id: ç”¨æˆ·ID

        Returns:
            ä¸Šä¼ æˆåŠŸè¿”å›å®Œæ•´çš„æ–‡ä»¶ä¿¡æ¯å­—å…¸ï¼Œå¤±è´¥è¿”å›None
        """
        if settings.ANONYMOUS_MODE or not data_url.startswith("data:"):
            return None

        try:
            # è§£æ data URL
            header, encoded = data_url.split(",", 1)
            mime_type = header.split(";")[0].split(":")[1] if ":" in header else "image/jpeg"

            # è§£ç  base64 æ•°æ®
            image_data = base64.b64decode(encoded)
            filename = str(uuid.uuid4())

            self.logger.debug(f"ğŸ“¤ ä¸Šä¼ å›¾ç‰‡: {filename}, å¤§å°: {len(image_data)} bytes")

            # æ„å»ºä¸Šä¼ è¯·æ±‚ - ä½¿ç”¨ç®€åŒ–çš„è¯·æ±‚å¤´é…ç½®
            upload_url = f"{self.base_url}/api/v1/files/"
            headers = {
                "Accept": "*/*",
                "Accept-Language": "zh-CN,zh;q=0.9",
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "Origin": f"{self.base_url}",
                "Pragma": "no-cache",
                "Referer": f"{self.base_url}/c/{chat_id}",
                "Sec-Ch-Ua": '"Microsoft Edge";v="141", "Not?A_Brand";v="8", "Chromium";v="141"',
                "Sec-Ch-Ua-Mobile": "?0",
                "Sec-Ch-Ua-Platform": '"Windows"',
                "Sec-Fetch-Dest": "empty",
                "Sec-Fetch-Mode": "cors",
                "Sec-Fetch-Site": "same-origin",
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36 Edg/141.0.0.0",
                "Authorization": f"Bearer {token}",
            }

            # Get proxy configuration
            proxies = self._get_proxy_config()

            # ä½¿ç”¨ httpx ä¸Šä¼ æ–‡ä»¶
            async with httpx.AsyncClient(timeout=30.0, proxies=proxies) as client:
                files = {
                    "file": (filename, image_data, mime_type)
                }
                response = await client.post(upload_url, files=files, headers=headers)

                if response.status_code == 200:
                    result = response.json()
                    file_id = result.get("id")
                    file_name = result.get("filename")
                    file_size = len(image_data)

                    self.logger.info(f"âœ… å›¾ç‰‡ä¸Šä¼ æˆåŠŸ: {file_id}_{file_name}")

                    # è¿”å›ç¬¦åˆ Z.AI æ ¼å¼çš„æ–‡ä»¶ä¿¡æ¯
                    current_timestamp = int(time.time())
                    return {
                        "type": "image",
                        "file": {
                            "id": file_id,
                            "user_id": user_id,
                            "hash": None,
                            "filename": file_name,
                            "data": {},
                            "meta": {
                                "name": file_name,
                                "content_type": mime_type,
                                "size": file_size,
                                "data": {},
                            },
                            "created_at": current_timestamp,
                            "updated_at": current_timestamp
                        },
                        "id": file_id,
                        "url": f"/api/v1/files/{file_id}/content",
                        "name": file_name,
                        "status": "uploaded",
                        "size": file_size,
                        "error": "",
                        "itemId": str(uuid.uuid4()),
                        "media": "image"
                    }
                else:
                    self.logger.error(f"âŒ å›¾ç‰‡ä¸Šä¼ å¤±è´¥: {response.status_code} - {response.text}")
                    return None

        except Exception as e:
            self.logger.error(f"âŒ å›¾ç‰‡ä¸Šä¼ å¼‚å¸¸: {e}")
            return None

    async def transform_request(self, request: OpenAIRequest) -> Dict[str, Any]:
        """è½¬æ¢OpenAIè¯·æ±‚ä¸ºZ.AIæ ¼å¼"""
        self.logger.info(f"ğŸ”„ è½¬æ¢ OpenAI è¯·æ±‚åˆ° Z.AI æ ¼å¼: {request.model}")

        # è·å–è®¤è¯ä»¤ç‰Œ
        token = await self.get_token()
        user_id = _extract_user_id_from_token(token)

        # ç”Ÿæˆ chat_idï¼ˆç”¨äºå›¾ç‰‡ä¸Šä¼ ï¼‰
        chat_id = generate_uuid()

        # å¤„ç†æ¶ˆæ¯æ ¼å¼ - Z.AI ä½¿ç”¨å•ç‹¬çš„ files å­—æ®µä¼ é€’å›¾ç‰‡
        messages = []
        files = []  # å­˜å‚¨ä¸Šä¼ çš„å›¾ç‰‡æ–‡ä»¶ä¿¡æ¯

        for msg in request.messages:
            if isinstance(msg.content, str):
                # çº¯æ–‡æœ¬æ¶ˆæ¯
                messages.append({
                    "role": msg.role,
                    "content": msg.content
                })
            elif isinstance(msg.content, list):
                # å¤šæ¨¡æ€å†…å®¹ï¼šåˆ†ç¦»æ–‡æœ¬å’Œå›¾ç‰‡
                text_parts = []
                image_parts = []  # å­˜å‚¨å›¾ç‰‡å¼•ç”¨

                for part in msg.content:
                    if hasattr(part, 'type'):
                        if part.type == 'text' and hasattr(part, 'text'):
                            # æ–‡æœ¬éƒ¨åˆ†
                            text_parts.append(part.text or '')
                        elif part.type == 'image_url' and hasattr(part, 'image_url'):
                            # å›¾ç‰‡éƒ¨åˆ† - æå–å¹¶ä¸Šä¼ 
                            image_url = None
                            if hasattr(part.image_url, 'url'):
                                image_url = part.image_url.url
                            elif isinstance(part.image_url, dict) and 'url' in part.image_url:
                                image_url = part.image_url['url']

                            if image_url:
                                self.logger.debug(f"âœ… æ£€æµ‹åˆ°å›¾ç‰‡: {image_url[:50]}...")

                                # å¦‚æœæ˜¯ base64 ç¼–ç çš„å›¾ç‰‡ï¼Œä¸Šä¼ å¹¶æ·»åŠ åˆ° files æ•°ç»„
                                if image_url.startswith("data:") and not settings.ANONYMOUS_MODE:
                                    self.logger.info(f"ğŸ”„ ä¸Šä¼  base64 å›¾ç‰‡åˆ° Z.AI æœåŠ¡å™¨")
                                    file_info = await self.upload_image(image_url, chat_id, token, user_id)

                                    if file_info:
                                        files.append(file_info)
                                        self.logger.info(f"âœ… å›¾ç‰‡å·²æ·»åŠ åˆ° files æ•°ç»„")

                                        # åœ¨æ¶ˆæ¯ä¸­ä¿ç•™å›¾ç‰‡å¼•ç”¨
                                        image_ref = f"{file_info['id']}_{file_info['name']}"
                                        image_parts.append({
                                            "type": "image_url",
                                            "image_url": {
                                                "url": image_ref
                                            }
                                        })
                                        self.logger.debug(f"ğŸ“ å›¾ç‰‡å¼•ç”¨: {image_ref}")
                                    else:
                                        # ä¸Šä¼ å¤±è´¥ï¼Œæ·»åŠ é”™è¯¯æç¤º
                                        self.logger.warning(f"âš ï¸ å›¾ç‰‡ä¸Šä¼ å¤±è´¥")
                                        text_parts.append("[ç³»ç»Ÿæç¤º: å›¾ç‰‡ä¸Šä¼ å¤±è´¥]")
                                else:
                                    # é base64 å›¾ç‰‡æˆ–åŒ¿åæ¨¡å¼ï¼Œç›´æ¥ä½¿ç”¨åŸURL
                                    if not settings.ANONYMOUS_MODE:
                                        self.logger.warning(f"âš ï¸ é base64 å›¾ç‰‡æˆ–åŒ¿åæ¨¡å¼ï¼Œä¿ç•™åŸå§‹URL")
                                    image_parts.append({
                                        "type": "image_url",
                                        "image_url": {"url": image_url}
                                    })
                    elif isinstance(part, dict):
                        # ç›´æ¥æ˜¯å­—å…¸æ ¼å¼çš„å†…å®¹
                        if part.get('type') == 'text':
                            text_parts.append(part.get('text', ''))
                        elif part.get('type') == 'image_url':
                            image_url = part.get('image_url', {}).get('url', '')
                            if image_url:
                                self.logger.debug(f"âœ… æ£€æµ‹åˆ°å›¾ç‰‡: {image_url[:50]}...")

                                # å¦‚æœæ˜¯ base64 ç¼–ç çš„å›¾ç‰‡ï¼Œä¸Šä¼ å¹¶æ·»åŠ åˆ° files æ•°ç»„
                                if image_url.startswith("data:") and not settings.ANONYMOUS_MODE:
                                    self.logger.info(f"ğŸ”„ ä¸Šä¼  base64 å›¾ç‰‡åˆ° Z.AI æœåŠ¡å™¨")
                                    file_info = await self.upload_image(image_url, chat_id, token, user_id)

                                    if file_info:
                                        files.append(file_info)
                                        self.logger.info(f"âœ… å›¾ç‰‡å·²æ·»åŠ åˆ° files æ•°ç»„")

                                        # åœ¨æ¶ˆæ¯ä¸­ä¿ç•™å›¾ç‰‡å¼•ç”¨
                                        image_ref = f"{file_info['id']}_{file_info['name']}"
                                        image_parts.append({
                                            "type": "image_url",
                                            "image_url": {
                                                "url": image_ref
                                            }
                                        })
                                        self.logger.debug(f"ğŸ“ å›¾ç‰‡å¼•ç”¨: {image_ref}")
                                    else:
                                        # ä¸Šä¼ å¤±è´¥ï¼Œæ·»åŠ é”™è¯¯æç¤º
                                        self.logger.warning(f"âš ï¸ å›¾ç‰‡ä¸Šä¼ å¤±è´¥")
                                        text_parts.append("[ç³»ç»Ÿæç¤º: å›¾ç‰‡ä¸Šä¼ å¤±è´¥]")
                                else:
                                    # é base64 å›¾ç‰‡æˆ–åŒ¿åæ¨¡å¼
                                    if not settings.ANONYMOUS_MODE:
                                        self.logger.warning(f"âš ï¸ é base64 å›¾ç‰‡æˆ–åŒ¿åæ¨¡å¼ï¼Œä¿ç•™åŸå§‹URL")
                                    image_parts.append({
                                        "type": "image_url",
                                        "image_url": {"url": image_url}
                                    })
                    elif isinstance(part, str):
                        # çº¯å­—ç¬¦ä¸²éƒ¨åˆ†
                        text_parts.append(part)

                # æ„å»ºå¤šæ¨¡æ€æ¶ˆæ¯å†…å®¹
                message_content = []

                # æ·»åŠ æ–‡æœ¬éƒ¨åˆ†
                combined_text = " ".join(text_parts).strip()
                if combined_text:
                    message_content.append({
                        "type": "text",
                        "text": combined_text
                    })

                # æ·»åŠ å›¾ç‰‡éƒ¨åˆ†ï¼ˆä¿æŒå›¾ç‰‡å¼•ç”¨åœ¨æ¶ˆæ¯ä¸­ï¼‰
                message_content.extend(image_parts)

                # åªæœ‰åœ¨æœ‰å†…å®¹æ—¶æ‰æ·»åŠ æ¶ˆæ¯
                if message_content:
                    messages.append({
                        "role": msg.role,
                        "content": message_content  # âœ… å¤šæ¨¡æ€å†…å®¹æ•°ç»„
                    })
        
        # ç¡®å®šè¯·æ±‚çš„æ¨¡å‹ç‰¹æ€§
        # Extract last user message text for signing (æå–æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯çš„æ–‡æœ¬ç”¨äºç­¾å)
        last_user_text = ""
        for m in reversed(messages):
            if m.get("role") == "user":
                content = m.get("content")
                if isinstance(content, str):
                    # çº¯æ–‡æœ¬æ¶ˆæ¯
                    last_user_text = content
                    break
                elif isinstance(content, list):
                    # å¤šæ¨¡æ€æ¶ˆæ¯ï¼šåªæå–æ–‡æœ¬éƒ¨åˆ†ç”¨äºç­¾å
                    texts = [p.get("text", "") for p in content if isinstance(p, dict) and p.get("type") == "text"]
                    last_user_text = " ".join([t for t in texts if t]).strip()
                    break
        requested_model = request.model
        is_thinking = "-thinking" in requested_model.casefold()
        is_search = "-search" in requested_model.casefold()
        is_advanced_search = requested_model == settings.GLM46_ADVANCED_SEARCH_MODEL
        is_air = "-air" in requested_model.casefold()

        # è·å–ä¸Šæ¸¸æ¨¡å‹ID
        upstream_model_id = self.model_mapping.get(requested_model, "0727-360B-API")

        # âš ï¸ é‡è¦ï¼šåœ¨æ„å»º body ä¹‹å‰å¤„ç†å·¥å…·è°ƒç”¨ï¼
        # å¤„ç†å·¥å…·æ”¯æŒ - ä½¿ç”¨æç¤ºè¯æ³¨å…¥æ–¹å¼
        if settings.TOOL_SUPPORT and not is_thinking and request.tools:
            tool_choice = getattr(request, 'tool_choice', 'auto') or 'auto'
            messages = process_messages_with_tools(
                messages=messages,
                tools=request.tools,
                tool_choice=tool_choice
            )
            self.logger.info(f"ğŸ”§ å·¥å…·è°ƒç”¨å·²é€šè¿‡æç¤ºè¯æ³¨å…¥: {len(request.tools)} ä¸ªå·¥å…·")

        # æ„å»ºMCPæœåŠ¡å™¨åˆ—è¡¨
        mcp_servers = []
        if is_advanced_search:
            mcp_servers.append("advanced-search")
            self.logger.info("ğŸ” æ£€æµ‹åˆ°é«˜çº§æœç´¢æ¨¡å‹ï¼Œæ·»åŠ  advanced-search MCP æœåŠ¡å™¨")
        elif is_search and "-4.5" in requested_model:
            mcp_servers.append("deep-web-search")
            self.logger.info("ğŸ” æ£€æµ‹åˆ°æœç´¢æ¨¡å‹ï¼Œæ·»åŠ  deep-web-search MCP æœåŠ¡å™¨")

        # æ„å»ºä¸Šæ¸¸è¯·æ±‚ä½“ï¼ˆchat_id å·²åœ¨å‰é¢ç”Ÿæˆï¼‰

        body = {
            "stream": True,  # æ€»æ˜¯ä½¿ç”¨æµå¼
            "model": upstream_model_id,
            "messages": messages,  # âœ… messages å·²ç»åŒ…å«å·¥å…·æç¤ºè¯
            "signature_prompt": last_user_text,  # ç”¨äºç­¾åçš„æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
            "files": files,  # å›¾ç‰‡æ–‡ä»¶æ•°ç»„
            "params": {},
            "features": {
                "image_generation": False,
                "web_search": is_search or is_advanced_search,
                "auto_web_search": is_search or is_advanced_search,
                "preview_mode": is_search or is_advanced_search,
                "flags": [],
                "features": [
                    {
                        "type": "mcp",
                        "server": "vibe-coding",
                        "status": "hidden"
                    },
                    {
                        "type": "mcp",
                        "server": "ppt-maker",
                        "status": "hidden"
                    },
                    {
                        "type": "mcp",
                        "server": "image-search",
                        "status": "hidden"
                    },
                    {
                        "type": "mcp",
                        "server": "deep-research",
                        "status": "hidden"
                    },
                    {
                        "type": "tool_selector",
                        "server": "tool_selector",
                        "status": "hidden"
                    },
                    {
                        "type": "mcp",
                        "server": "advanced-search",
                        "status": "hidden"
                    }
                ],
                "enable_thinking": is_thinking,
            },
            "background_tasks": {
                "title_generation": False,
                "tags_generation": False,
            },
            "mcp_servers": mcp_servers,
            "variables": {
                "{{USER_NAME}}": "Guest",
                "{{USER_LOCATION}}": "Unknown",
                "{{CURRENT_DATETIME}}": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "{{CURRENT_DATE}}": datetime.now().strftime("%Y-%m-%d"),
                "{{CURRENT_TIME}}": datetime.now().strftime("%H:%M:%S"),
                "{{CURRENT_WEEKDAY}}": datetime.now().strftime("%A"),
                "{{CURRENT_TIMEZONE}}": "Asia/Shanghai",
                "{{USER_LANGUAGE}}": "zh-CN",
            },
            "model_item": {
                "id": upstream_model_id,
                "name": requested_model,
                "owned_by": "z.ai"
            },
            "chat_id": chat_id,
            "id": generate_uuid(),
        }

        # ä¸ä¼ é€’ tools ç»™ä¸Šæ¸¸,ä½¿ç”¨æç¤ºå·¥ç¨‹æ–¹å¼
        body["tools"] = None
        
        # å¤„ç†å…¶ä»–å‚æ•°
        if request.temperature is not None:
            body["params"]["temperature"] = request.temperature
        if request.max_tokens is not None:
            body["params"]["max_tokens"] = request.max_tokens
        
        # æ„å»ºè¯·æ±‚å¤´
        headers = get_zai_dynamic_headers(chat_id)
        if token:
            headers["Authorization"] = f"Bearer {token}"

        # Dual-layer HMAC signing metadata and header
        user_id = _extract_user_id_from_token(token)
        timestamp_ms = int(time.time() * 1000)
        request_id = generate_uuid()
        secret = os.getenv("ZAI_SIGNING_SECRET", "junjie") or "junjie"
        signature = generate_signature(
            message_text=last_user_text,
            request_id=request_id,
            timestamp_ms=timestamp_ms,
            user_id=user_id,
            secret=secret,
        )
        query_params = {
            "timestamp": timestamp_ms,
            "requestId": request_id,
            "user_id": user_id,
            "token": token or "",
            "current_url": f"https://chat.z.ai/c/{chat_id}",
            "pathname": f"/c/{chat_id}",
            "signature_timestamp": timestamp_ms,
        }
        signed_url = f"{self.config.api_endpoint}?{urlencode(query_params)}"
        headers["X-Signature"] = signature
        
        # å­˜å‚¨å½“å‰tokenç”¨äºé”™è¯¯å¤„ç†
        self._current_token = token

        return {
            "url": signed_url,
            "headers": headers,
            "body": body,
            "token": token,
            "chat_id": chat_id,
            "model": requested_model
        }
    
    async def chat_completion(
        self,
        request: OpenAIRequest,
        **kwargs
    ) -> Union[Dict[str, Any], AsyncGenerator[str, None]]:
        """èŠå¤©å®Œæˆæ¥å£"""
        self.log_request(request)

        try:
            # è½¬æ¢è¯·æ±‚
            transformed = await self.transform_request(request)

            # æ ¹æ®è¯·æ±‚ç±»å‹è¿”å›å“åº”
            if request.stream:
                # æµå¼å“åº”
                return self._create_stream_response(request, transformed)
            else:
                # Get proxy configuration
                proxies = self._get_proxy_config()

                # éæµå¼å“åº”
                async with httpx.AsyncClient(timeout=30.0, proxies=proxies) as client:
                    response = await client.post(
                        transformed["url"],
                        headers=transformed["headers"],
                        json=transformed["body"]
                    )

                    if not response.is_success:
                        error_msg = f"Z.AI API é”™è¯¯: {response.status_code}"
                        self.log_response(False, error_msg)
                        return self.handle_error(Exception(error_msg))

                    return await self.transform_response(response, request, transformed)

        except Exception as e:
            self.log_response(False, str(e))
            return self.handle_error(e, "è¯·æ±‚å¤„ç†")

    
    async def _create_stream_response(
        self,
        request: OpenAIRequest,
        transformed: Dict[str, Any]
    ) -> AsyncGenerator[str, None]:

        current_token = transformed.get("token", "")
        try:
            # Get proxy configuration
            proxies = self._get_proxy_config()

            async with httpx.AsyncClient(
                timeout=60.0,
                http2=True,
                proxies=proxies,
            ) as client:
                self.logger.info(f"ğŸ¯ å‘é€è¯·æ±‚åˆ° Z.AI: {transformed['url']}")
                # self.logger.info(f"ğŸ“¦ è¯·æ±‚ä½“ model: {transformed['body']['model']}")
                # self.logger.info(f"ğŸ“¦ è¯·æ±‚ä½“ messages: {json.dumps(transformed['body']['messages'], ensure_ascii=False)}")
                async with client.stream(
                    "POST",
                    transformed["url"],
                    json=transformed["body"],
                    headers=transformed["headers"],
                ) as response:
                    if response.status_code != 200:
                        self.logger.error(f"âŒ ä¸Šæ¸¸è¿”å›é”™è¯¯: {response.status_code}")
                        error_text = await response.aread()
                        error_msg = error_text.decode('utf-8', errors='ignore')
                        if error_msg:
                            self.logger.error(f"âŒ é”™è¯¯è¯¦æƒ…: {error_msg}")

                        # ç‰¹æ®Šå¤„ç† 405 çŠ¶æ€ç (WAFæ‹¦æˆª)
                        if response.status_code == 405:
                            self.logger.error(f"ğŸš« è¯·æ±‚è¢«ä¸Šæ¸¸WAFæ‹¦æˆª,å¯èƒ½æ˜¯è¯·æ±‚å¤´æˆ–ç­¾åå¼‚å¸¸,è¯·ç¨åé‡è¯•...")
                            error_response = {
                                "error": {
                                    "message": "è¯·æ±‚è¢«ä¸Šæ¸¸WAFæ‹¦æˆª(405 Method Not Allowed),å¯èƒ½æ˜¯è¯·æ±‚å¤´æˆ–ç­¾åå¼‚å¸¸,è¯·ç¨åé‡è¯•...",
                                    "type": "waf_blocked",
                                    "code": 405
                                }
                            }
                        else:
                            error_response = {
                                "error": {
                                    "message": f"Upstream error: {response.status_code}",
                                    "type": "upstream_error",
                                    "code": response.status_code
                                }
                            }
                        yield f"data: {json.dumps(error_response)}\n\n"
                        yield "data: [DONE]\n\n"
                        return

                    if current_token and not settings.ANONYMOUS_MODE:
                        token_pool = get_token_pool()
                        if token_pool:
                            token_pool.mark_token_success(current_token)

                    chat_id = transformed["chat_id"]
                    model = transformed["model"]
                    async for chunk in self._handle_stream_response(response, chat_id, model, request, transformed):
                        yield chunk
                    return
        except Exception as e:
            self.logger.error(f"âŒ æµå¤„ç†é”™è¯¯: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            if current_token and not settings.ANONYMOUS_MODE:
                self.mark_token_failure(current_token, e)
            error_response = {
                "error": {
                    "message": str(e),
                    "type": "stream_error"
                }
            }
            yield f"data: {json.dumps(error_response)}\n\n"
            yield "data: [DONE]\n\n"
            return

    async def transform_response(
        self, 
        response: httpx.Response, 
        request: OpenAIRequest,
        transformed: Dict[str, Any]
    ) -> Union[Dict[str, Any], AsyncGenerator[str, None]]:
        """è½¬æ¢Z.AIå“åº”ä¸ºOpenAIæ ¼å¼"""
        chat_id = transformed["chat_id"]
        model = transformed["model"]
        
        if request.stream:
            return self._handle_stream_response(response, chat_id, model, request, transformed)
        else:
            return await self._handle_non_stream_response(response, chat_id, model)
    
    async def _handle_stream_response(
        self,
        response: httpx.Response,
        chat_id: str,
        model: str,
        request: OpenAIRequest,
        transformed: Dict[str, Any]
    ) -> AsyncGenerator[str, None]:
        """å¤„ç†Z.AIæµå¼å“åº”"""
        self.logger.info(f"âœ… Z.AI å“åº”æˆåŠŸï¼Œå¼€å§‹å¤„ç† SSE æµ")

        # æ£€æŸ¥æ˜¯å¦å¯ç”¨äº†å·¥å…·è°ƒç”¨ (é€šè¿‡æ£€æŸ¥åŸå§‹è¯·æ±‚)
        has_tools = settings.TOOL_SUPPORT and request.tools is not None and len(request.tools) > 0

        # ç´¯ç§¯å†…å®¹ç¼“å†²åŒº,ç”¨äºæå–å·¥å…·è°ƒç”¨
        buffered_content = ""
        has_sent_role = False

        # å¤„ç†çŠ¶æ€
        has_thinking = False
        thinking_signature = None

        # å¤„ç†SSEæµ
        buffer = ""
        line_count = 0
        self.logger.debug("ğŸ“¡ å¼€å§‹æ¥æ”¶ SSE æµæ•°æ®...")

        try:
            async for line in response.aiter_lines():
                line_count += 1
                if not line:
                    continue

                # ç´¯ç§¯åˆ°bufferå¤„ç†å®Œæ•´çš„æ•°æ®è¡Œ
                buffer += line + "\n"

                # æ£€æŸ¥æ˜¯å¦æœ‰å®Œæ•´çš„dataè¡Œ
                while "\n" in buffer:
                    current_line, buffer = buffer.split("\n", 1)
                    if not current_line.strip():
                        continue

                    if current_line.startswith("data:"):
                        chunk_str = current_line[5:].strip()
                        if not chunk_str or chunk_str == "[DONE]":
                            if chunk_str == "[DONE]":
                                yield "data: [DONE]\n\n"
                            continue

                        self.logger.debug(f"ğŸ“¦ è§£ææ•°æ®å—: {chunk_str[:1000]}..." if len(chunk_str) > 1000 else f"ğŸ“¦ è§£ææ•°æ®å—: {chunk_str}")

                        try:
                            chunk = json.loads(chunk_str)

                            if chunk.get("type") == "chat:completion":
                                data = chunk.get("data", {})
                                phase = data.get("phase")

                                # è®°å½•æ¯ä¸ªé˜¶æ®µï¼ˆåªåœ¨é˜¶æ®µå˜åŒ–æ—¶è®°å½•ï¼‰
                                if phase and phase != getattr(self, '_last_phase', None):
                                    self.logger.info(f"ğŸ“ˆ SSE é˜¶æ®µ: {phase}")
                                    self._last_phase = phase

                                # å¤„ç†æ€è€ƒå†…å®¹
                                if phase == "thinking":
                                    if not has_thinking:
                                        has_thinking = True
                                        # å‘é€åˆå§‹è§’è‰²
                                        role_chunk = self.create_openai_chunk(
                                            chat_id,
                                            model,
                                            {"role": "assistant"}
                                        )
                                        yield await self.format_sse_chunk(role_chunk)

                                    delta_content = data.get("delta_content", "")
                                    if delta_content:
                                        # å¤„ç†æ€è€ƒå†…å®¹æ ¼å¼
                                        if delta_content.startswith("<details"):
                                            content = (
                                                delta_content.split("</summary>\n>")[-1].strip()
                                                if "</summary>\n>" in delta_content
                                                else delta_content
                                            )
                                        else:
                                            content = delta_content

                                        thinking_chunk = self.create_openai_chunk(
                                            chat_id,
                                            model,
                                            {
                                                "role": "assistant",
                                                "reasoning_content": content
                                            }
                                        )
                                        yield await self.format_sse_chunk(thinking_chunk)

                                # å¤„ç†ç­”æ¡ˆå†…å®¹
                                elif phase == "answer":
                                    delta_content = data.get("delta_content", "")
                                    edit_content = data.get("edit_content", "")

                                    # ç´¯ç§¯å†…å®¹(ç”¨äºå·¥å…·è°ƒç”¨æå–)
                                    if delta_content:
                                        buffered_content += delta_content
                                    elif edit_content:
                                        buffered_content = edit_content

                                    # å¦‚æœåŒ…å« usage,è¯´æ˜æµå¼ç»“æŸ
                                    if data.get("usage"):
                                        usage = data["usage"]
                                        self.logger.info(f"ğŸ“¦ å®Œæˆå“åº” - ä½¿ç”¨ç»Ÿè®¡: {json.dumps(usage)}")

                                        # å°è¯•ä»ç¼“å†²åŒºæå– tool_calls
                                        tool_calls = None
                                        cleaned_content = buffered_content

                                        if has_tools:
                                            tool_calls, cleaned_content = parse_and_extract_tool_calls(buffered_content)

                                        if tool_calls:
                                            # å‘ç°å·¥å…·è°ƒç”¨
                                            self.logger.info(f"ğŸ”§ ä»å“åº”ä¸­æå–åˆ° {len(tool_calls)} ä¸ªå·¥å…·è°ƒç”¨")

                                            if not has_sent_role:
                                                role_chunk = self.create_openai_chunk(
                                                    chat_id,
                                                    model,
                                                    {"role": "assistant"}
                                                )
                                                yield await self.format_sse_chunk(role_chunk)
                                                has_sent_role = True

                                            # å‘é€å·¥å…·è°ƒç”¨
                                            for idx, tc in enumerate(tool_calls):
                                                tool_chunk = self.create_openai_chunk(
                                                    chat_id,
                                                    model,
                                                    {
                                                        "role": "assistant",
                                                        "tool_calls": [{
                                                            "index": idx,
                                                            "id": tc.get("id", f"call_{idx}"),
                                                            "type": "function",
                                                            "function": {
                                                                "name": tc.get("function", {}).get("name", ""),
                                                                "arguments": tc.get("function", {}).get("arguments", "")
                                                            }
                                                        }]
                                                    }
                                                )
                                                yield await self.format_sse_chunk(tool_chunk)

                                            # å‘é€å®Œæˆå—
                                            finish_chunk = self.create_openai_chunk(
                                                chat_id,
                                                model,
                                                {"role": "assistant"},
                                                "tool_calls"
                                            )
                                            finish_chunk["usage"] = usage
                                            yield await self.format_sse_chunk(finish_chunk)
                                            yield "data: [DONE]\n\n"

                                        else:
                                            # æ²¡æœ‰å·¥å…·è°ƒç”¨,æ­£å¸¸è¿”å›å†…å®¹
                                            # å¤„ç†æ€è€ƒç»“æŸå’Œç­”æ¡ˆå¼€å§‹
                                            if edit_content and "</details>\n" in edit_content:
                                                if has_thinking:
                                                    # å‘é€æ€è€ƒç­¾å
                                                    thinking_signature = str(int(time.time() * 1000))
                                                    sig_chunk = self.create_openai_chunk(
                                                        chat_id,
                                                        model,
                                                        {
                                                            "role": "assistant",
                                                            "thinking": {
                                                                "content": "",
                                                                "signature": thinking_signature,
                                                            }
                                                        }
                                                    )
                                                    yield await self.format_sse_chunk(sig_chunk)

                                                # æå–ç­”æ¡ˆå†…å®¹
                                                cleaned_content = edit_content.split("</details>\n")[-1]

                                            if not has_sent_role and not has_thinking:
                                                role_chunk = self.create_openai_chunk(
                                                    chat_id,
                                                    model,
                                                    {"role": "assistant"}
                                                )
                                                yield await self.format_sse_chunk(role_chunk)
                                                has_sent_role = True

                                            if cleaned_content:
                                                content_chunk = self.create_openai_chunk(
                                                    chat_id,
                                                    model,
                                                    {
                                                        "role": "assistant",
                                                        "content": cleaned_content
                                                    }
                                                )
                                                yield await self.format_sse_chunk(content_chunk)

                                            finish_chunk = self.create_openai_chunk(
                                                chat_id,
                                                model,
                                                {"role": "assistant", "content": ""},
                                                "stop"
                                            )
                                            finish_chunk["usage"] = usage
                                            yield await self.format_sse_chunk(finish_chunk)
                                            yield "data: [DONE]\n\n"
                                    else:
                                        # æµå¼è¿‡ç¨‹ä¸­,è¾“å‡ºç­”æ¡ˆå†…å®¹ï¼ˆå³ä½¿æœ‰å·¥å…·è°ƒç”¨ä¹Ÿè¦æ˜¾ç¤ºï¼‰
                                        # å¤„ç†æ€è€ƒç»“æŸå’Œç­”æ¡ˆå¼€å§‹
                                        if edit_content and "</details>\n" in edit_content:
                                            if has_thinking:
                                                # å‘é€æ€è€ƒç­¾å
                                                thinking_signature = str(int(time.time() * 1000))
                                                sig_chunk = self.create_openai_chunk(
                                                    chat_id,
                                                    model,
                                                    {
                                                        "role": "assistant",
                                                        "thinking": {
                                                            "content": "",
                                                            "signature": thinking_signature,
                                                        }
                                                    }
                                                )
                                                yield await self.format_sse_chunk(sig_chunk)

                                            # æå–ç­”æ¡ˆå†…å®¹
                                            content_after = edit_content.split("</details>\n")[-1]
                                            if content_after:
                                                content_chunk = self.create_openai_chunk(
                                                    chat_id,
                                                    model,
                                                    {
                                                        "role": "assistant",
                                                        "content": content_after
                                                    }
                                                )
                                                yield await self.format_sse_chunk(content_chunk)

                                        # å¤„ç†å¢é‡å†…å®¹
                                        elif delta_content:
                                            if not has_sent_role and not has_thinking:
                                                role_chunk = self.create_openai_chunk(
                                                    chat_id,
                                                    model,
                                                    {"role": "assistant"}
                                                )
                                                yield await self.format_sse_chunk(role_chunk)
                                                has_sent_role = True

                                            content_chunk = self.create_openai_chunk(
                                                chat_id,
                                                model,
                                                {
                                                    "role": "assistant",
                                                    "content": delta_content
                                                }
                                            )
                                            output_data = await self.format_sse_chunk(content_chunk)
                                            self.logger.debug(f"â¡ï¸ è¾“å‡ºå†…å®¹å—åˆ°å®¢æˆ·ç«¯: {output_data}")
                                            yield output_data

                        except json.JSONDecodeError as e:
                            self.logger.debug(f"âŒ JSONè§£æé”™è¯¯: {e}, å†…å®¹: {chunk_str[:1000]}")
                        except Exception as e:
                            self.logger.error(f"âŒ å¤„ç†chunké”™è¯¯: {e}")

            self.logger.info(f"âœ… SSE æµå¤„ç†å®Œæˆï¼Œå…±å¤„ç† {line_count} è¡Œæ•°æ®")

        except Exception as e:
            self.logger.error(f"âŒ æµå¼å“åº”å¤„ç†é”™è¯¯: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            # å‘é€é”™è¯¯ç»“æŸå—
            yield await self.format_sse_chunk(
                self.create_openai_chunk(chat_id, model, {}, "stop")
            )
            yield "data: [DONE]\n\n"
    
    async def _handle_non_stream_response(
        self, 
        response: httpx.Response, 
        chat_id: str, 
        model: str
    ) -> Dict[str, Any]:
        """å¤„ç†éæµå¼å“åº”

        è¯´æ˜ï¼šä¸Šæ¸¸å§‹ç»ˆä»¥ SSE å½¢å¼è¿”å›ï¼ˆtransform_request å›ºå®š stream=Trueï¼‰ï¼Œ
        å› æ­¤è¿™é‡Œéœ€è¦èšåˆ aiter_lines() çš„ data: å—ï¼Œæå– usageã€æ€è€ƒå†…å®¹ä¸ç­”æ¡ˆå†…å®¹ï¼Œ
        å¹¶æœ€ç»ˆäº§å‡ºä¸€æ¬¡æ€§ OpenAI æ ¼å¼å“åº”ã€‚
        """
        final_content = ""
        reasoning_content = ""
        usage_info: Dict[str, int] = {
            "prompt_tokens": 0,
            "completion_tokens": 0,
            "total_tokens": 0,
        }

        try:
            async for line in response.aiter_lines():
                if not line:
                    continue

                line = line.strip()

                # ä»…å¤„ç†ä»¥ data: å¼€å¤´çš„ SSE è¡Œï¼Œå…¶ä½™è¡Œå°è¯•ä½œä¸ºé”™è¯¯/JSON å¿½ç•¥
                if not line.startswith("data:"):
                    # å°è¯•è§£æä¸ºé”™è¯¯ JSON
                    try:
                        maybe_err = json.loads(line)
                        if isinstance(maybe_err, dict) and (
                            "error" in maybe_err or "code" in maybe_err or "message" in maybe_err
                        ):
                            # ç»Ÿä¸€é”™è¯¯å¤„ç†
                            msg = (
                                (maybe_err.get("error") or {}).get("message")
                                if isinstance(maybe_err.get("error"), dict)
                                else maybe_err.get("message")
                            ) or "ä¸Šæ¸¸è¿”å›é”™è¯¯"
                            return self.handle_error(Exception(msg), "APIå“åº”")
                    except Exception:
                        pass
                    continue

                data_str = line[5:].strip()
                if not data_str or data_str in ("[DONE]", "DONE", "done"):
                    continue

                # è§£æ SSE æ•°æ®å—
                try:
                    chunk = json.loads(data_str)
                except json.JSONDecodeError:
                    continue

                if chunk.get("type") != "chat:completion":
                    continue

                data = chunk.get("data", {})
                phase = data.get("phase")
                delta_content = data.get("delta_content", "")
                edit_content = data.get("edit_content", "")

                # è®°å½•ç”¨é‡ï¼ˆé€šå¸¸åœ¨æœ€åå—ä¸­å‡ºç°ï¼Œä½†è¿™é‡Œæ¯æ¬¡è¦†ç›–ä¿æŒæœ€æ–°ï¼‰
                if data.get("usage"):
                    try:
                        usage_info = data["usage"]
                    except Exception:
                        pass

                # æ€è€ƒé˜¶æ®µèšåˆï¼ˆå»é™¤ <details><summary>... åŒ…è£¹å¤´ï¼‰
                if phase == "thinking":
                    if delta_content:
                        if delta_content.startswith("<details"):
                            cleaned = (
                                delta_content.split("</summary>\n>")[-1].strip()
                                if "</summary>\n>" in delta_content
                                else delta_content
                            )
                        else:
                            cleaned = delta_content
                        reasoning_content += cleaned

                # ç­”æ¡ˆé˜¶æ®µèšåˆ
                elif phase == "answer":
                    # å½“ edit_content åŒæ—¶åŒ…å«æ€è€ƒç»“æŸæ ‡è®°ä¸ç­”æ¡ˆæ—¶ï¼Œæå–ç­”æ¡ˆéƒ¨åˆ†
                    if edit_content and "</details>\n" in edit_content:
                        content_after = edit_content.split("</details>\n")[-1]
                        if content_after:
                            final_content += content_after
                    elif delta_content:
                        final_content += delta_content

        except Exception as e:
            self.logger.error(f"âŒ éæµå¼å“åº”å¤„ç†é”™è¯¯: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            # è¿”å›ç»Ÿä¸€é”™è¯¯å“åº”
            return self.handle_error(e, "éæµå¼èšåˆ")

        # æ¸…ç†å¹¶è¿”å›
        final_content = (final_content or "").strip()
        reasoning_content = (reasoning_content or "").strip()

        # è‹¥æ²¡æœ‰èšåˆåˆ°ç­”æ¡ˆï¼Œä½†æœ‰æ€è€ƒå†…å®¹ï¼Œåˆ™ä¿åº•è¿”å›æ€è€ƒå†…å®¹
        if not final_content and reasoning_content:
            final_content = reasoning_content

        # è¿”å›åŒ…å«æ¨ç†å†…å®¹çš„æ ‡å‡†å“åº”ï¼ˆè‹¥æ— æ¨ç†åˆ™ä¸ä¼šæºå¸¦ï¼‰
        return self.create_openai_response_with_reasoning(
            chat_id,
            model,
            final_content,
            reasoning_content,
            usage_info,
        )
