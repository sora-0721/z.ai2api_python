#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
SSE Tool Handler

å¤„ç† Z.AI SSE æµæ•°æ®å¹¶è½¬æ¢ä¸º OpenAI å…¼å®¹æ ¼å¼çš„å·¥å…·è°ƒç”¨å¤„ç†å™¨ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
- è§£æ glm_block æ ¼å¼çš„å·¥å…·è°ƒç”¨
- ä» metadata.arguments æå–å®Œæ•´å‚æ•°
- æ”¯æŒå¤šé˜¶æ®µå¤„ç†ï¼šthinking â†’ tool_call â†’ other â†’ answer
- è¾“å‡ºç¬¦åˆ OpenAI API è§„èŒƒçš„æµå¼å“åº”
"""

import json
import time
from typing import Dict, Any, Generator
from enum import Enum

from app.utils.logger import get_logger

logger = get_logger()


class SSEPhase(Enum):
    """SSE å¤„ç†é˜¶æ®µæšä¸¾"""
    THINKING = "thinking"
    TOOL_CALL = "tool_call"
    OTHER = "other"
    ANSWER = "answer"
    DONE = "done"


class SSEToolHandler:
    """SSE å·¥å…·è°ƒç”¨å¤„ç†å™¨"""

    def __init__(self, model: str, stream: bool = True):
        self.model = model
        self.stream = stream

        # çŠ¶æ€ç®¡ç†
        self.current_phase = None
        self.has_tool_call = False

        # å·¥å…·è°ƒç”¨çŠ¶æ€
        self.tool_id = ""
        self.tool_name = ""
        self.tool_args = ""
        self.tool_call_usage = {}
        self.content_index = 0  # å·¥å…·è°ƒç”¨ç´¢å¼•

        # æ€§èƒ½ä¼˜åŒ–ï¼šå†…å®¹ç¼“å†²
        self.content_buffer = ""
        self.buffer_size = 0
        self.last_flush_time = time.time()
        self.flush_interval = 0.05  # 50ms åˆ·æ–°é—´éš”
        self.max_buffer_size = 100  # æœ€å¤§ç¼“å†²å­—ç¬¦æ•°

        logger.debug(f"ğŸ”§ åˆå§‹åŒ–å·¥å…·å¤„ç†å™¨: model={model}, stream={stream}")

    def process_sse_chunk(self, chunk_data: Dict[str, Any]) -> Generator[str, None, None]:
        """
        å¤„ç† SSE æ•°æ®å—ï¼Œè¿”å› OpenAI æ ¼å¼çš„æµå¼å“åº”

        Args:
            chunk_data: Z.AI SSE æ•°æ®å—

        Yields:
            str: OpenAI æ ¼å¼çš„ SSE å“åº”è¡Œ
        """
        try:
            phase = chunk_data.get("phase")
            edit_content = chunk_data.get("edit_content", "")
            delta_content = chunk_data.get("delta_content", "")
            edit_index = chunk_data.get("edit_index")
            usage = chunk_data.get("usage", {})

            # æ•°æ®éªŒè¯
            if not phase:
                logger.warning("âš ï¸ æ”¶åˆ°æ— æ•ˆçš„ SSE å—ï¼šç¼ºå°‘ phase å­—æ®µ")
                return

            # é˜¶æ®µå˜åŒ–æ£€æµ‹å’Œæ—¥å¿—
            if phase != self.current_phase:
                # é˜¶æ®µå˜åŒ–æ—¶å¼ºåˆ¶åˆ·æ–°ç¼“å†²åŒº
                if hasattr(self, 'content_buffer') and self.content_buffer:
                    yield from self._flush_content_buffer()

                logger.info(f"ğŸ“ˆ SSE é˜¶æ®µå˜åŒ–: {self.current_phase} â†’ {phase}")
                content_preview = edit_content or delta_content
                if content_preview:
                    logger.debug(f"   ğŸ“ å†…å®¹é¢„è§ˆ: {content_preview[:1000]}{'...' if len(content_preview) > 1000 else ''}")
                if edit_index is not None:
                    logger.debug(f"   ğŸ“ edit_index: {edit_index}")
                self.current_phase = phase

            # æ ¹æ®é˜¶æ®µå¤„ç†
            if phase == SSEPhase.THINKING.value:
                yield from self._process_thinking_phase(delta_content)

            elif phase == SSEPhase.TOOL_CALL.value:
                yield from self._process_tool_call_phase(edit_content)

            elif phase == SSEPhase.OTHER.value:
                yield from self._process_other_phase(usage, edit_content)

            elif phase == SSEPhase.ANSWER.value:
                yield from self._process_answer_phase(delta_content)

            elif phase == SSEPhase.DONE.value:
                yield from self._process_done_phase(chunk_data)
            else:
                logger.warning(f"âš ï¸ æœªçŸ¥çš„ SSE é˜¶æ®µ: {phase}")

        except Exception as e:
            logger.error(f"âŒ å¤„ç† SSE å—æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            logger.debug(f"   ğŸ“¦ é”™è¯¯å—æ•°æ®: {chunk_data}")
            # ä¸ä¸­æ–­æµï¼Œç»§ç»­å¤„ç†åç»­å—

    def _process_thinking_phase(self, delta_content: str) -> Generator[str, None, None]:
        """å¤„ç†æ€è€ƒé˜¶æ®µ"""
        if not delta_content:
            return

        logger.debug(f"ğŸ¤” æ€è€ƒå†…å®¹: +{len(delta_content)} å­—ç¬¦")

        # åœ¨æµæ¨¡å¼ä¸‹è¾“å‡ºæ€è€ƒå†…å®¹
        if self.stream:
            chunk = self._create_content_chunk(delta_content)
            yield f"data: {json.dumps(chunk, ensure_ascii=False)}\n\n"

    def _process_tool_call_phase(self, edit_content: str) -> Generator[str, None, None]:
        """å¤„ç†å·¥å…·è°ƒç”¨é˜¶æ®µ"""
        if not edit_content:
            return

        logger.debug(f"ğŸ”§ è¿›å…¥å·¥å…·è°ƒç”¨é˜¶æ®µï¼Œå†…å®¹é•¿åº¦: {len(edit_content)}")

        # æ£€æµ‹ glm_block æ ‡è®°
        if "<glm_block " in edit_content:
            yield from self._handle_glm_blocks(edit_content)
        else:
            # æ²¡æœ‰ glm_block æ ‡è®°ï¼Œå¯èƒ½æ˜¯å‚æ•°è¡¥å……
            if self.has_tool_call:
                # åªç´¯ç§¯å‚æ•°éƒ¨åˆ†ï¼Œæ‰¾åˆ°ç¬¬ä¸€ä¸ª ", "result"" ä¹‹å‰çš„å†…å®¹
                result_pos = edit_content.find('", "result"')
                if result_pos > 0:
                    param_fragment = edit_content[:result_pos]
                    self.tool_args += param_fragment
                    logger.debug(f"ğŸ“¦ ç´¯ç§¯å‚æ•°ç‰‡æ®µ: {param_fragment}")
                else:
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç»“æŸæ ‡è®°ï¼Œç´¯ç§¯æ•´ä¸ªå†…å®¹ï¼ˆå¯èƒ½æ˜¯ä¸­é—´ç‰‡æ®µï¼‰
                    self.tool_args += edit_content
                    logger.debug(f"ğŸ“¦ ç´¯ç§¯å‚æ•°ç‰‡æ®µ: {edit_content[:100]}...")

    def _handle_glm_blocks(self, edit_content: str) -> Generator[str, None, None]:
        """å¤„ç† glm_block æ ‡è®°çš„å†…å®¹"""
        blocks = edit_content.split('<glm_block ')
        logger.debug(f"ğŸ“¦ åˆ†å‰²å¾—åˆ° {len(blocks)} ä¸ªå—")

        for index, block in enumerate(blocks):
            if not block.strip():
                continue

            if index == 0:
                # ç¬¬ä¸€ä¸ªå—ï¼šæå–å‚æ•°ç‰‡æ®µ
                if self.has_tool_call:
                    logger.debug(f"ğŸ“¦ ä»ç¬¬ä¸€ä¸ªå—æå–å‚æ•°ç‰‡æ®µ")
                    # æ‰¾åˆ° "result" çš„ä½ç½®ï¼Œæå–ä¹‹å‰çš„å‚æ•°ç‰‡æ®µ
                    result_pos = edit_content.find('"result"')
                    if result_pos > 0:
                        # å¾€å‰é€€3ä¸ªå­—ç¬¦å»æ‰ ", "
                        param_fragment = edit_content[:result_pos - 3]
                        self.tool_args += param_fragment
                        logger.debug(f"ğŸ“¦ ç´¯ç§¯å‚æ•°ç‰‡æ®µ: {param_fragment}")
                else:
                    # æ²¡æœ‰æ´»è·ƒå·¥å…·è°ƒç”¨ï¼Œè·³è¿‡ç¬¬ä¸€ä¸ªå—
                    continue
            else:
                # åç»­å—ï¼šå¤„ç†æ–°å·¥å…·è°ƒç”¨
                if "</glm_block>" not in block:
                    continue

                # å¦‚æœæœ‰æ´»è·ƒçš„å·¥å…·è°ƒç”¨ï¼Œå…ˆå®Œæˆå®ƒ
                if self.has_tool_call:
                    # è¡¥å…¨å‚æ•°å¹¶å®Œæˆå·¥å…·è°ƒç”¨
                    self.tool_args += '"'  # è¡¥å…¨æœ€åçš„å¼•å·
                    yield from self._finish_current_tool()

                # å¤„ç†æ–°å·¥å…·è°ƒç”¨
                yield from self._process_metadata_block(block)

    def _process_metadata_block(self, block: str) -> Generator[str, None, None]:
        """å¤„ç†åŒ…å«å·¥å…·å…ƒæ•°æ®çš„å—"""
        try:
            # æå– JSON å†…å®¹
            start_pos = block.find('>')
            end_pos = block.rfind('</glm_block>')

            if start_pos == -1 or end_pos == -1:
                logger.warning(f"âŒ æ— æ³•æ‰¾åˆ° JSON å†…å®¹è¾¹ç•Œ: {block[:1000]}...")
                return

            json_content = block[start_pos + 1:end_pos]
            logger.debug(f"ğŸ“¦ æå–çš„ JSON å†…å®¹: {json_content[:1000]}...")

            # è§£æå·¥å…·å…ƒæ•°æ®
            metadata_obj = json.loads(json_content)

            if "data" in metadata_obj and "metadata" in metadata_obj["data"]:
                metadata = metadata_obj["data"]["metadata"]

                # å¼€å§‹æ–°çš„å·¥å…·è°ƒç”¨
                self.tool_id = metadata.get("id", f"call_{int(time.time() * 1000000)}")
                self.tool_name = metadata.get("name", "unknown")
                self.has_tool_call = True

                # åªæœ‰åœ¨è¿™æ˜¯ç¬¬äºŒä¸ªåŠä»¥åçš„å·¥å…·è°ƒç”¨æ—¶æ‰é€’å¢ index
                # ç¬¬ä¸€ä¸ªå·¥å…·è°ƒç”¨åº”è¯¥ä½¿ç”¨ index 0

                # ä» metadata.arguments è·å–å‚æ•°èµ·å§‹éƒ¨åˆ†
                if "arguments" in metadata:
                    arguments_str = metadata["arguments"]
                    # å»æ‰æœ€åä¸€ä¸ªå­—ç¬¦
                    self.tool_args = arguments_str[:-1] if arguments_str.endswith('"') else arguments_str
                    logger.debug(f"ğŸ¯ æ–°å·¥å…·è°ƒç”¨: {self.tool_name}(id={self.tool_id}), åˆå§‹å‚æ•°: {self.tool_args}")
                else:
                    self.tool_args = "{}"
                    logger.debug(f"ğŸ¯ æ–°å·¥å…·è°ƒç”¨: {self.tool_name}(id={self.tool_id}), ç©ºå‚æ•°")

        except (json.JSONDecodeError, KeyError, AttributeError) as e:
            logger.error(f"âŒ è§£æå·¥å…·å…ƒæ•°æ®å¤±è´¥: {e}, å—å†…å®¹: {block[:1000]}...")

        # ç¡®ä¿è¿”å›ç”Ÿæˆå™¨ï¼ˆå³ä½¿ä¸ºç©ºï¼‰
        if False:  # æ°¸è¿œä¸ä¼šæ‰§è¡Œï¼Œä½†ç¡®ä¿å‡½æ•°æ˜¯ç”Ÿæˆå™¨
            yield

    def _process_other_phase(self, usage: Dict[str, Any], edit_content: str = "") -> Generator[str, None, None]:
        """å¤„ç†å…¶ä»–é˜¶æ®µ"""
        # ä¿å­˜ä½¿ç”¨ç»Ÿè®¡ä¿¡æ¯
        if usage:
            self.tool_call_usage = usage
            logger.debug(f"ğŸ“Š ä¿å­˜ä½¿ç”¨ç»Ÿè®¡: {usage}")

        # å·¥å…·è°ƒç”¨å®Œæˆåˆ¤æ–­ï¼šæ£€æµ‹åˆ° "null," å¼€å¤´çš„ edit_content
        if self.has_tool_call and edit_content and edit_content.startswith("null,"):
            logger.info(f"ğŸ æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨ç»“æŸæ ‡è®°")

            # å®Œæˆå½“å‰å·¥å…·è°ƒç”¨
            yield from self._finish_current_tool()

            # å‘é€æµç»“æŸæ ‡è®°
            if self.stream:
                yield "data: [DONE]\n\n"

            # é‡ç½®çŠ¶æ€
            self._reset_all_state()

    def _process_answer_phase(self, edit_content: str) -> Generator[str, None, None]:
        """å¤„ç†å›ç­”é˜¶æ®µï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
        if not edit_content:
            return

        # æ·»åŠ åˆ°ç¼“å†²åŒº
        self.content_buffer += edit_content
        self.buffer_size += len(edit_content)

        current_time = time.time()
        time_since_last_flush = current_time - self.last_flush_time

        # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ·æ–°ç¼“å†²åŒº
        should_flush = (
            self.buffer_size >= self.max_buffer_size or  # ç¼“å†²åŒºæ»¡äº†
            time_since_last_flush >= self.flush_interval or  # æ—¶é—´é—´éš”åˆ°äº†
            '\n' in edit_content or  # åŒ…å«æ¢è¡Œç¬¦
            'ã€‚' in edit_content or 'ï¼' in edit_content or 'ï¼Ÿ' in edit_content  # åŒ…å«å¥å­ç»“æŸç¬¦
        )

        if should_flush and self.content_buffer:
            yield from self._flush_content_buffer()

    def _flush_content_buffer(self) -> Generator[str, None, None]:
        """åˆ·æ–°å†…å®¹ç¼“å†²åŒº"""
        if not self.content_buffer:
            return

        logger.debug(f"ğŸ’¬ åˆ·æ–°ç¼“å†²åŒº: {self.buffer_size} å­—ç¬¦")

        if self.stream:
            chunk = self._create_content_chunk(self.content_buffer)
            yield f"data: {json.dumps(chunk, ensure_ascii=False)}\n\n"

        # æ¸…ç©ºç¼“å†²åŒº
        self.content_buffer = ""
        self.buffer_size = 0
        self.last_flush_time = time.time()

    def _process_done_phase(self, chunk_data: Dict[str, Any]) -> Generator[str, None, None]:
        """å¤„ç†å®Œæˆé˜¶æ®µ"""
        logger.info("ğŸ å¯¹è¯å®Œæˆ")

        # å…ˆåˆ·æ–°ä»»ä½•å‰©ä½™çš„ç¼“å†²å†…å®¹
        if self.content_buffer:
            yield from self._flush_content_buffer()

        # å®Œæˆä»»ä½•æœªå®Œæˆçš„å·¥å…·è°ƒç”¨
        if self.has_tool_call:
            yield from self._finish_current_tool()

        # å‘é€æµç»“æŸæ ‡è®°
        if self.stream:
            # åˆ›å»ºæœ€ç»ˆçš„å®Œæˆå—
            final_chunk = {
                "id": f"chatcmpl-{int(time.time())}",
                "object": "chat.completion.chunk",
                "created": int(time.time()),
                "model": self.model,
                "choices": [{
                    "index": 0,
                    "delta": {},
                    "finish_reason": "stop"
                }]
            }

            # å¦‚æœæœ‰ usage ä¿¡æ¯ï¼Œæ·»åŠ åˆ°æœ€ç»ˆå—ä¸­
            if "usage" in chunk_data:
                final_chunk["usage"] = chunk_data["usage"]

            yield f"data: {json.dumps(final_chunk, ensure_ascii=False)}\n\n"
            yield "data: [DONE]\n\n"

        # é‡ç½®æ‰€æœ‰çŠ¶æ€
        self._reset_all_state()

    def _finish_current_tool(self) -> Generator[str, None, None]:
        """å®Œæˆå½“å‰å·¥å…·è°ƒç”¨"""
        if not self.has_tool_call:
            return

        # ä¿®å¤å‚æ•°æ ¼å¼
        fixed_args = self._fix_tool_arguments(self.tool_args)
        logger.debug(f"âœ… å®Œæˆå·¥å…·è°ƒç”¨: {self.tool_name}, å‚æ•°: {fixed_args}")

        # è¾“å‡ºå·¥å…·è°ƒç”¨ï¼ˆå¼€å§‹ + å‚æ•° + å®Œæˆï¼‰
        if self.stream:
            # å‘é€å·¥å…·å¼€å§‹å—
            start_chunk = self._create_tool_start_chunk()
            yield f"data: {json.dumps(start_chunk, ensure_ascii=False)}\n\n"

            # å‘é€å‚æ•°å—
            args_chunk = self._create_tool_arguments_chunk(fixed_args)
            yield f"data: {json.dumps(args_chunk, ensure_ascii=False)}\n\n"

            # å‘é€å®Œæˆå—
            finish_chunk = self._create_tool_finish_chunk()
            yield f"data: {json.dumps(finish_chunk, ensure_ascii=False)}\n\n"

        # é‡ç½®å·¥å…·çŠ¶æ€
        self._reset_tool_state()

    def _fix_tool_arguments(self, raw_args: str) -> str:
        """ä½¿ç”¨ json-repair åº“ä¿®å¤å·¥å…·å‚æ•°æ ¼å¼"""
        if not raw_args or raw_args == "{}":
            return "{}"

        logger.debug(f"ğŸ”§ å¼€å§‹ä¿®å¤å‚æ•°: {raw_args[:1000]}{'...' if len(raw_args) > 1000 else ''}")

        # å°è¯•ç›´æ¥è§£æ
        try:
            args_obj = json.loads(raw_args)
            result = json.dumps(args_obj, ensure_ascii=False)
            logger.debug(f"âœ… å‚æ•°æ— éœ€ä¿®å¤: {result}")
            return result
        except json.JSONDecodeError:
            pass

        # é¢„å¤„ç†ï¼šæå–çº¯ JSON éƒ¨åˆ†å’Œä¿®å¤è½¬ä¹‰å¼•å·
        processed_args = self._preprocess_json_string(raw_args.strip())

        # ä½¿ç”¨ json-repair åº“è¿›è¡Œä¿®å¤
        from json_repair import repair_json

        try:
            repaired_json = repair_json(processed_args)
            logger.debug(f"ğŸ”§ json-repair ä¿®å¤ç»“æœ: {repaired_json}")

            # éªŒè¯ä¿®å¤ç»“æœ
            args_obj = json.loads(repaired_json)
            fixed_result = json.dumps(args_obj, ensure_ascii=False)

            # è®°å½•ä¿®å¤å‰åå¯¹æ¯”
            logger.info(f"âœ… JSON ä¿®å¤æˆåŠŸ:")
            logger.info(f"   ä¿®å¤å‰: {raw_args[:1000]}{'...' if len(raw_args) > 1000 else ''}")
            logger.info(f"   ä¿®å¤å: {fixed_result}")

            return fixed_result

        except Exception as e:
            logger.error(f"âŒ JSON ä¿®å¤å¤±è´¥: {e}, åŸå§‹å‚æ•°: {raw_args[:1000]}..., ä½¿ç”¨ç©ºå‚æ•°")
            return "{}"

    def _preprocess_json_string(self, text: str) -> str:
        """é¢„å¤„ç† JSON å­—ç¬¦ä¸²ï¼Œä¿®å¤è½¬ä¹‰å¼•å·å’Œæå–çº¯ JSON éƒ¨åˆ†"""
        import re

        # 1. å¦‚æœåŒ…å«é¢å¤–å†…å®¹ï¼ˆå¦‚ "result" å­—æ®µï¼‰ï¼Œæå–çº¯ JSON éƒ¨åˆ†
        if '"result"' in text:
            brace_count = 0
            json_end = -1
            for i, char in enumerate(text):
                if char == '{':
                    brace_count += 1
                elif char == '}':
                    brace_count -= 1
                    if brace_count == 0:
                        json_end = i + 1
                        break

            if json_end > 0:
                text = text[:json_end]
                logger.debug(f"ğŸ”§ æå–çº¯ JSON éƒ¨åˆ†: {text[:1000]}...")

        # 2. ä¿®å¤ç¼ºå°‘å¼€å§‹æ‹¬å·çš„æƒ…å†µ
        if not text.startswith('{') and text.endswith('}'):
            text = '{' + text
            logger.debug(f"ğŸ”§ è¡¥å…¨å¼€å§‹æ‹¬å·")

        # 3. ä¿®å¤è½¬ä¹‰å¼•å·é—®é¢˜
        # å¤„ç† "key:\"value\"," æ¨¡å¼ -> "key":"value",
        pattern = r'(["\w]+):\\"([^"\\]*)\\"'
        if re.search(pattern, text):
            text = re.sub(pattern, r'\1:"\2"', text)
            logger.debug(f"ğŸ”§ ä¿®å¤å­—æ®µè½¬ä¹‰å¼•å·æ¨¡å¼")

        # å¤„ç†å‰©ä½™çš„è½¬ä¹‰å¼•å· \" -> "
        if '\\"' in text:
            text = text.replace('\\"', '"')
            logger.debug(f"ğŸ”§ æ›¿æ¢å‰©ä½™è½¬ä¹‰å¼•å·")

        return text

    def _create_content_chunk(self, content: str) -> Dict[str, Any]:
        """åˆ›å»ºå†…å®¹å—"""
        return {
            "id": f"chatcmpl-{int(time.time())}",
            "object": "chat.completion.chunk",
            "created": int(time.time()),
            "model": self.model,
            "choices": [{
                "index": 0,
                "delta": {
                    "role": "assistant",
                    "content": content
                },
                "finish_reason": None
            }]
        }

    def _create_tool_start_chunk(self) -> Dict[str, Any]:
        """åˆ›å»ºå·¥å…·å¼€å§‹å—"""
        return {
            "id": f"chatcmpl-{int(time.time())}",
            "object": "chat.completion.chunk", 
            "created": int(time.time()),
            "model": self.model,
            "choices": [{
                "index": 0,
                "delta": {
                    "role": "assistant",
                    "tool_calls": [{
                        "index": self.content_index,
                        "id": self.tool_id,
                        "type": "function",
                        "function": {
                            "name": self.tool_name,
                            "arguments": ""
                        }
                    }]
                },
                "finish_reason": None
            }]
        }

    def _create_tool_arguments_chunk(self, arguments: str) -> Dict[str, Any]:
        """åˆ›å»ºå·¥å…·å‚æ•°å—"""
        return {
            "id": f"chatcmpl-{int(time.time())}",
            "object": "chat.completion.chunk",
            "created": int(time.time()),
            "model": self.model,
            "choices": [{
                "index": 0,
                "delta": {
                    "tool_calls": [{
                        "index": self.content_index,
                        "id": self.tool_id,
                        "function": {
                            "arguments": arguments
                        }
                    }]
                },
                "finish_reason": None
            }]
        }

    def _create_tool_finish_chunk(self) -> Dict[str, Any]:
        """åˆ›å»ºå·¥å…·å®Œæˆå—"""
        chunk = {
            "id": f"chatcmpl-{int(time.time())}",
            "object": "chat.completion.chunk",
            "created": int(time.time()),
            "model": self.model,
            "choices": [{
                "index": 0,
                "delta": {
                    "tool_calls": []
                },
                "finish_reason": "tool_calls"
            }]
        }
        
        # æ·»åŠ ä½¿ç”¨ç»Ÿè®¡ï¼ˆå¦‚æœæœ‰ï¼‰
        if self.tool_call_usage:
            chunk["usage"] = self.tool_call_usage
            
        return chunk

    def _reset_tool_state(self):
        """é‡ç½®å·¥å…·çŠ¶æ€"""
        self.tool_id = ""
        self.tool_name = ""
        self.tool_args = ""
        self.has_tool_call = False
        # content_index åœ¨å•æ¬¡å¯¹è¯ä¸­åº”è¯¥ä¿æŒä¸å˜ï¼Œåªæœ‰åœ¨æ–°çš„å·¥å…·è°ƒç”¨å¼€å§‹æ—¶æ‰é€’å¢

    def _reset_all_state(self):
        """é‡ç½®æ‰€æœ‰çŠ¶æ€"""
        # å…ˆåˆ·æ–°ä»»ä½•å‰©ä½™çš„ç¼“å†²å†…å®¹
        if hasattr(self, 'content_buffer') and self.content_buffer:
            list(self._flush_content_buffer())  # æ¶ˆè´¹ç”Ÿæˆå™¨

        self._reset_tool_state()
        self.current_phase = None
        self.tool_call_usage = {}

        # é‡ç½®ç¼“å†²åŒº
        self.content_buffer = ""
        self.buffer_size = 0
        self.last_flush_time = time.time()

        # content_index é‡ç½®ä¸º 0ï¼Œä¸ºä¸‹ä¸€è½®å¯¹è¯åšå‡†å¤‡
        self.content_index = 0
        logger.debug("ğŸ”„ é‡ç½®æ‰€æœ‰å¤„ç†å™¨çŠ¶æ€")
