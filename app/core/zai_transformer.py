#!/usr/bin/env python
# -*- coding: utf-8 -*-

import json
import time
import uuid
import random
import requests
from datetime import datetime
from typing import Dict, List, Any, Optional, Generator, AsyncGenerator
import httpx
import asyncio
from fake_useragent import UserAgent

from app.core.config import settings
from app.utils.logger import get_logger
from app.utils.token_pool import get_token_pool, initialize_token_pool

logger = get_logger()

# å…¨å±€ UserAgent å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
_user_agent_instance = None


def get_user_agent_instance() -> UserAgent:
    """è·å–æˆ–åˆ›å»º UserAgent å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    global _user_agent_instance
    if _user_agent_instance is None:
        _user_agent_instance = UserAgent()
    return _user_agent_instance


def get_dynamic_headers(chat_id: str = "") -> Dict[str, str]:
    """ç”ŸæˆåŠ¨æ€æµè§ˆå™¨headersï¼ŒåŒ…å«éšæœºUser-Agent"""
    ua = get_user_agent_instance()

    # éšæœºé€‰æ‹©æµè§ˆå™¨ç±»å‹ï¼Œåå‘Chromeå’ŒEdge
    browser_choices = ["chrome", "chrome", "chrome", "edge", "edge", "firefox", "safari"]
    browser_type = random.choice(browser_choices)

    try:
        if browser_type == "chrome":
            user_agent = ua.chrome
        elif browser_type == "edge":
            user_agent = ua.edge
        elif browser_type == "firefox":
            user_agent = ua.firefox
        elif browser_type == "safari":
            user_agent = ua.safari
        else:
            user_agent = ua.random
    except:
        user_agent = ua.random

    # æå–ç‰ˆæœ¬ä¿¡æ¯
    chrome_version = "139"
    edge_version = "139"

    if "Chrome/" in user_agent:
        try:
            chrome_version = user_agent.split("Chrome/")[1].split(".")[0]
        except:
            pass

    if "Edg/" in user_agent:
        try:
            edge_version = user_agent.split("Edg/")[1].split(".")[0]
            sec_ch_ua = f'"Microsoft Edge";v="{edge_version}", "Chromium";v="{chrome_version}", "Not_A Brand";v="24"'
        except:
            sec_ch_ua = f'"Not_A Brand";v="8", "Chromium";v="{chrome_version}", "Google Chrome";v="{chrome_version}"'
    elif "Firefox/" in user_agent:
        sec_ch_ua = None  # Firefoxä¸ä½¿ç”¨sec-ch-ua
    else:
        sec_ch_ua = f'"Not_A Brand";v="8", "Chromium";v="{chrome_version}", "Google Chrome";v="{chrome_version}"'

    headers = {
        "Content-Type": "application/json",
        "Accept": "application/json, text/event-stream",
        "User-Agent": user_agent,
        "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
        "X-FE-Version": "prod-fe-1.0.79",
        "Origin": "https://chat.z.ai",
    }

    if sec_ch_ua:
        headers["sec-ch-ua"] = sec_ch_ua
        headers["sec-ch-ua-mobile"] = "?0"
        headers["sec-ch-ua-platform"] = '"Windows"'

    if chat_id:
        headers["Referer"] = f"https://chat.z.ai/c/{chat_id}"
    else:
        headers["Referer"] = "https://chat.z.ai/"

    return headers


def generate_uuid() -> str:
    """ç”ŸæˆUUID v4"""
    return str(uuid.uuid4())


def get_auth_token_sync() -> str:
    """åŒæ­¥è·å–è®¤è¯ä»¤ç‰Œï¼ˆç”¨äºéå¼‚æ­¥åœºæ™¯ï¼‰"""
    if settings.ANONYMOUS_MODE:
        try:
            headers = get_dynamic_headers()
            response = requests.get("https://chat.z.ai/api/v1/auths/", headers=headers, timeout=10)
            if response.status_code == 200:
                data = response.json()
                token = data.get("token", "")
                if token:
                    logger.debug(f"è·å–è®¿å®¢ä»¤ç‰ŒæˆåŠŸ: {token[:20]}...")
                    return token
        except Exception as e:
            logger.warning(f"è·å–è®¿å®¢ä»¤ç‰Œå¤±è´¥: {e}")

    # ä½¿ç”¨tokenæ± è·å–å¤‡ä»½ä»¤ç‰Œ
    token_pool = get_token_pool()
    if token_pool:
        token = token_pool.get_next_token()
        if token:
            logger.debug(f"ä»tokenæ± è·å–ä»¤ç‰Œ: {token[:20]}...")
            return token

    # æ²¡æœ‰å¯ç”¨çš„token
    logger.warning("âš ï¸ æ²¡æœ‰å¯ç”¨çš„å¤‡ä»½token")
    return ""


class ZAITransformer:
    """ZAIè½¬æ¢å™¨ç±»"""

    def __init__(self):
        """åˆå§‹åŒ–è½¬æ¢å™¨"""
        self.name = "zai"
        self.base_url = "https://chat.z.ai"
        self.api_url = settings.API_ENDPOINT
        self.auth_url = f"{self.base_url}/api/v1/auths/"

        # æ¨¡å‹æ˜ å°„
        self.model_mapping = {
            settings.PRIMARY_MODEL: "0727-360B-API",  # GLM-4.5
            settings.THINKING_MODEL: "0727-360B-API",  # GLM-4.5-Thinking
            settings.SEARCH_MODEL: "0727-360B-API",  # GLM-4.5-Search
            settings.AIR_MODEL: "0727-106B-API",  # GLM-4.5-Air
        }

    async def get_token(self) -> str:
        """å¼‚æ­¥è·å–è®¤è¯ä»¤ç‰Œ"""
        if settings.ANONYMOUS_MODE:
            try:
    
                headers = get_dynamic_headers()
                async with httpx.AsyncClient() as client:
                    response = await client.get(self.auth_url, headers=headers, timeout=10.0)
                    if response.status_code == 200:
                        data = response.json()
                        token = data.get("token", "")
                        if token:
                            logger.debug(f"è·å–è®¿å®¢ä»¤ç‰ŒæˆåŠŸ: {token[:20]}...")
                            return token
            except Exception as e:
                logger.warning(f"å¼‚æ­¥è·å–è®¿å®¢ä»¤ç‰Œå¤±è´¥: {e}")

        # ä½¿ç”¨tokenæ± è·å–å¤‡ä»½ä»¤ç‰Œ
        token_pool = get_token_pool()
        if token_pool:
            token = token_pool.get_next_token()
            if token:
                logger.debug(f"ä»tokenæ± è·å–ä»¤ç‰Œ: {token[:20]}...")
                return token

        # æ²¡æœ‰å¯ç”¨çš„token
        logger.warning("âš ï¸ æ²¡æœ‰å¯ç”¨çš„å¤‡ä»½token")
        return ""

    def mark_token_success(self, token: str):
        """æ ‡è®°tokenä½¿ç”¨æˆåŠŸ"""
        token_pool = get_token_pool()
        if token_pool:
            token_pool.mark_token_success(token)

    def mark_token_failure(self, token: str, error: Exception = None):
        """æ ‡è®°tokenä½¿ç”¨å¤±è´¥"""
        token_pool = get_token_pool()
        if token_pool:
            token_pool.mark_token_failure(token, error)

    async def transform_request_in(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """
        è½¬æ¢OpenAIè¯·æ±‚ä¸ºz.aiæ ¼å¼
        æ•´åˆç°æœ‰åŠŸèƒ½ï¼šæ¨¡å‹æ˜ å°„ã€MCPæœåŠ¡å™¨ç­‰
        """
        logger.info(f"ğŸ”„ å¼€å§‹è½¬æ¢ OpenAI è¯·æ±‚åˆ° Z.AI æ ¼å¼: {request.get('model', settings.PRIMARY_MODEL)} -> Z.AI")

        # è·å–è®¤è¯ä»¤ç‰Œ
        token = await self.get_token()
        logger.debug(f"  ä½¿ç”¨ä»¤ç‰Œ: {token[:20] if token else 'None'}...")

        # æ£€æŸ¥tokenæ˜¯å¦æœ‰æ•ˆ
        if not token:
            logger.error("âŒ æ— æ³•è·å–æœ‰æ•ˆçš„è®¤è¯ä»¤ç‰Œ")
            raise Exception("æ— æ³•è·å–æœ‰æ•ˆçš„è®¤è¯ä»¤ç‰Œï¼Œè¯·æ£€æŸ¥åŒ¿åæ¨¡å¼é…ç½®æˆ–tokenæ± é…ç½®")

        # ç¡®å®šè¯·æ±‚çš„æ¨¡å‹ç‰¹æ€§
        requested_model = request.get("model", settings.PRIMARY_MODEL)
        is_thinking = requested_model == settings.THINKING_MODEL or request.get("reasoning", False)
        is_search = requested_model == settings.SEARCH_MODEL
        is_air = requested_model == settings.AIR_MODEL

        # è·å–ä¸Šæ¸¸æ¨¡å‹IDï¼ˆä½¿ç”¨æ¨¡å‹æ˜ å°„ï¼‰
        upstream_model_id = self.model_mapping.get(requested_model, "0727-360B-API")
        logger.debug(f"  æ¨¡å‹æ˜ å°„: {requested_model} -> {upstream_model_id}")
        logger.debug(f"  æ¨¡å‹ç‰¹æ€§æ£€æµ‹: is_search={is_search}, is_thinking={is_thinking}, is_air={is_air}")
        logger.debug(f"  SEARCH_MODELé…ç½®: {settings.SEARCH_MODEL}")

        # å¤„ç†æ¶ˆæ¯åˆ—è¡¨
        logger.debug(f"  å¼€å§‹å¤„ç† {len(request.get('messages', []))} æ¡æ¶ˆæ¯")
        messages = []
        for idx, orig_msg in enumerate(request.get("messages", [])):
            msg = orig_msg.copy()

            # å¤„ç†systemè§’è‰²è½¬æ¢
            if msg.get("role") == "system":

                msg["role"] = "user"
                content = msg.get("content")

                if isinstance(content, list):
                    msg["content"] = [
                        {"type": "text", "text": "This is a system command, you must enforce compliance."}
                    ] + content
                elif isinstance(content, str):
                    msg["content"] = f"This is a system command, you must enforce compliance.{content}"

            # å¤„ç†userè§’è‰²çš„å›¾ç‰‡å†…å®¹
            elif msg.get("role") == "user":
                content = msg.get("content")
                if isinstance(content, list):
                    new_content = []
                    for part_idx, part in enumerate(content):
                        # å¤„ç†å›¾ç‰‡URLï¼ˆæ”¯æŒbase64å’Œhttp URLï¼‰
                        if (
                            part.get("type") == "image_url"
                            and part.get("image_url", {}).get("url")
                            and isinstance(part["image_url"]["url"], str)
                        ):
                            logger.debug(f"    æ¶ˆæ¯[{idx}]å†…å®¹[{part_idx}]: æ£€æµ‹åˆ°å›¾ç‰‡URL")
                            # ç›´æ¥ä¼ é€’å›¾ç‰‡å†…å®¹
                            new_content.append(part)
                        else:
                            new_content.append(part)
                    msg["content"] = new_content

            # å¤„ç†assistantæ¶ˆæ¯ä¸­çš„reasoning_content
            elif msg.get("role") == "assistant" and msg.get("reasoning_content"):

                # å¦‚æœæœ‰reasoning_contentï¼Œä¿ç•™å®ƒ
                pass

            messages.append(msg)

        # æ„å»ºMCPæœåŠ¡å™¨åˆ—è¡¨
        mcp_servers = []
        if is_search:
            mcp_servers.append("deep-web-search")
            logger.info(f"ğŸ” æ£€æµ‹åˆ°æœç´¢æ¨¡å‹ï¼Œæ·»åŠ  deep-web-search MCP æœåŠ¡å™¨")
        else:
            logger.debug(f"  éæœç´¢æ¨¡å‹ï¼Œä¸æ·»åŠ  MCP æœåŠ¡å™¨")

        logger.debug(f"  MCPæœåŠ¡å™¨åˆ—è¡¨: {mcp_servers}")
            
        # æ„å»ºä¸Šæ¸¸è¯·æ±‚ä½“
        chat_id = generate_uuid()
        
        body = {
            "stream": True,  # æ€»æ˜¯ä½¿ç”¨æµå¼
            "model": upstream_model_id,  # ä½¿ç”¨æ˜ å°„åçš„æ¨¡å‹ID
            "messages": messages,
            "params": {},
            "features": {
                "image_generation": False,
                "web_search": is_search,
                "auto_web_search": is_search,
                "preview_mode": False,
                "flags": [],
                "features": [],
                "enable_thinking": is_thinking,
            },
            "background_tasks": {
                "title_generation": False,
                "tags_generation": False,
            },
            "mcp_servers": mcp_servers,  # ä¿ç•™MCPæœåŠ¡å™¨æ”¯æŒ
            "variables": {
                "{{USER_NAME}}": "Guest",
                "{{USER_LOCATION}}": "Unknown",
                "{{CURRENT_DATETIME}}": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "{{CURRENT_DATE}}": datetime.now().strftime("%Y-%m-%d"),
                "{{CURRENT_TIME}}": datetime.now().strftime("%H:%M:%S"),
                "{{CURRENT_WEEKDAY}}": datetime.now().strftime("%A"),
                "{{CURRENT_TIMEZONE}}": "UTC",
                "{{USER_LANGUAGE}}": "zh-CN",
            },
            "model_item": {},
            "chat_id": chat_id,
            "id": generate_uuid(),
        }

        # å¤„ç†å·¥å…·æ”¯æŒ
        if settings.TOOL_SUPPORT and not is_thinking and request.get("tools"):
            body["tools"] = request["tools"]
            logger.info(f"å¯ç”¨å·¥å…·æ”¯æŒ: {len(request['tools'])} ä¸ªå·¥å…·")
        else:
            body["tools"] = None

        # æ„å»ºè¯·æ±‚é…ç½®
        dynamic_headers = get_dynamic_headers(chat_id)

        config = {
            "url": self.api_url,  # ä½¿ç”¨åŸå§‹URL
            "headers": {
                **dynamic_headers,  # ä½¿ç”¨åŠ¨æ€ç”Ÿæˆçš„headers
                "Authorization": f"Bearer {token}",
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "Pragma": "no-cache",
                "Sec-Fetch-Dest": "empty",
                "Sec-Fetch-Mode": "cors",
                "Sec-Fetch-Site": "same-origin",
            },
        }

        logger.info("âœ… è¯·æ±‚è½¬æ¢å®Œæˆ")

        # è®°å½•å…³é”®çš„è¯·æ±‚ä¿¡æ¯ç”¨äºè°ƒè¯•
        logger.debug(f"  ğŸ“‹ å‘é€åˆ°Z.AIçš„å…³é”®ä¿¡æ¯:")
        logger.debug(f"    - ä¸Šæ¸¸æ¨¡å‹: {body['model']}")
        logger.debug(f"    - MCPæœåŠ¡å™¨: {body['mcp_servers']}")
        logger.debug(f"    - web_search: {body['features']['web_search']}")
        logger.debug(f"    - auto_web_search: {body['features']['auto_web_search']}")
        logger.debug(f"    - æ¶ˆæ¯æ•°é‡: {len(body['messages'])}")

        return {"body": body, "config": config, "token": token}

    async def transform_response_out(
        self, response_stream: Generator, context: Dict[str, Any]
    ) -> Generator[str, None, None]:
        """
        è½¬æ¢z.aiå“åº”ä¸ºOpenAIæ ¼å¼
        æ”¯æŒæµå¼å’Œéæµå¼è¾“å‡º
        """
        is_stream = context.get("req", {}).get("body", {}).get("stream", True)

        # åˆå§‹åŒ–ç»“æœå¯¹è±¡ï¼ˆç”¨äºéæµå¼ï¼‰
        result = {
            "id": "",
            "choices": [
                {
                    "finish_reason": None,
                    "index": 0,
                    "message": {
                        "content": "",
                        "role": "assistant",
                    },
                }
            ],
            "created": int(time.time()),
            "model": context.get("req", {}).get("body", {}).get("model", ""),
            "object": "chat.completion",
            "usage": {
                "completion_tokens": 0,
                "prompt_tokens": 0,
                "total_tokens": 0,
            },
        }

        # çŠ¶æ€å˜é‡
        current_id = ""
        current_model = context.get("req", {}).get("body", {}).get("model", "")
        has_tool_call = False
        tool_args = ""
        tool_id = ""
        tool_call_usage = None
        content_index = 0
        has_thinking = False

        async for line in response_stream:
            if not line.strip():
                continue

            if line.startswith("data:"):
                chunk_str = line[5:].strip()
                if not chunk_str:
                    continue

                try:
                    chunk = json.loads(chunk_str)

                    if chunk.get("type") == "chat:completion":
                        data = chunk.get("data", {})

                        # ä¿å­˜IDå’Œæ¨¡å‹ä¿¡æ¯
                        if data.get("id"):
                            current_id = data["id"]
                        if data.get("model"):
                            current_model = data["model"]

                        # å¤„ç†ä¸åŒé˜¶æ®µ
                        phase = data.get("phase")

                        if phase == "tool_call":
                            # å¤„ç†å·¥å…·è°ƒç”¨
                            if not has_tool_call:
                                has_tool_call = True

                                if is_stream:
                                    # å‘é€åˆå§‹è§’è‰²
                                    role_chunk = {
                                        "choices": [
                                            {
                                                "delta": {"role": "assistant"},
                                                "finish_reason": None,
                                                "index": 0,
                                            }
                                        ],
                                        "created": int(time.time()),
                                        "id": current_id,
                                        "model": current_model,
                                        "object": "chat.completion.chunk",
                                    }
                                    yield f"data: {json.dumps(role_chunk)}\n\n"

                            # å¤„ç†å·¥å…·è°ƒç”¨å—
                            tool_call_id = data.get("tool_call", {}).get("id", "")
                            tool_name = data.get("tool_call", {}).get("name", "")
                            delta_args = data.get("delta_tool_call", {}).get("arguments", "")

                            if tool_call_id and tool_call_id != tool_id:
                                # æ–°å·¥å…·è°ƒç”¨
                                if tool_id and is_stream:
                                    # å…³é—­å‰ä¸€ä¸ªå·¥å…·è°ƒç”¨
                                    close_chunk = {
                                        "choices": [
                                            {
                                                "delta": {
                                                    "tool_calls": [
                                                        {"index": content_index, "function": {"arguments": ""}}
                                                    ]
                                                },
                                                "finish_reason": None,
                                                "index": 0,
                                            }
                                        ],
                                        "created": int(time.time()),
                                        "id": current_id,
                                        "model": current_model,
                                        "object": "chat.completion.chunk",
                                    }
                                    yield f"data: {json.dumps(close_chunk)}\n\n"
                                    content_index += 1

                                tool_id = tool_call_id
                                tool_args = ""

                                if is_stream:
                                    # å‘é€æ–°å·¥å…·è°ƒç”¨
                                    new_tool_chunk = {
                                        "choices": [
                                            {
                                                "delta": {
                                                    "tool_calls": [
                                                        {
                                                            "index": content_index,
                                                            "id": tool_call_id,
                                                            "type": "function",
                                                            "function": {"name": tool_name, "arguments": ""},
                                                        }
                                                    ]
                                                },
                                                "finish_reason": None,
                                                "index": 0,
                                            }
                                        ],
                                        "created": int(time.time()),
                                        "id": current_id,
                                        "model": current_model,
                                        "object": "chat.completion.chunk",
                                    }
                                    yield f"data: {json.dumps(new_tool_chunk)}\n\n"

                            # å¤„ç†å‚æ•°å¢é‡
                            if delta_args:
                                tool_args += delta_args
                                if is_stream:
                                    args_chunk = {
                                        "choices": [
                                            {
                                                "delta": {
                                                    "tool_calls": [
                                                        {
                                                            "index": content_index,
                                                            "function": {"arguments": delta_args},
                                                        }
                                                    ]
                                                },
                                                "finish_reason": None,
                                                "index": 0,
                                            }
                                        ],
                                        "created": int(time.time()),
                                        "id": current_id,
                                        "model": current_model,
                                        "object": "chat.completion.chunk",
                                    }
                                    yield f"data: {json.dumps(args_chunk)}\n\n"

                        elif phase == "thinking":
                            # å¤„ç†æ€è€ƒå†…å®¹
                            if not has_thinking:
                                has_thinking = True
                                # åˆå§‹åŒ–thinkingå­—æ®µ
                                if not is_stream:
                                    result["choices"][0]["message"]["thinking"] = {"content": ""}

                                if is_stream:
                                    # å‘é€åˆå§‹è§’è‰²
                                    role_chunk = {
                                        "choices": [
                                            {
                                                "delta": {"role": "assistant"},
                                                "finish_reason": None,
                                                "index": 0,
                                            }
                                        ],
                                        "created": int(time.time()),
                                        "id": current_id,
                                        "model": current_model,
                                        "object": "chat.completion.chunk",
                                    }
                                    yield f"data: {json.dumps(role_chunk)}\n\n"

                            delta_content = data.get("delta_content", "")
                            if delta_content:
                                # å¤„ç†æ€è€ƒå†…å®¹æ ¼å¼
                                if delta_content.startswith("<details"):
                                    content = (
                                        delta_content.split("</summary>\n>")[-1].strip()
                                        if "</summary>\n>" in delta_content
                                        else delta_content
                                    )
                                else:
                                    content = delta_content

                                if is_stream:
                                    thinking_chunk = {
                                        "choices": [
                                            {
                                                "delta": {"thinking": {"content": content}},
                                                "finish_reason": None,
                                                "index": 0,
                                            }
                                        ],
                                        "created": int(time.time()),
                                        "id": current_id,
                                        "model": current_model,
                                        "object": "chat.completion.chunk",
                                    }
                                    yield f"data: {json.dumps(thinking_chunk)}\n\n"
                                else:
                                    result["choices"][0]["message"]["thinking"]["content"] += content

                        elif phase == "answer":
                            # å¤„ç†ç­”æ¡ˆå†…å®¹
                            edit_content = data.get("edit_content", "")
                            delta_content = data.get("delta_content", "")

                            # å¤„ç†æ€è€ƒç»“æŸå’Œç­”æ¡ˆå¼€å§‹
                            if edit_content and "</details>\n" in edit_content:
                                if has_thinking:
                                    signature = str(int(time.time() * 1000))

                                    if is_stream:
                                        # å‘é€æ€è€ƒç­¾å
                                        sig_chunk = {
                                            "choices": [
                                                {
                                                    "delta": {
                                                        "role": "assistant",
                                                        "thinking": {"content": "", "signature": signature},
                                                    },
                                                    "finish_reason": None,
                                                    "index": 0,
                                                }
                                            ],
                                            "created": int(time.time()),
                                            "id": current_id,
                                            "model": current_model,
                                            "object": "chat.completion.chunk",
                                        }
                                        yield f"data: {json.dumps(sig_chunk)}\n\n"
                                        content_index += 1
                                    else:
                                        result["choices"][0]["message"]["thinking"]["signature"] = signature

                                # æå–ç­”æ¡ˆå†…å®¹
                                content_after = edit_content.split("</details>\n")[-1]
                                if content_after:
                                    if is_stream:
                                        content_chunk = {
                                            "choices": [
                                                {
                                                    "delta": {"role": "assistant", "content": content_after},
                                                    "finish_reason": None,
                                                    "index": 0,
                                                }
                                            ],
                                            "created": int(time.time()),
                                            "id": current_id,
                                            "model": current_model,
                                            "object": "chat.completion.chunk",
                                        }
                                        yield f"data: {json.dumps(content_chunk)}\n\n"
                                    else:
                                        result["choices"][0]["message"]["content"] += content_after

                            # å¤„ç†å¢é‡å†…å®¹
                            elif delta_content:
                                if is_stream:
                                    # å¦‚æœè¿˜æ²¡æœ‰å‘é€è§’è‰²
                                    if not has_thinking and not has_tool_call:
                                        role_chunk = {
                                            "choices": [
                                                {
                                                    "delta": {"role": "assistant"},
                                                    "finish_reason": None,
                                                    "index": 0,
                                                }
                                            ],
                                            "created": int(time.time()),
                                            "id": current_id,
                                            "model": current_model,
                                            "object": "chat.completion.chunk",
                                        }
                                        yield f"data: {json.dumps(role_chunk)}\n\n"

                                    content_chunk = {
                                        "choices": [
                                            {
                                                "delta": {"role": "assistant", "content": delta_content},
                                                "finish_reason": None,
                                                "index": 0,
                                            }
                                        ],
                                        "created": int(time.time()),
                                        "id": current_id,
                                        "model": current_model,
                                        "object": "chat.completion.chunk",
                                    }
                                    yield f"data: {json.dumps(content_chunk)}\n\n"
                                else:
                                    result["choices"][0]["message"]["content"] += delta_content

                            # å¤„ç†å®Œæˆ
                            if data.get("usage"):
                                usage = data["usage"]
                                if is_stream:
                                    finish_chunk = {
                                        "choices": [
                                            {
                                                "delta": {"role": "assistant", "content": ""},
                                                "finish_reason": "stop",
                                                "index": 0,
                                            }
                                        ],
                                        "usage": usage,
                                        "created": int(time.time()),
                                        "id": current_id,
                                        "model": current_model,
                                        "object": "chat.completion.chunk",
                                    }
                                    yield f"data: {json.dumps(finish_chunk)}\n\n"
                                    yield "data: [DONE]\n\n"
                                else:
                                    result["id"] = current_id
                                    result["model"] = current_model
                                    result["usage"] = usage
                                    result["choices"][0]["finish_reason"] = "stop"

                        elif phase == "other":
                            # å¤„ç†å…¶ä»–é˜¶æ®µï¼ˆå¯èƒ½åŒ…å«usageä¿¡æ¯ï¼‰
                            if data.get("usage"):
                                tool_call_usage = data["usage"]
                                if has_tool_call and is_stream:
                                    # å…³é—­æœ€åä¸€ä¸ªå·¥å…·è°ƒç”¨å¹¶å‘é€å®Œæˆ
                                    if tool_id:
                                        close_chunk = {
                                            "choices": [
                                                {
                                                    "delta": {
                                                        "tool_calls": [
                                                            {"index": content_index, "function": {"arguments": ""}}
                                                        ]
                                                    },
                                                    "finish_reason": "tool_calls",
                                                    "index": 0,
                                                }
                                            ],
                                            "usage": tool_call_usage,
                                            "created": int(time.time()),
                                            "id": current_id,
                                            "model": current_model,
                                            "object": "chat.completion.chunk",
                                        }
                                        yield f"data: {json.dumps(close_chunk)}\n\n"
                                        yield "data: [DONE]\n\n"

                except json.JSONDecodeError as e:
                    logger.debug(f"JSONè§£æé”™è¯¯: {e}")
                except Exception as e:
                    logger.error(f"å¤„ç†chunké”™è¯¯: {e}")

        # éæµå¼æ¨¡å¼è¿”å›å®Œæ•´ç»“æœ
        if not is_stream:
            yield json.dumps(result)
