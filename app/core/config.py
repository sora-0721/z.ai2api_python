#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
from typing import Dict, List, Optional
from pydantic_settings import BaseSettings
from app.utils.logger import logger


class Settings(BaseSettings):
    """Application settings"""

    # API Configuration
    API_ENDPOINT: str = "https://chat.z.ai/api/chat/completions"
    AUTH_TOKEN: str = os.getenv("AUTH_TOKEN", "sk-your-api-key")

    # ËÆ§ËØÅtokenÊñá‰ª∂Ë∑ØÂæÑÔºàÂèØÈÄâÔºâ
    AUTH_TOKENS_FILE: Optional[str] = os.getenv("AUTH_TOKENS_FILE")

    # TokenÊ±†ÈÖçÁΩÆ
    TOKEN_HEALTH_CHECK_INTERVAL: int = int(os.getenv("TOKEN_HEALTH_CHECK_INTERVAL", "300"))  # 5ÂàÜÈíü
    TOKEN_FAILURE_THRESHOLD: int = int(os.getenv("TOKEN_FAILURE_THRESHOLD", "3"))  # Â§±Ë¥•3Ê¨°ÂêéÊ†áËÆ∞‰∏∫‰∏çÂèØÁî®
    TOKEN_RECOVERY_TIMEOUT: int = int(os.getenv("TOKEN_RECOVERY_TIMEOUT", "1800"))  # 30ÂàÜÈíüÂêéÈáçËØïÂ§±Ë¥•ÁöÑtoken

    def _load_tokens_from_file(self, file_path: str) -> List[str]:
        """
        ‰ªéÊñá‰ª∂Âä†ËΩΩtokenÂàóË°®

        ÊîØÊåÅÂ§öÁßçÊ†ºÂºèÁöÑÊ∑∑Âêà‰ΩøÁî®Ôºö
        1. ÊØèË°å‰∏Ä‰∏™tokenÔºàÊç¢Ë°åÂàÜÈöîÔºâ
        2. ÈÄóÂè∑ÂàÜÈöîÁöÑtoken
        3. Ê∑∑ÂêàÊ†ºÂºèÔºàÂêåÊó∂ÊîØÊåÅÊç¢Ë°åÂíåÈÄóÂè∑ÂàÜÈöîÔºâ
        """
        tokens = []
        try:
            if os.path.exists(file_path):
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read().strip()

                    if not content:
                        logger.debug(f"üìÑ TokenÊñá‰ª∂‰∏∫Á©∫: {file_path}")
                        return tokens

                    # Êô∫ËÉΩËß£ÊûêÔºöÂêåÊó∂ÊîØÊåÅÊç¢Ë°åÂíåÈÄóÂè∑ÂàÜÈöî
                    # 1. ÂÖàÊåâÊç¢Ë°åÁ¨¶ÂàÜÂâ≤Â§ÑÁêÜÊØè‰∏ÄË°å
                    lines = content.split('\n')

                    for line in lines:
                        line = line.strip()
                        # Ë∑≥ËøáÁ©∫Ë°åÂíåÊ≥®ÈáäË°å
                        if not line or line.startswith('#'):
                            continue

                        # 2. Ê£ÄÊü•ÂΩìÂâçË°åÊòØÂê¶ÂåÖÂê´ÈÄóÂè∑ÂàÜÈöî
                        if ',' in line:
                            # ÊåâÈÄóÂè∑ÂàÜÂâ≤ÂΩìÂâçË°å
                            comma_tokens = line.split(',')
                            for token in comma_tokens:
                                token = token.strip()
                                if token:  # Ë∑≥ËøáÁ©∫token
                                    tokens.append(token)
                        else:
                            # Êï¥Ë°å‰Ωú‰∏∫‰∏Ä‰∏™token
                            tokens.append(line)

                logger.info(f"üìÑ ‰ªéÊñá‰ª∂Âä†ËΩΩ‰∫Ü {len(tokens)} ‰∏™token: {file_path}")
            else:
                logger.debug(f"üìÑ TokenÊñá‰ª∂‰∏çÂ≠òÂú®: {file_path}")
        except Exception as e:
            logger.error(f"‚ùå ËØªÂèñtokenÊñá‰ª∂Â§±Ë¥• {file_path}: {e}")
        return tokens

    @property
    def auth_token_list(self) -> List[str]:
        """
        Ëß£ÊûêËÆ§ËØÅtokenÂàóË°®

        ‰ªéAUTH_TOKENS_FILEÊåáÂÆöÁöÑÊñá‰ª∂Âä†ËΩΩtokenÔºàÂ¶ÇÊûúÈÖçÁΩÆ‰∫ÜÊñá‰ª∂Ë∑ØÂæÑÔºâ
        """
        # Â¶ÇÊûúÊú™ÈÖçÁΩÆtokenÊñá‰ª∂Ë∑ØÂæÑÔºåËøîÂõûÁ©∫ÂàóË°®
        if not self.AUTH_TOKENS_FILE:
            logger.debug("üìÑ Êú™ÈÖçÁΩÆAUTH_TOKENS_FILEÔºåË∑≥ËøátokenÊñá‰ª∂Âä†ËΩΩ")
            return []

        # ‰ªéÊñá‰ª∂Âä†ËΩΩtoken
        tokens = self._load_tokens_from_file(self.AUTH_TOKENS_FILE)

        # ÂéªÈáçÔºå‰øùÊåÅÈ°∫Â∫è
        if tokens:
            seen = set()
            unique_tokens = []
            for token in tokens:
                if token not in seen:
                    unique_tokens.append(token)
                    seen.add(token)

            # ËÆ∞ÂΩïÂéªÈáç‰ø°ÊÅØ
            duplicate_count = len(tokens) - len(unique_tokens)
            if duplicate_count > 0:
                logger.warning(f"‚ö†Ô∏è Ê£ÄÊµãÂà∞ {duplicate_count} ‰∏™ÈáçÂ§çtokenÔºåÂ∑≤Ëá™Âä®ÂéªÈáç")

            return unique_tokens

        return []

    @property
    def longcat_token_list(self) -> List[str]:
        """
        Ëß£Êûê LongCat token ÂàóË°®

        ‰ªé LONGCAT_TOKENS_FILE ÊåáÂÆöÁöÑÊñá‰ª∂Âä†ËΩΩ tokenÔºàÂ¶ÇÊûúÈÖçÁΩÆ‰∫ÜÊñá‰ª∂Ë∑ØÂæÑÔºâ
        """
        # Â¶ÇÊûúÊú™ÈÖçÁΩÆtokenÊñá‰ª∂Ë∑ØÂæÑÔºåËøîÂõûÁ©∫ÂàóË°®
        if not self.LONGCAT_TOKENS_FILE:
            logger.debug("üìÑ Êú™ÈÖçÁΩÆLONGCAT_TOKENS_FILEÔºåË∑≥ËøáLongCat tokenÊñá‰ª∂Âä†ËΩΩ")
            return []

        # ‰ªéÊñá‰ª∂Âä†ËΩΩtoken
        tokens = self._load_tokens_from_file(self.LONGCAT_TOKENS_FILE)

        # ÂéªÈáçÔºå‰øùÊåÅÈ°∫Â∫è
        if tokens:
            seen = set()
            unique_tokens = []
            for token in tokens:
                if token not in seen:
                    unique_tokens.append(token)
                    seen.add(token)

            # ËÆ∞ÂΩïÂéªÈáç‰ø°ÊÅØ
            duplicate_count = len(tokens) - len(unique_tokens)
            if duplicate_count > 0:
                logger.warning(f"‚ö†Ô∏è Ê£ÄÊµãÂà∞ {duplicate_count} ‰∏™ÈáçÂ§çLongCat tokenÔºåÂ∑≤Ëá™Âä®ÂéªÈáç")

            return unique_tokens

        return []

    # Model Configuration
    PRIMARY_MODEL: str = os.getenv("PRIMARY_MODEL", "GLM-4.5")
    THINKING_MODEL: str = os.getenv("THINKING_MODEL", "GLM-4.5-Thinking")
    SEARCH_MODEL: str = os.getenv("SEARCH_MODEL", "GLM-4.5-Search")
    AIR_MODEL: str = os.getenv("AIR_MODEL", "GLM-4.5-Air")
    GLM46_MODEL: str = os.getenv("GLM46_MODEL", "GLM-4.6")
    GLM46_THINKING_MODEL: str = os.getenv("GLM46_THINKING_MODEL", "GLM-4.6-Thinking")
    GLM46_SEARCH_MODEL: str = os.getenv("GLM46_SEARCH_MODEL", "GLM-4.6-Search")



    # Provider Model Mapping
    @property
    def provider_model_mapping(self) -> Dict[str, str]:
        """Ê®°ÂûãÂà∞Êèê‰æõÂïÜÁöÑÊò†Â∞Ñ"""
        return {
            # Z.AI models
            "GLM-4.5": "zai",
            "GLM-4.5-Thinking": "zai",
            "GLM-4.5-Search": "zai",
            "GLM-4.5-Air": "zai",
            "GLM-4.6": "zai",
            "GLM-4.6-Thinking": "zai",
            "GLM-4.6-Search": "zai",
            # K2Think models
            "MBZUAI-IFM/K2-Think": "k2think",
            # LongCat models
            "LongCat-Flash": "longcat",
            "LongCat": "longcat",
            "LongCat-Search": "longcat",
        }

    # Server Configuration
    LISTEN_PORT: int = int(os.getenv("LISTEN_PORT", "8080"))
    DEBUG_LOGGING: bool = os.getenv("DEBUG_LOGGING", "true").lower() == "true"
    SERVICE_NAME: str = os.getenv("SERVICE_NAME", "z-ai2api-server")

    ANONYMOUS_MODE: bool = os.getenv("ANONYMOUS_MODE", "true").lower() == "true"
    TOOL_SUPPORT: bool = os.getenv("TOOL_SUPPORT", "true").lower() == "true"
    SCAN_LIMIT: int = int(os.getenv("SCAN_LIMIT", "200000"))
    SKIP_AUTH_TOKEN: bool = os.getenv("SKIP_AUTH_TOKEN", "false").lower() == "true"

    # LongCat Configuration
    LONGCAT_PASSPORT_TOKEN: Optional[str] = os.getenv("LONGCAT_PASSPORT_TOKEN")
    LONGCAT_TOKENS_FILE: Optional[str] = os.getenv("LONGCAT_TOKENS_FILE")

    # Browser Headers
    CLIENT_HEADERS: Dict[str, str] = {
        "Content-Type": "application/json",
        "Accept": "application/json, text/event-stream",
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36 Edg/139.0.0.0",
        "Accept-Language": "zh-CN",
        "sec-ch-ua": '"Not;A=Brand";v="99", "Microsoft Edge";v="139", "Chromium";v="139"',
        "sec-ch-ua-mobile": "?0",
        "sec-ch-ua-platform": '"Windows"',
        "X-FE-Version": "prod-fe-1.0.70",
        "Origin": "https://chat.z.ai",
    }

    class Config:
        env_file = ".env"


settings = Settings()
