#!/usr/bin/env python
# -*- coding: utf-8 -*-

import time
import json
import asyncio
from typing import List, Dict, Any
from fastapi import APIRouter, Header, HTTPException
from fastapi.responses import StreamingResponse, JSONResponse
import httpx

from app.core.config import settings
from app.models.schemas import OpenAIRequest, Message, ModelsResponse, Model, OpenAIResponse, Choice, Usage
from app.utils.logger import get_logger
from app.core.zai_transformer import ZAITransformer
from app.utils.sse_tool_handler import SSEToolHandler
from app.utils.token_pool import get_token_pool

logger = get_logger()
router = APIRouter()
transformer = ZAITransformer()


def create_chunk(chat_id: str, model: str, delta: Dict[str, Any], finish_reason: str = None) -> Dict[str, Any]:
    """åˆ›å»ºæ ‡å‡†çš„ OpenAI chunk ç»“æ„"""
    return {
        "choices": [{
            "delta": delta,
            "finish_reason": finish_reason,
            "index": 0,
            "logprobs": None,
        }],
        "created": int(time.time()),
        "id": chat_id,
        "model": model,
        "object": "chat.completion.chunk",
        "system_fingerprint": "fp_zai_001",
    }


async def handle_non_stream_response(stream_response, request: OpenAIRequest) -> JSONResponse:
    """å¤„ç†éæµå¼å“åº”"""
    logger.info("ğŸ“„ å¼€å§‹å¤„ç†éæµå¼å“åº”")

    # æ”¶é›†æ‰€æœ‰æµå¼æ•°æ®
    full_content = []
    async for chunk_data in stream_response():
        if chunk_data.startswith("data: "):
            chunk_str = chunk_data[6:].strip()
            if chunk_str and chunk_str != "[DONE]":
                try:
                    chunk = json.loads(chunk_str)
                    if "choices" in chunk and chunk["choices"]:
                        choice = chunk["choices"][0]
                        if "delta" in choice and "content" in choice["delta"]:
                            content = choice["delta"]["content"]
                            if content:
                                full_content.append(content)
                except json.JSONDecodeError:
                    continue

    # æ„å»ºå“åº”
    response_data = OpenAIResponse(
        id=f"chatcmpl-{int(time.time())}",
        object="chat.completion",
        created=int(time.time()),
        model=request.model,
        choices=[Choice(
            index=0,
            message=Message(
                role="assistant",
                content="".join(full_content),
                tool_calls=None
            ),
            finish_reason="stop"
        )],
        usage=Usage(
            prompt_tokens=0,
            completion_tokens=0,
            total_tokens=0
        )
    )

    logger.info("âœ… éæµå¼å“åº”å¤„ç†å®Œæˆ")
    return JSONResponse(content=response_data.model_dump(exclude_none=True))


@router.get("/v1/models")
async def list_models():
    """List available models"""
    current_time = int(time.time())
    response = ModelsResponse(
        data=[
            Model(id=settings.PRIMARY_MODEL, created=current_time, owned_by="z.ai"),
            Model(id=settings.THINKING_MODEL, created=current_time, owned_by="z.ai"),
            Model(id=settings.SEARCH_MODEL, created=current_time, owned_by="z.ai"),
            Model(id=settings.AIR_MODEL, created=current_time, owned_by="z.ai"),
        ]
    )
    return response


@router.post("/v1/chat/completions")
async def chat_completions(request: OpenAIRequest, authorization: str = Header(...)):
    """Handle chat completion requests with ZAI transformer"""
    role = request.messages[0].role if request.messages else "unknown"
    logger.info(f"ğŸ˜¶â€ğŸŒ«ï¸ æ”¶åˆ° å®¢æˆ·ç«¯ è¯·æ±‚ - æ¨¡å‹: {request.model}, æµå¼: {request.stream}, æ¶ˆæ¯æ•°: {len(request.messages)}, è§’è‰²: {role}, å·¥å…·æ•°: {len(request.tools) if request.tools else 0}")

    try:
        # Validate API key (skip if SKIP_AUTH_TOKEN is enabled)
        if not settings.SKIP_AUTH_TOKEN:
            if not authorization.startswith("Bearer "):
                raise HTTPException(status_code=401, detail="Missing or invalid Authorization header")

            api_key = authorization[7:]
            if api_key != settings.AUTH_TOKEN:
                raise HTTPException(status_code=401, detail="Invalid API key")

        # ä½¿ç”¨æ–°çš„è½¬æ¢å™¨è½¬æ¢è¯·æ±‚
        request_dict = request.model_dump()
        
        transformed = await transformer.transform_request_in(request_dict)
        # logger.debug(f"ğŸ”„ è½¬æ¢å Z.AI è¯·æ±‚ä½“: {json.dumps(transformed['body'], ensure_ascii=False, indent=2)}")

        # è°ƒç”¨ä¸Šæ¸¸API
        async def stream_response():
            """æµå¼å“åº”ç”Ÿæˆå™¨ï¼ˆåŒ…å«é‡è¯•æœºåˆ¶ï¼‰"""
            retry_count = 0
            last_error = None
            current_token = transformed.get("token", "")  # è·å–å½“å‰ä½¿ç”¨çš„token

            while retry_count <= settings.MAX_RETRIES:
                try:
                    # å¦‚æœæ˜¯é‡è¯•ï¼Œé‡æ–°è·å–ä»¤ç‰Œå¹¶æ›´æ–°è¯·æ±‚
                    if retry_count > 0:
                        delay = settings.RETRY_DELAY
                        logger.warning(f"é‡è¯•è¯·æ±‚ ({retry_count}/{settings.MAX_RETRIES}) - ç­‰å¾… {delay:.1f}s")
                        await asyncio.sleep(delay)

                        # æ ‡è®°å‰ä¸€ä¸ªtokenå¤±è´¥ï¼ˆå¦‚æœä¸æ˜¯åŒ¿åæ¨¡å¼ï¼‰
                        if current_token and not settings.ANONYMOUS_MODE:
                            transformer.mark_token_failure(current_token, Exception(f"Retry {retry_count}: {last_error}"))

                        # é‡æ–°è·å–ä»¤ç‰Œ
                        logger.info("ğŸ”‘ é‡æ–°è·å–ä»¤ç‰Œç”¨äºé‡è¯•...")
                        new_token = await transformer.get_token()
                        if not new_token:
                            logger.error("âŒ é‡è¯•æ—¶æ— æ³•è·å–æœ‰æ•ˆçš„è®¤è¯ä»¤ç‰Œ")
                            raise Exception("é‡è¯•æ—¶æ— æ³•è·å–æœ‰æ•ˆçš„è®¤è¯ä»¤ç‰Œ")
                        transformed["config"]["headers"]["Authorization"] = f"Bearer {new_token}"
                        current_token = new_token

                    async with httpx.AsyncClient(timeout=60.0) as client:
                        # å‘é€è¯·æ±‚åˆ°ä¸Šæ¸¸
                        logger.info(f"ğŸ¯ å‘é€è¯·æ±‚åˆ° Z.AI: {transformed['config']['url']}")
                        async with client.stream(
                            "POST",
                            transformed["config"]["url"],
                            json=transformed["body"],
                            headers=transformed["config"]["headers"],
                        ) as response:
                            # æ£€æŸ¥å“åº”çŠ¶æ€ç 
                            if response.status_code == 400:
                                # 400 é”™è¯¯ï¼Œè§¦å‘é‡è¯•
                                error_text = await response.aread()
                                error_msg = error_text.decode('utf-8', errors='ignore')
                                logger.warning(f"âŒ ä¸Šæ¸¸è¿”å› 400 é”™è¯¯ (å°è¯• {retry_count + 1}/{settings.MAX_RETRIES + 1})")

                                retry_count += 1
                                last_error = f"400 Bad Request: {error_msg}"

                                # å¦‚æœè¿˜æœ‰é‡è¯•æœºä¼šï¼Œç»§ç»­å¾ªç¯
                                if retry_count <= settings.MAX_RETRIES:
                                    continue
                                else:
                                    # è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ŒæŠ›å‡ºé”™è¯¯
                                    logger.error(f"âŒ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({settings.MAX_RETRIES})ï¼Œè¯·æ±‚å¤±è´¥")
                                    error_response = {
                                        "error": {
                                            "message": f"Request failed after {settings.MAX_RETRIES} retries: {last_error}",
                                            "type": "upstream_error",
                                            "code": 400
                                        }
                                    }
                                    yield f"data: {json.dumps(error_response)}\n\n"
                                    yield "data: [DONE]\n\n"
                                    return

                            elif response.status_code != 200:
                                # å…¶ä»–é”™è¯¯ï¼Œæ ¹æ®çŠ¶æ€ç å†³å®šå¤„ç†æ–¹å¼
                                logger.error(f"âŒ ä¸Šæ¸¸è¿”å›é”™è¯¯: {response.status_code}")
                                error_text = await response.aread()
                                error_msg = error_text.decode('utf-8', errors='ignore')
                                logger.error(f"âŒ é”™è¯¯è¯¦æƒ…: {error_msg}")

                                # å¯¹äº5xxé”™è¯¯ï¼ŒæŠ›å‡ºHTTPException
                                if 500 <= response.status_code < 600:
                                    if response.status_code == 502:
                                        raise HTTPException(
                                            status_code=502,
                                            detail=f"Upstream service unavailable: {error_msg[:200]}"
                                        )
                                    elif response.status_code == 503:
                                        raise HTTPException(
                                            status_code=503,
                                            detail=f"Upstream service temporarily unavailable: {error_msg[:200]}"
                                        )
                                    elif response.status_code == 504:
                                        raise HTTPException(
                                            status_code=504,
                                            detail=f"Upstream service timeout: {error_msg[:200]}"
                                        )
                                    else:
                                        raise HTTPException(
                                            status_code=502,
                                            detail=f"Upstream server error ({response.status_code}): {error_msg[:200]}"
                                        )

                                # å¯¹äº4xxé”™è¯¯ï¼Œè¿”å›é”™è¯¯å“åº”è€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸
                                error_response = {
                                    "error": {
                                        "message": f"Upstream error: {response.status_code}",
                                        "type": "upstream_error",
                                        "code": response.status_code
                                    }
                                }
                                yield f"data: {json.dumps(error_response)}\n\n"
                                yield "data: [DONE]\n\n"
                                return

                            # 200 æˆåŠŸï¼Œå¤„ç†å“åº”
                            logger.info(f"âœ… Z.AI å“åº”æˆåŠŸï¼Œå¼€å§‹å¤„ç† SSE æµ")
                            if retry_count > 0:
                                logger.info(f"âœ¨ ç¬¬ {retry_count} æ¬¡é‡è¯•æˆåŠŸ")

                            # æ ‡è®°tokenä½¿ç”¨æˆåŠŸï¼ˆå¦‚æœä¸æ˜¯åŒ¿åæ¨¡å¼ï¼‰
                            if current_token and not settings.ANONYMOUS_MODE:
                                transformer.mark_token_success(current_token)

                            # åˆå§‹åŒ–å·¥å…·å¤„ç†å™¨ï¼ˆå¦‚æœéœ€è¦ï¼‰
                            has_tools = transformed["body"].get("tools") is not None
                            tool_handler = None

                            if has_tools:
                                tool_handler = SSEToolHandler(request.model, stream=True)
                                logger.info(f"ğŸ”§ åˆå§‹åŒ–å·¥å…·å¤„ç†å™¨: {len(transformed['body'].get('tools', []))} ä¸ªå·¥å…·")
                                
                            # å¤„ç†çŠ¶æ€
                            has_thinking = False
                            thinking_signature = None

                            # å¤„ç†SSEæµ
                            buffer = ""
                            line_count = 0
                            logger.debug("ğŸ“¡ å¼€å§‹æ¥æ”¶ SSE æµæ•°æ®...")

                            async for line in response.aiter_lines():
                                line_count += 1
                                if not line:
                                    continue

                                # ç´¯ç§¯åˆ°bufferå¤„ç†å®Œæ•´çš„æ•°æ®è¡Œ
                                buffer += line + "\n"

                                # æ£€æŸ¥æ˜¯å¦æœ‰å®Œæ•´çš„dataè¡Œ
                                while "\n" in buffer:
                                    current_line, buffer = buffer.split("\n", 1)
                                    if not current_line.strip():
                                        continue

                                    if current_line.startswith("data:"):
                                        chunk_str = current_line[5:].strip()
                                        if not chunk_str or chunk_str == "[DONE]":
                                            if chunk_str == "[DONE]":
                                                yield "data: [DONE]\n\n"
                                            continue

                                        logger.debug(f"ğŸ“¦ è§£ææ•°æ®å—: {chunk_str[:1000]}..." if len(chunk_str) > 1000 else f"ğŸ“¦ è§£ææ•°æ®å—: {chunk_str}")

                                        try:
                                            chunk = json.loads(chunk_str)

                                            if chunk.get("type") == "chat:completion":
                                                data = chunk.get("data", {})
                                                phase = data.get("phase")

                                                # è®°å½•æ¯ä¸ªé˜¶æ®µï¼ˆåªåœ¨é˜¶æ®µå˜åŒ–æ—¶è®°å½•ï¼‰
                                                if phase and phase != getattr(stream_response, '_last_phase', None):
                                                    logger.info(f"ğŸ“ˆ SSE é˜¶æ®µ: {phase}")
                                                    stream_response._last_phase = phase

                                                # ä½¿ç”¨æ–°çš„å·¥å…·å¤„ç†å™¨å¤„ç†æ‰€æœ‰é˜¶æ®µ
                                                if tool_handler:
                                                    # æ„å»º SSE æ•°æ®å—ï¼ŒåŒ…å«æ‰€æœ‰å¿…è¦å­—æ®µ
                                                    sse_chunk = {
                                                        "phase": phase,
                                                        "edit_content": data.get("edit_content", ""),
                                                        "delta_content": data.get("delta_content", ""),
                                                        "edit_index": data.get("edit_index"),
                                                        "usage": data.get("usage", {})
                                                    }

                                                    # å¤„ç†å·¥å…·è°ƒç”¨å¹¶è¾“å‡ºç»“æœ
                                                    for output in tool_handler.process_sse_chunk(sse_chunk):
                                                        yield output

                                                # éå·¥å…·è°ƒç”¨æ¨¡å¼ - å¤„ç†æ€è€ƒå†…å®¹
                                                elif phase == "thinking":
                                                    if not has_thinking:
                                                        has_thinking = True
                                                        # å‘é€åˆå§‹è§’è‰²
                                                        role_chunk = create_chunk(
                                                            transformed["body"]["chat_id"],
                                                            request.model,
                                                            {"role": "assistant"}
                                                        )
                                                        yield f"data: {json.dumps(role_chunk)}\n\n"

                                                    delta_content = data.get("delta_content", "")
                                                    if delta_content:
                                                        # å¤„ç†æ€è€ƒå†…å®¹æ ¼å¼
                                                        if delta_content.startswith("<details"):
                                                            content = (
                                                                delta_content.split("</summary>\n>")[-1].strip()
                                                                if "</summary>\n>" in delta_content
                                                                else delta_content
                                                            )
                                                        else:
                                                            content = delta_content

                                                        thinking_chunk = create_chunk(
                                                            transformed["body"]["chat_id"],
                                                            request.model,
                                                            {
                                                                "role": "assistant",
                                                                "thinking": {"content": content}
                                                            }
                                                        )
                                                        yield f"data: {json.dumps(thinking_chunk)}\n\n"

                                                # å¤„ç†ç­”æ¡ˆå†…å®¹
                                                elif phase == "answer":
                                                    edit_content = data.get("edit_content", "")
                                                    delta_content = data.get("delta_content", "")

                                                    # å¤„ç†æ€è€ƒç»“æŸå’Œç­”æ¡ˆå¼€å§‹
                                                    if edit_content and "</details>\n" in edit_content:
                                                        if has_thinking:
                                                            # å‘é€æ€è€ƒç­¾å
                                                            thinking_signature = str(int(time.time() * 1000))
                                                            sig_chunk = create_chunk(
                                                                transformed["body"]["chat_id"],
                                                                request.model,
                                                                {
                                                                    "role": "assistant",
                                                                    "thinking": {
                                                                        "content": "",
                                                                        "signature": thinking_signature,
                                                                    }
                                                                }
                                                            )
                                                            yield f"data: {json.dumps(sig_chunk)}\n\n"

                                                        # æå–ç­”æ¡ˆå†…å®¹
                                                        content_after = edit_content.split("</details>\n")[-1]
                                                        if content_after:
                                                            content_chunk = create_chunk(
                                                                transformed["body"]["chat_id"],
                                                                request.model,
                                                                {
                                                                    "role": "assistant",
                                                                    "content": content_after
                                                                }
                                                            )
                                                            yield f"data: {json.dumps(content_chunk)}\n\n"

                                                    # å¤„ç†å¢é‡å†…å®¹
                                                    elif delta_content:
                                                        # å¦‚æœè¿˜æ²¡æœ‰å‘é€è§’è‰²
                                                        if not has_thinking:
                                                            role_chunk = create_chunk(
                                                                transformed["body"]["chat_id"],
                                                                request.model,
                                                                {"role": "assistant"}
                                                            )
                                                            yield f"data: {json.dumps(role_chunk)}\n\n"

                                                        content_chunk = create_chunk(
                                                            transformed["body"]["chat_id"],
                                                            request.model,
                                                            {
                                                                "role": "assistant",
                                                                "content": delta_content
                                                            }
                                                        )
                                                        output_data = f"data: {json.dumps(content_chunk)}\n\n"
                                                        logger.debug(f"â¡ï¸ è¾“å‡ºå†…å®¹å—åˆ°å®¢æˆ·ç«¯: {output_data}")
                                                        yield output_data

                                                    # å¤„ç†å®Œæˆ
                                                    if data.get("usage"):
                                                        logger.info(f"ğŸ“¦ å®Œæˆå“åº” - ä½¿ç”¨ç»Ÿè®¡: {json.dumps(data['usage'])}")

                                                        # åªæœ‰åœ¨éå·¥å…·è°ƒç”¨æ¨¡å¼ä¸‹æ‰å‘é€æ™®é€šå®Œæˆä¿¡å·
                                                        if not tool_handler:
                                                            finish_chunk = create_chunk(
                                                                transformed["body"]["chat_id"],
                                                                request.model,
                                                                {"role": "assistant", "content": ""},
                                                                "stop"
                                                            )
                                                            finish_chunk["usage"] = data["usage"]

                                                            finish_output = f"data: {json.dumps(finish_chunk)}\n\n"
                                                            logger.debug(f"â¡ï¸ å‘é€å®Œæˆä¿¡å·: {finish_output[:1000]}...")
                                                            yield finish_output
                                                            logger.debug("â¡ï¸ å‘é€ [DONE]")
                                                            yield "data: [DONE]\n\n"

                                        except json.JSONDecodeError as e:
                                            logger.debug(f"âŒ JSONè§£æé”™è¯¯: {e}, å†…å®¹: {chunk_str[:1000]}")
                                        except Exception as e:
                                            logger.error(f"âŒ å¤„ç†chunké”™è¯¯: {e}")

                            # å·¥å…·å¤„ç†å™¨ä¼šè‡ªåŠ¨å‘é€ç»“æŸä¿¡å·ï¼Œè¿™é‡Œä¸éœ€è¦é‡å¤å‘é€
                            if not tool_handler:
                                logger.debug("ğŸ“¤ å‘é€æœ€ç»ˆ [DONE] ä¿¡å·")
                                yield "data: [DONE]\n\n"

                            logger.info(f"âœ… SSE æµå¤„ç†å®Œæˆï¼Œå…±å¤„ç† {line_count} è¡Œæ•°æ®")
                            # æˆåŠŸå¤„ç†å®Œæˆï¼Œé€€å‡ºé‡è¯•å¾ªç¯
                            return

                except Exception as e:
                    logger.error(f"âŒ æµå¤„ç†é”™è¯¯: {e}")
                    import traceback
                    logger.error(traceback.format_exc())

                    # æ£€æŸ¥æ˜¯å¦æ˜¯ç½‘ç»œè¿æ¥é”™è¯¯
                    error_str = str(e).lower()
                    is_connection_error = any(keyword in error_str for keyword in [
                        'server disconnected', 'connection closed', 'connection reset',
                        'timeout', 'connection error', 'network error'
                    ])

                    # æ£€æŸ¥æ˜¯å¦æ˜¯ç‰¹å®šçš„ httpcore é”™è¯¯
                    is_httpcore_error = 'httpcore' in str(type(e)) or 'RemoteProtocolError' in str(type(e))

                    # æ ‡è®°tokenå¤±è´¥ï¼ˆå¦‚æœä¸æ˜¯åŒ¿åæ¨¡å¼ï¼‰
                    if current_token and not settings.ANONYMOUS_MODE:
                        transformer.mark_token_failure(current_token, e)

                    # æ£€æŸ¥æ˜¯å¦è¿˜å¯ä»¥é‡è¯•
                    retry_count += 1
                    last_error = str(e)

                    # å¯¹äºä¸¥é‡çš„è¿æ¥é”™è¯¯ï¼Œåœ¨è¾¾åˆ°é‡è¯•ä¸Šé™æ—¶æŠ›å‡º HTTPException
                    if retry_count > settings.MAX_RETRIES:
                        if is_connection_error or is_httpcore_error:
                            logger.error(f"âŒ ä¸Šæ¸¸æœåŠ¡è¿æ¥å¤±è´¥ï¼Œé‡è¯•æ¬¡æ•°å·²è¾¾ä¸Šé™")
                            raise HTTPException(
                                status_code=502,
                                detail=f"Upstream service connection failed: {last_error}"
                            )
                        else:
                            # è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œè¿”å›é”™è¯¯
                            logger.error(f"âŒ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({settings.MAX_RETRIES})ï¼Œæµå¤„ç†å¤±è´¥")
                            error_response = {
                                "error": {
                                    "message": f"Stream processing failed after {settings.MAX_RETRIES} retries: {last_error}",
                                    "type": "stream_error"
                                }
                            }
                            yield f"data: {json.dumps(error_response)}\n\n"
                            yield "data: [DONE]\n\n"
                            return
                    else:
                        # ç»§ç»­é‡è¯•
                        if is_connection_error or is_httpcore_error:
                            logger.warning(f"âš ï¸ è¿æ¥é”™è¯¯ï¼Œé‡è¯•è¯·æ±‚ ({retry_count}/{settings.MAX_RETRIES})")
                        else:
                            logger.warning(f"âš ï¸ é‡è¯•è¯·æ±‚ ({retry_count}/{settings.MAX_RETRIES})")
                        continue

        # æ ¹æ®è¯·æ±‚ç±»å‹è¿”å›å“åº”
        if request.stream:
            logger.info("ğŸš€ å¯åŠ¨ SSE æµå¼å“åº”")
            return StreamingResponse(
                stream_response(),
                media_type="text/event-stream",
                headers={
                    "Cache-Control": "no-cache",
                    "Connection": "keep-alive",
                },
            )
        else:
            logger.info("ğŸ“„ å¤„ç†éæµå¼å“åº”")
            return await handle_non_stream_response(stream_response, request)

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback

        logger.error(f"âŒ é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")


@router.get("/v1/token-pool/status")
async def get_token_pool_status():
    """è·å–tokenæ± çŠ¶æ€ä¿¡æ¯"""
    try:
        token_pool = get_token_pool()
        if not token_pool:
            return {
                "status": "disabled",
                "message": "Tokenæ± æœªåˆå§‹åŒ–ï¼Œå½“å‰ä»…ä½¿ç”¨åŒ¿åæ¨¡å¼",
                "anonymous_mode": settings.ANONYMOUS_MODE,
                "auth_tokens_file": settings.AUTH_TOKENS_FILE,
                "auth_tokens_configured": len(settings.auth_token_list) > 0
            }

        pool_status = token_pool.get_pool_status()
        return {
            "status": "active",
            "pool_info": pool_status,
            "config": {
                "anonymous_mode": settings.ANONYMOUS_MODE,
                "failure_threshold": settings.TOKEN_FAILURE_THRESHOLD,
                "recovery_timeout": settings.TOKEN_RECOVERY_TIMEOUT,
                "health_check_interval": settings.TOKEN_HEALTH_CHECK_INTERVAL
            }
        }
    except Exception as e:
        logger.error(f"è·å–tokenæ± çŠ¶æ€å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to get token pool status: {str(e)}")


@router.post("/v1/token-pool/health-check")
async def trigger_health_check():
    """æ‰‹åŠ¨è§¦å‘tokenæ± å¥åº·æ£€æŸ¥"""
    try:
        token_pool = get_token_pool()
        if not token_pool:
            raise HTTPException(status_code=404, detail="Tokenæ± æœªåˆå§‹åŒ–")

        start_time = time.time()
        logger.info("ğŸ” APIè§¦å‘Tokenæ± å¥åº·æ£€æŸ¥...")
        await token_pool.health_check_all()
        duration = time.time() - start_time

        pool_status = token_pool.get_pool_status()
        total_tokens = pool_status['total_tokens']
        healthy_tokens = sum(1 for token_info in pool_status['tokens'] if token_info['is_healthy'])

        response = {
            "status": "completed",
            "message": f"å¥åº·æ£€æŸ¥å·²å®Œæˆï¼Œè€—æ—¶ {duration:.2f} ç§’",
            "summary": {
                "total_tokens": total_tokens,
                "healthy_tokens": healthy_tokens,
                "unhealthy_tokens": total_tokens - healthy_tokens,
                "health_rate": f"{(healthy_tokens/total_tokens*100):.1f}%" if total_tokens > 0 else "0%",
                "duration_seconds": round(duration, 2)
            },
            "pool_info": pool_status
        }

        logger.info(f"âœ… APIå¥åº·æ£€æŸ¥å®Œæˆ: {healthy_tokens}/{total_tokens} ä¸ªtokenå¥åº·")
        return response
    except Exception as e:
        logger.error(f"å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"Health check failed: {str(e)}")


@router.post("/v1/token-pool/update")
async def update_token_pool_endpoint(tokens: List[str]):
    """åŠ¨æ€æ›´æ–°tokenæ± """
    try:
        from app.utils.token_pool import update_token_pool

        valid_tokens = [token.strip() for token in tokens if token.strip()]
        if not valid_tokens:
            raise HTTPException(status_code=400, detail="è‡³å°‘éœ€è¦æä¾›ä¸€ä¸ªæœ‰æ•ˆçš„token")

        update_token_pool(valid_tokens)
        token_pool = get_token_pool()

        return {
            "status": "updated",
            "message": f"Tokenæ± å·²æ›´æ–°ï¼Œå…± {len(valid_tokens)} ä¸ªtoken",
            "pool_info": token_pool.get_pool_status() if token_pool else None
        }
    except Exception as e:
        logger.error(f"æ›´æ–°tokenæ± å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to update token pool: {str(e)}")
