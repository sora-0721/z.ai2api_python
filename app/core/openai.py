#!/usr/bin/env python
# -*- coding: utf-8 -*-

import time
import json
import asyncio
from datetime import datetime
from typing import List, Dict, Any
from fastapi import APIRouter, Header, HTTPException
from fastapi.responses import StreamingResponse, JSONResponse
import httpx

from app.core.config import settings
from app.models.schemas import OpenAIRequest, Message, ModelsResponse, Model, OpenAIResponse, Choice, Usage
from app.utils.logger import get_logger
from app.core.zai_transformer import ZAITransformer, generate_uuid
from app.utils.sse_tool_handler import SSEToolHandler
from app.utils.token_pool import get_token_pool

logger = get_logger()

router = APIRouter()

# å…¨å±€è½¬æ¢å™¨å®ä¾‹
transformer = ZAITransformer()


async def handle_non_stream_response(stream_response, request: OpenAIRequest, transformed: Dict[str, Any]) -> JSONResponse:
    """å¤„ç†éæµå¼å“åº”"""
    logger.info("ğŸ“„ å¼€å§‹å¤„ç†éæµå¼å“åº”")

    # åˆå§‹åŒ–å·¥å…·å¤„ç†å™¨
    tool_handler = None
    has_tools = transformed["body"].get("tools") is not None

    if has_tools:
        tool_handler = SSEToolHandler(request.model)
        logger.info(f"ğŸ”§ åˆå§‹åŒ–å·¥å…·å¤„ç†å™¨: {len(transformed['body'].get('tools', []))} ä¸ªå·¥å…·")

    # æ”¶é›†æ‰€æœ‰æµå¼æ•°æ®
    full_content = []
    async for chunk_data in stream_response():
        # è§£æchunkæ•°æ®ï¼ˆå»é™¤SSEæ ¼å¼ï¼‰
        if chunk_data.startswith("data: "):
            chunk_str = chunk_data[6:].strip()
            if chunk_str and chunk_str != "[DONE]":
                try:
                    chunk = json.loads(chunk_str)

                    # å¦‚æœæ˜¯å·¥å…·å¤„ç†å™¨çš„è¾“å‡ºï¼Œè·³è¿‡ï¼ˆæˆ‘ä»¬ä¼šåœ¨æœ€åå¤„ç†ï¼‰
                    if "choices" in chunk and chunk["choices"]:
                        choice = chunk["choices"][0]
                        if "delta" in choice:
                            delta = choice["delta"]

                            # æ”¶é›†æ™®é€šå†…å®¹
                            if "content" in delta and delta["content"]:
                                content = delta["content"]
                                full_content.append(content)
                                if tool_handler:
                                    tool_handler.buffer_content(content)

                            # æ”¶é›†æ€è€ƒå†…å®¹
                            if "reasoning_content" in delta and delta["reasoning_content"]:
                                content = delta["reasoning_content"]
                                full_content.append(content)
                                if tool_handler:
                                    tool_handler.buffer_content(content)

                except json.JSONDecodeError:
                    continue

    # å¤„ç†å·¥å…·è°ƒç”¨
    final_content = "".join(full_content)
    tool_calls = None
    finish_reason = "stop"
    message_content = final_content

    if tool_handler:
        # æå–å·¥å…·è°ƒç”¨
        tool_calls = tool_handler.extract_tools_at_end()
        if tool_calls:
            # æ ¹æ®OpenAIè§„èŒƒï¼Œæœ‰å·¥å…·è°ƒç”¨æ—¶contentå¿…é¡»ä¸ºnull
            message_content = None
            finish_reason = "tool_calls"
        else:
            # æ¸…ç†å·¥å…·JSONå†…å®¹
            message_content = tool_handler.get_cleaned_content()

    # æ„å»ºå“åº”
    response_data = OpenAIResponse(
        id=f"chatcmpl-{int(time.time())}",
        object="chat.completion",
        created=int(time.time()),
        model=request.model,
        choices=[Choice(
            index=0,
            message=Message(
                role="assistant",
                content=message_content,
                tool_calls=tool_calls
            ),
            finish_reason=finish_reason
        )],
        usage=Usage(
            prompt_tokens=0,
            completion_tokens=0,
            total_tokens=0
        )
    )

    logger.info("âœ… éæµå¼å“åº”å¤„ç†å®Œæˆ")
    return JSONResponse(content=response_data.model_dump(exclude_none=True))


@router.get("/v1/models")
async def list_models():
    """List available models"""
    current_time = int(time.time())
    response = ModelsResponse(
        data=[
            Model(id=settings.PRIMARY_MODEL, created=current_time, owned_by="z.ai"),
            Model(id=settings.THINKING_MODEL, created=current_time, owned_by="z.ai"),
            Model(id=settings.SEARCH_MODEL, created=current_time, owned_by="z.ai"),
            Model(id=settings.AIR_MODEL, created=current_time, owned_by="z.ai"),
        ]
    )
    return response


@router.post("/v1/chat/completions")
async def chat_completions(request: OpenAIRequest, authorization: str = Header(...)):
    """Handle chat completion requests with ZAI transformer"""
    role = request.messages[0].role if request.messages else "unknown"
    logger.info(f"ğŸ˜¶â€ğŸŒ«ï¸ æ”¶åˆ° å®¢æˆ·ç«¯ è¯·æ±‚ - æ¨¡å‹: {request.model}, æµå¼: {request.stream}, æ¶ˆæ¯æ•°: {len(request.messages)}, è§’è‰²: {role}, å·¥å…·æ•°: {len(request.tools) if request.tools else 0}")

    try:
        # Validate API key (skip if SKIP_AUTH_TOKEN is enabled)
        if not settings.SKIP_AUTH_TOKEN:
            if not authorization.startswith("Bearer "):
                raise HTTPException(status_code=401, detail="Missing or invalid Authorization header")

            api_key = authorization[7:]
            if api_key != settings.AUTH_TOKEN:
                raise HTTPException(status_code=401, detail="Invalid API key")

        # ä½¿ç”¨æ–°çš„è½¬æ¢å™¨è½¬æ¢è¯·æ±‚
        request_dict = request.model_dump()
        
        transformed = await transformer.transform_request_in(request_dict)
        # logger.debug(f"ğŸ”„ è½¬æ¢å Z.AI è¯·æ±‚ä½“: {json.dumps(transformed['body'], ensure_ascii=False, indent=2)}")

        # è°ƒç”¨ä¸Šæ¸¸API
        async def stream_response():
            """æµå¼å“åº”ç”Ÿæˆå™¨ï¼ˆåŒ…å«é‡è¯•æœºåˆ¶ï¼‰"""
            retry_count = 0
            last_error = None
            current_token = transformed.get("token", "")  # è·å–å½“å‰ä½¿ç”¨çš„token

            while retry_count <= settings.MAX_RETRIES:
                try:
                    # å¦‚æœæ˜¯é‡è¯•ï¼Œé‡æ–°è·å–ä»¤ç‰Œå¹¶æ›´æ–°è¯·æ±‚
                    if retry_count > 0:
                        delay = settings.RETRY_DELAY
                        logger.warning(f"é‡è¯•è¯·æ±‚ ({retry_count}/{settings.MAX_RETRIES}) - ç­‰å¾… {delay:.1f}s")
                        await asyncio.sleep(delay)

                        # æ ‡è®°å‰ä¸€ä¸ªtokenå¤±è´¥ï¼ˆå¦‚æœä¸æ˜¯åŒ¿åæ¨¡å¼ï¼‰
                        if current_token and not settings.ANONYMOUS_MODE:
                            transformer.mark_token_failure(current_token, Exception(f"Retry {retry_count}: {last_error}"))

                        # é‡æ–°è·å–ä»¤ç‰Œ
                        logger.info("ğŸ”‘ é‡æ–°è·å–ä»¤ç‰Œç”¨äºé‡è¯•...")
                        new_token = await transformer.get_token()
                        if not new_token:
                            logger.error("âŒ é‡è¯•æ—¶æ— æ³•è·å–æœ‰æ•ˆçš„è®¤è¯ä»¤ç‰Œ")
                            raise Exception("é‡è¯•æ—¶æ— æ³•è·å–æœ‰æ•ˆçš„è®¤è¯ä»¤ç‰Œ")
                        transformed["config"]["headers"]["Authorization"] = f"Bearer {new_token}"
                        current_token = new_token

                    async with httpx.AsyncClient(timeout=60.0) as client:
                        # å‘é€è¯·æ±‚åˆ°ä¸Šæ¸¸
                        logger.info(f"ğŸ¯ å‘é€è¯·æ±‚åˆ° Z.AI: {transformed['config']['url']}")
                        async with client.stream(
                            "POST",
                            transformed["config"]["url"],
                            json=transformed["body"],
                            headers=transformed["config"]["headers"],
                        ) as response:
                            # æ£€æŸ¥å“åº”çŠ¶æ€ç 
                            if response.status_code == 400:
                                # 400 é”™è¯¯ï¼Œè§¦å‘é‡è¯•
                                error_text = await response.aread()
                                error_msg = error_text.decode('utf-8', errors='ignore')
                                logger.warning(f"âŒ ä¸Šæ¸¸è¿”å› 400 é”™è¯¯ (å°è¯• {retry_count + 1}/{settings.MAX_RETRIES + 1})")

                                retry_count += 1
                                last_error = f"400 Bad Request: {error_msg}"

                                # å¦‚æœè¿˜æœ‰é‡è¯•æœºä¼šï¼Œç»§ç»­å¾ªç¯
                                if retry_count <= settings.MAX_RETRIES:
                                    continue
                                else:
                                    # è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ŒæŠ›å‡ºé”™è¯¯
                                    logger.error(f"âŒ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({settings.MAX_RETRIES})ï¼Œè¯·æ±‚å¤±è´¥")
                                    error_response = {
                                        "error": {
                                            "message": f"Request failed after {settings.MAX_RETRIES} retries: {last_error}",
                                            "type": "upstream_error",
                                            "code": 400
                                        }
                                    }
                                    yield f"data: {json.dumps(error_response)}\n\n"
                                    yield "data: [DONE]\n\n"
                                    return

                            elif response.status_code != 200:
                                # å…¶ä»–é”™è¯¯ï¼Œç›´æ¥è¿”å›
                                logger.error(f"âŒ ä¸Šæ¸¸è¿”å›é”™è¯¯: {response.status_code}")
                                error_text = await response.aread()
                                error_msg = error_text.decode('utf-8', errors='ignore')
                                logger.error(f"âŒ é”™è¯¯è¯¦æƒ…: {error_msg}")

                                error_response = {
                                    "error": {
                                        "message": f"Upstream error: {response.status_code}",
                                        "type": "upstream_error",
                                        "code": response.status_code
                                    }
                                }
                                yield f"data: {json.dumps(error_response)}\n\n"
                                yield "data: [DONE]\n\n"
                                return

                            # 200 æˆåŠŸï¼Œå¤„ç†å“åº”
                            logger.info(f"âœ… Z.AI å“åº”æˆåŠŸï¼Œå¼€å§‹å¤„ç† SSE æµ")
                            if retry_count > 0:
                                logger.info(f"âœ¨ ç¬¬ {retry_count} æ¬¡é‡è¯•æˆåŠŸ")

                            # æ ‡è®°tokenä½¿ç”¨æˆåŠŸï¼ˆå¦‚æœä¸æ˜¯åŒ¿åæ¨¡å¼ï¼‰
                            if current_token and not settings.ANONYMOUS_MODE:
                                transformer.mark_token_success(current_token)

                            # åˆå§‹åŒ–å·¥å…·å¤„ç†å™¨ï¼ˆå¦‚æœéœ€è¦ï¼‰
                            has_tools = transformed["body"].get("tools") is not None
                            tool_handler = None
                            
                            if has_tools:
                                tool_handler = SSEToolHandler(request.model)
                                logger.info(f"ğŸ”§ åˆå§‹åŒ–å·¥å…·å¤„ç†å™¨: {len(transformed['body'].get('tools', []))} ä¸ªå·¥å…·")
                                
                            # å¤„ç†çŠ¶æ€
                            has_thinking = False
                            thinking_signature = None

                            # å¤„ç†SSEæµ
                            buffer = ""
                            line_count = 0
                            logger.debug("ğŸ“¡ å¼€å§‹æ¥æ”¶ SSE æµæ•°æ®...")

                            async for line in response.aiter_lines():
                                line_count += 1
                                if not line:
                                    continue

                                # ç´¯ç§¯åˆ°bufferå¤„ç†å®Œæ•´çš„æ•°æ®è¡Œ
                                buffer += line + "\n"

                                # æ£€æŸ¥æ˜¯å¦æœ‰å®Œæ•´çš„dataè¡Œ
                                while "\n" in buffer:
                                    current_line, buffer = buffer.split("\n", 1)
                                    if not current_line.strip():
                                        continue

                                    if current_line.startswith("data:"):
                                        chunk_str = current_line[5:].strip()
                                        if not chunk_str or chunk_str == "[DONE]":
                                            if chunk_str == "[DONE]":
                                                yield "data: [DONE]\n\n"
                                            continue

                                        logger.debug(f"ğŸ“¦ è§£ææ•°æ®å—: {chunk_str[:1000]}..." if len(chunk_str) > 1000 else f"ğŸ“¦ è§£ææ•°æ®å—: {chunk_str}")

                                        try:
                                            chunk = json.loads(chunk_str)

                                            if chunk.get("type") == "chat:completion":
                                                data = chunk.get("data", {})
                                                phase = data.get("phase")

                                                # è®°å½•æ¯ä¸ªé˜¶æ®µï¼ˆåªåœ¨é˜¶æ®µå˜åŒ–æ—¶è®°å½•ï¼‰
                                                if phase and phase != getattr(stream_response, '_last_phase', None):
                                                    logger.info(f"ğŸ“ˆ SSE é˜¶æ®µ: {phase}")
                                                    stream_response._last_phase = phase

                                                # å¤„ç†å·¥å…·è°ƒç”¨é˜¶æ®µ - ç¼“å†²å†…å®¹
                                                if phase == "tool_call" and tool_handler:
                                                    content = data.get("delta_content", "") or data.get("edit_content", "")
                                                    if content:
                                                        tool_handler.buffer_content(content)

                                                # å¤„ç†å…¶ä»–é˜¶æ®µ - å¯èƒ½æ˜¯å·¥å…·è°ƒç”¨ç»“æŸ
                                                elif phase == "other" and tool_handler:
                                                    # ç»§ç»­ç¼“å†²å†…å®¹
                                                    content = data.get("delta_content", "") or data.get("edit_content", "")
                                                    if content:
                                                        tool_handler.buffer_content(content)

                                                    # æ£€æŸ¥æ˜¯å¦ç»“æŸï¼ˆæœ‰usageä¿¡æ¯æˆ–doneæ ‡å¿—ï¼‰
                                                    if data.get("usage") or data.get("done"):
                                                        logger.debug("ğŸ æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨ç»“æŸï¼Œå¼€å§‹æå–å·¥å…·")

                                                        # å‘é€åˆå§‹è§’è‰²ä¿¡æ¯
                                                        role_chunk = {
                                                            "choices": [{
                                                                "delta": {"role": "assistant"},
                                                                "finish_reason": None,
                                                                "index": 0
                                                            }],
                                                            "created": int(time.time()),
                                                            "id": transformed["body"]["chat_id"],
                                                            "model": request.model,
                                                            "object": "chat.completion.chunk"
                                                        }
                                                        yield f"data: {json.dumps(role_chunk)}\n\n"

                                                        # æå–å·¥å…·è°ƒç”¨
                                                        tool_calls = tool_handler.extract_tools_at_end()

                                                        if tool_calls:
                                                            # å‘é€å·¥å…·è°ƒç”¨
                                                            tool_calls_list = []
                                                            for i, tc in enumerate(tool_calls):
                                                                tool_calls_list.append({
                                                                    "index": i,
                                                                    "id": tc.get("id"),
                                                                    "type": tc.get("type", "function"),
                                                                    "function": tc.get("function", {}),
                                                                })

                                                            tool_chunk = {
                                                                "choices": [{
                                                                    "delta": {"tool_calls": tool_calls_list},
                                                                    "finish_reason": None,
                                                                    "index": 0
                                                                }],
                                                                "created": int(time.time()),
                                                                "id": transformed["body"]["chat_id"],
                                                                "model": request.model,
                                                                "object": "chat.completion.chunk"
                                                            }
                                                            yield f"data: {json.dumps(tool_chunk)}\n\n"

                                                            # å‘é€å®Œæˆå—
                                                            finish_chunk = {
                                                                "choices": [{
                                                                    "delta": {},
                                                                    "finish_reason": "tool_calls",
                                                                    "index": 0
                                                                }],
                                                                "created": int(time.time()),
                                                                "id": transformed["body"]["chat_id"],
                                                                "model": request.model,
                                                                "object": "chat.completion.chunk"
                                                            }

                                                            # æ·»åŠ usageä¿¡æ¯
                                                            if data.get("usage"):
                                                                finish_chunk["usage"] = data["usage"]

                                                            yield f"data: {json.dumps(finish_chunk)}\n\n"
                                                            yield "data: [DONE]\n\n"
                                                        else:
                                                            # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œå‘é€æ¸…ç†åçš„å†…å®¹
                                                            cleaned_content = tool_handler.get_cleaned_content()
                                                            if cleaned_content.strip():
                                                                content_chunk = {
                                                                    "choices": [{
                                                                        "delta": {"content": cleaned_content},
                                                                        "finish_reason": None,
                                                                        "index": 0
                                                                    }],
                                                                    "created": int(time.time()),
                                                                    "id": transformed["body"]["chat_id"],
                                                                    "model": request.model,
                                                                    "object": "chat.completion.chunk"
                                                                }
                                                                yield f"data: {json.dumps(content_chunk)}\n\n"

                                                # å¤„ç†æ€è€ƒå†…å®¹
                                                elif phase == "thinking":
                                                    if not has_thinking:
                                                        has_thinking = True
                                                        has_thinking = True
                                                        # å‘é€åˆå§‹è§’è‰²
                                                        role_chunk = {
                                                            "choices": [
                                                                {
                                                                    "delta": {"role": "assistant"},
                                                                    "finish_reason": None,
                                                                    "index": 0,
                                                                    "logprobs": None,
                                                                }
                                                            ],
                                                            "created": int(time.time()),
                                                            "id": transformed["body"]["chat_id"],
                                                            "model": request.model,
                                                            "object": "chat.completion.chunk",
                                                            "system_fingerprint": "fp_zai_001",
                                                        }
                                                        yield f"data: {json.dumps(role_chunk)}\n\n"

                                                    delta_content = data.get("delta_content", "")
                                                    if delta_content:
                                                        # å¤„ç†æ€è€ƒå†…å®¹æ ¼å¼
                                                        if delta_content.startswith("<details"):
                                                            content = (
                                                                delta_content.split("</summary>\n>")[-1].strip()
                                                                if "</summary>\n>" in delta_content
                                                                else delta_content
                                                            )
                                                        else:
                                                            content = delta_content

                                                        thinking_chunk = {
                                                            "choices": [
                                                                {
                                                                    "delta": {
                                                                        "role": "assistant",
                                                                        "thinking": {"content": content},
                                                                    },
                                                                    "finish_reason": None,
                                                                    "index": 0,
                                                                    "logprobs": None,
                                                                }
                                                            ],
                                                            "created": int(time.time()),
                                                            "id": transformed["body"]["chat_id"],
                                                            "model": request.model,
                                                            "object": "chat.completion.chunk",
                                                            "system_fingerprint": "fp_zai_001",
                                                        }
                                                        yield f"data: {json.dumps(thinking_chunk)}\n\n"

                                                # å¤„ç†ç­”æ¡ˆå†…å®¹
                                                elif phase == "answer":
                                                    edit_content = data.get("edit_content", "")
                                                    delta_content = data.get("delta_content", "")

                                                    # å¤„ç†æ€è€ƒç»“æŸå’Œç­”æ¡ˆå¼€å§‹
                                                    if edit_content and "</details>\n" in edit_content:
                                                        if has_thinking:
                                                            # å‘é€æ€è€ƒç­¾å
                                                            thinking_signature = str(int(time.time() * 1000))
                                                            sig_chunk = {
                                                                "choices": [
                                                                    {
                                                                        "delta": {
                                                                            "role": "assistant",
                                                                            "thinking": {
                                                                                "content": "",
                                                                                "signature": thinking_signature,
                                                                            },
                                                                        },
                                                                        "finish_reason": None,
                                                                        "index": 0,
                                                                        "logprobs": None,
                                                                    }
                                                                ],
                                                                "created": int(time.time()),
                                                                "id": transformed["body"]["chat_id"],
                                                                "model": request.model,
                                                                "object": "chat.completion.chunk",
                                                                "system_fingerprint": "fp_zai_001",
                                                            }
                                                            yield f"data: {json.dumps(sig_chunk)}\n\n"

                                                        # æå–ç­”æ¡ˆå†…å®¹
                                                        content_after = edit_content.split("</details>\n")[-1]
                                                        if content_after:
                                                            content_chunk = {
                                                                "choices": [
                                                                    {
                                                                        "delta": {
                                                                            "role": "assistant",
                                                                            "content": content_after,
                                                                        },
                                                                        "finish_reason": None,
                                                                        "index": 0,
                                                                        "logprobs": None,
                                                                    }
                                                                ],
                                                                "created": int(time.time()),
                                                                "id": transformed["body"]["chat_id"],
                                                                "model": request.model,
                                                                "object": "chat.completion.chunk",
                                                                "system_fingerprint": "fp_zai_001",
                                                            }
                                                            yield f"data: {json.dumps(content_chunk)}\n\n"

                                                    # å¤„ç†å¢é‡å†…å®¹
                                                    elif delta_content:
                                                        # å¦‚æœè¿˜æ²¡æœ‰å‘é€è§’è‰²
                                                        if not has_thinking:
                                                            role_chunk = {
                                                                "choices": [
                                                                    {
                                                                        "delta": {"role": "assistant"},
                                                                        "finish_reason": None,
                                                                        "index": 0,
                                                                        "logprobs": None,
                                                                    }
                                                                ],
                                                                "created": int(time.time()),
                                                                "id": transformed["body"]["chat_id"],
                                                                "model": request.model,
                                                                "object": "chat.completion.chunk",
                                                                "system_fingerprint": "fp_zai_001",
                                                            }
                                                            yield f"data: {json.dumps(role_chunk)}\n\n"

                                                        content_chunk = {
                                                            "choices": [
                                                                {
                                                                    "delta": {
                                                                        "role": "assistant",
                                                                        "content": delta_content,
                                                                    },
                                                                    "finish_reason": None,
                                                                    "index": 0,
                                                                    "logprobs": None,
                                                                }
                                                            ],
                                                            "created": int(time.time()),
                                                            "id": transformed["body"]["chat_id"],
                                                            "model": request.model,
                                                            "object": "chat.completion.chunk",
                                                            "system_fingerprint": "fp_zai_001",
                                                        }
                                                        output_data = f"data: {json.dumps(content_chunk)}\n\n"
                                                        logger.debug(f"â¡ï¸ è¾“å‡ºå†…å®¹å—åˆ°å®¢æˆ·ç«¯: {output_data}")
                                                        yield output_data

                                                    # å¤„ç†å®Œæˆ
                                                    if data.get("usage"):
                                                        logger.info(f"ğŸ“¦ å®Œæˆå“åº” - ä½¿ç”¨ç»Ÿè®¡: {json.dumps(data['usage'])}")

                                                        # åªæœ‰åœ¨éå·¥å…·è°ƒç”¨æ¨¡å¼ä¸‹æ‰å‘é€æ™®é€šå®Œæˆä¿¡å·
                                                        if not tool_handler or not tool_handler.has_tools():
                                                            finish_chunk = {
                                                                "choices": [
                                                                    {
                                                                        "delta": {"role": "assistant", "content": ""},
                                                                        "finish_reason": "stop",
                                                                        "index": 0,
                                                                        "logprobs": None,
                                                                    }
                                                                ],
                                                                "usage": data["usage"],
                                                                "created": int(time.time()),
                                                                "id": transformed["body"]["chat_id"],
                                                                "model": request.model,
                                                                "object": "chat.completion.chunk",
                                                                "system_fingerprint": "fp_zai_001",
                                                            }
                                                            finish_output = f"data: {json.dumps(finish_chunk)}\n\n"
                                                            logger.debug(f"â¡ï¸ å‘é€å®Œæˆä¿¡å·: {finish_output[:1000]}...")
                                                            yield finish_output
                                                            logger.debug("â¡ï¸ å‘é€ [DONE]")
                                                            yield "data: [DONE]\n\n"

                                        except json.JSONDecodeError as e:
                                            logger.debug(f"âŒ JSONè§£æé”™è¯¯: {e}, å†…å®¹: {chunk_str[:1000]}")
                                        except Exception as e:
                                            logger.error(f"âŒ å¤„ç†chunké”™è¯¯: {e}")

                            # ç¡®ä¿å‘é€ç»“æŸä¿¡å·
                            if not tool_handler or not tool_handler.has_tools():
                                logger.debug("ğŸ“¤ å‘é€æœ€ç»ˆ [DONE] ä¿¡å·")
                                yield "data: [DONE]\n\n"

                            logger.info(f"âœ… SSE æµå¤„ç†å®Œæˆï¼Œå…±å¤„ç† {line_count} è¡Œæ•°æ®")
                            # æˆåŠŸå¤„ç†å®Œæˆï¼Œé€€å‡ºé‡è¯•å¾ªç¯
                            return

                except Exception as e:
                    logger.error(f"âŒ æµå¤„ç†é”™è¯¯: {e}")
                    import traceback
                    logger.error(traceback.format_exc())

                    # æ ‡è®°tokenå¤±è´¥ï¼ˆå¦‚æœä¸æ˜¯åŒ¿åæ¨¡å¼ï¼‰
                    if current_token and not settings.ANONYMOUS_MODE:
                        transformer.mark_token_failure(current_token, e)

                    # æ£€æŸ¥æ˜¯å¦è¿˜å¯ä»¥é‡è¯•
                    retry_count += 1
                    last_error = str(e)

                    if retry_count > settings.MAX_RETRIES:
                        # è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œè¿”å›é”™è¯¯
                        logger.error(f"âŒ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({settings.MAX_RETRIES})ï¼Œæµå¤„ç†å¤±è´¥")
                        error_response = {
                            "error": {
                                "message": f"Stream processing failed after {settings.MAX_RETRIES} retries: {last_error}",
                                "type": "stream_error"
                            }
                        }
                        yield f"data: {json.dumps(error_response)}\n\n"
                        yield "data: [DONE]\n\n"
                        return

        # æ ¹æ®è¯·æ±‚ç±»å‹è¿”å›å“åº”
        if request.stream:
            # æµå¼å“åº”
            logger.info("ğŸš€ å¯åŠ¨ SSE æµå¼å“åº”")

            # åˆ›å»ºä¸€ä¸ªåŒ…è£…çš„ç”Ÿæˆå™¨æ¥è¿½è¸ªæ•°æ®æµ
            async def logged_stream():
                chunk_count = 0
                try:
                    logger.debug("ğŸ“¤ å¼€å§‹å‘å®¢æˆ·ç«¯æµå¼ä¼ è¾“æ•°æ®...")
                    async for chunk in stream_response():
                        chunk_count += 1
                        logger.debug(f"ğŸ“¤ å‘é€å—[{chunk_count}]: {chunk[:1000]}..." if len(chunk) > 1000 else f"  ğŸ“¤ å‘é€å—[{chunk_count}]: {chunk}")
                        yield chunk
                    logger.info(f"âœ… æµå¼ä¼ è¾“å®Œæˆï¼Œå…±å‘é€ {chunk_count} ä¸ªæ•°æ®å—")
                except Exception as e:
                    logger.error(f"âŒ æµå¼ä¼ è¾“ä¸­æ–­: {e}")
                    raise

            return StreamingResponse(
                logged_stream(),
                media_type="text/event-stream",
                headers={
                    "Cache-Control": "no-cache",
                    "Connection": "keep-alive",
                },
            )
        else:
            # éæµå¼å“åº”
            logger.info("ğŸ“„ å¤„ç†éæµå¼å“åº”")
            return await handle_non_stream_response(stream_response, request, transformed)

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback

        logger.error(f"âŒ é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")


@router.get("/v1/token-pool/status")
async def get_token_pool_status():
    """è·å–tokenæ± çŠ¶æ€ä¿¡æ¯"""
    try:
        token_pool = get_token_pool()
        if not token_pool:
            return {
                "status": "disabled",
                "message": "Tokenæ± æœªåˆå§‹åŒ–ï¼Œå½“å‰ä»…ä½¿ç”¨åŒ¿åæ¨¡å¼",
                "anonymous_mode": settings.ANONYMOUS_MODE,
                "auth_tokens_file": settings.AUTH_TOKENS_FILE,
                "auth_tokens_configured": len(settings.auth_token_list) > 0
            }

        pool_status = token_pool.get_pool_status()
        return {
            "status": "active",
            "pool_info": pool_status,
            "config": {
                "anonymous_mode": settings.ANONYMOUS_MODE,
                "failure_threshold": settings.TOKEN_FAILURE_THRESHOLD,
                "recovery_timeout": settings.TOKEN_RECOVERY_TIMEOUT,
                "health_check_interval": settings.TOKEN_HEALTH_CHECK_INTERVAL
            }
        }
    except Exception as e:
        logger.error(f"è·å–tokenæ± çŠ¶æ€å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to get token pool status: {str(e)}")


@router.post("/v1/token-pool/health-check")
async def trigger_health_check():
    """æ‰‹åŠ¨è§¦å‘tokenæ± å¥åº·æ£€æŸ¥"""
    try:
        token_pool = get_token_pool()
        if not token_pool:
            raise HTTPException(status_code=404, detail="Tokenæ± æœªåˆå§‹åŒ–")

        # è®°å½•å¼€å§‹æ—¶é—´
        import time
        start_time = time.time()

        logger.info("ğŸ” APIè§¦å‘Tokenæ± å¥åº·æ£€æŸ¥...")
        await token_pool.health_check_all()

        # è®¡ç®—è€—æ—¶
        duration = time.time() - start_time

        pool_status = token_pool.get_pool_status()

        # ç»Ÿè®¡å¥åº·æ£€æŸ¥ç»“æœ - åŸºäºå®é™…çš„å¥åº·çŠ¶æ€
        total_tokens = pool_status['total_tokens']
        healthy_tokens = sum(1 for token_info in pool_status['tokens'] if token_info['is_healthy'])
        unhealthy_tokens = total_tokens - healthy_tokens

        # æ„å»ºå“åº”
        response = {
            "status": "completed",
            "message": f"å¥åº·æ£€æŸ¥å·²å®Œæˆï¼Œè€—æ—¶ {duration:.2f} ç§’",
            "summary": {
                "total_tokens": total_tokens,
                "healthy_tokens": healthy_tokens,
                "unhealthy_tokens": unhealthy_tokens,
                "health_rate": f"{(healthy_tokens/total_tokens*100):.1f}%" if total_tokens > 0 else "0%",
                "duration_seconds": round(duration, 2)
            },
            "pool_info": pool_status
        }

        # æ·»åŠ å»ºè®®
        if unhealthy_tokens > 0:
            response["recommendations"] = []
            if unhealthy_tokens == total_tokens:
                response["recommendations"].append("æ‰€æœ‰tokenéƒ½ä¸å¥åº·ï¼Œè¯·æ£€æŸ¥tokené…ç½®å’Œç½‘ç»œè¿æ¥")
            else:
                response["recommendations"].append(f"æœ‰ {unhealthy_tokens} ä¸ªtokenä¸å¥åº·ï¼Œå»ºè®®æ£€æŸ¥è¿™äº›tokençš„æœ‰æ•ˆæ€§")

        logger.info(f"âœ… APIå¥åº·æ£€æŸ¥å®Œæˆ: {healthy_tokens}/{total_tokens} ä¸ªtokenå¥åº·")
        return response
    except Exception as e:
        logger.error(f"å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"Health check failed: {str(e)}")


@router.post("/v1/token-pool/update")
async def update_token_pool(tokens: List[str]):
    """åŠ¨æ€æ›´æ–°tokenæ± """
    try:
        from app.utils.token_pool import update_token_pool

        # è¿‡æ»¤ç©ºtoken
        valid_tokens = [token.strip() for token in tokens if token.strip()]
        if not valid_tokens:
            raise HTTPException(status_code=400, detail="è‡³å°‘éœ€è¦æä¾›ä¸€ä¸ªæœ‰æ•ˆçš„token")

        update_token_pool(valid_tokens)

        token_pool = get_token_pool()
        pool_status = token_pool.get_pool_status() if token_pool else None

        return {
            "status": "updated",
            "message": f"Tokenæ± å·²æ›´æ–°ï¼Œå…± {len(valid_tokens)} ä¸ªtoken",
            "pool_info": pool_status
        }
    except Exception as e:
        logger.error(f"æ›´æ–°tokenæ± å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to update token pool: {str(e)}")
