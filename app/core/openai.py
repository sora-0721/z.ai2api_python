#!/usr/bin/env python
# -*- coding: utf-8 -*-

import time
import json
import asyncio
from datetime import datetime
from typing import List, Dict, Any
from fastapi import APIRouter, Header, HTTPException
from fastapi.responses import StreamingResponse
import httpx

from app.core.config import settings
from app.models.schemas import OpenAIRequest, Message, ModelsResponse, Model
from app.utils.logger import get_logger
from app.core.zai_transformer import ZAITransformer, generate_uuid
from app.utils.sse_tool_handler import SSEToolHandler

logger = get_logger()

router = APIRouter()

# å…¨å±€è½¬æ¢å™¨å®ä¾‹
transformer = ZAITransformer()


@router.get("/v1/models")
async def list_models():
    """List available models"""
    current_time = int(time.time())
    response = ModelsResponse(
        data=[
            Model(id=settings.PRIMARY_MODEL, created=current_time, owned_by="z.ai"),
            Model(id=settings.THINKING_MODEL, created=current_time, owned_by="z.ai"),
            Model(id=settings.SEARCH_MODEL, created=current_time, owned_by="z.ai"),
            Model(id=settings.AIR_MODEL, created=current_time, owned_by="z.ai"),
        ]
    )
    return response


@router.post("/v1/chat/completions")
async def chat_completions(request: OpenAIRequest, authorization: str = Header(...)):
    """Handle chat completion requests with ZAI transformer"""
    logger.info(f"ğŸ“¥ æ”¶åˆ° OpenAI è¯·æ±‚ - æ¨¡å‹: {request.model}, æµå¼: {request.stream}")
    logger.debug(f"è¯·æ±‚è¯¦æƒ… - æ¶ˆæ¯æ•°: {len(request.messages)}, å·¥å…·æ•°: {len(request.tools) if request.tools else 0}")
    
    # è¾“å‡ºæ¶ˆæ¯å†…å®¹ç”¨äºè°ƒè¯•
    for idx, msg in enumerate(request.messages):
        content_preview = str(msg.content)[:1000] if msg.content else "None"
        logger.debug(f"  æ¶ˆæ¯[{idx}] - è§’è‰²: {msg.role}, å†…å®¹é¢„è§ˆ: {content_preview}...")

    try:
        # Validate API key (skip if SKIP_AUTH_TOKEN is enabled)
        if not settings.SKIP_AUTH_TOKEN:
            if not authorization.startswith("Bearer "):
                logger.debug("ç¼ºå°‘æˆ–æ— æ•ˆçš„Authorizationå¤´")
                raise HTTPException(status_code=401, detail="Missing or invalid Authorization header")

            api_key = authorization[7:]
            if api_key != settings.AUTH_TOKEN:
                logger.debug(f"æ— æ•ˆçš„API key: {api_key}")
                raise HTTPException(status_code=401, detail="Invalid API key")

            logger.debug(f"API keyéªŒè¯é€šè¿‡")
        else:
            logger.debug("SKIP_AUTH_TOKENå·²å¯ç”¨ï¼Œè·³è¿‡API keyéªŒè¯")

        # è¾“å‡ºåŸå§‹è¯·æ±‚ä½“ç”¨äºè°ƒè¯•
        request_dict = request.model_dump()
        # logger.debug(f"ğŸ”„ åŸå§‹ OpenAI è¯·æ±‚ä½“: {json.dumps(request_dict, ensure_ascii=False, indent=2)}")
        
        # ä½¿ç”¨æ–°çš„è½¬æ¢å™¨è½¬æ¢è¯·æ±‚
        logger.info("ğŸ”„ å¼€å§‹è½¬æ¢è¯·æ±‚æ ¼å¼: OpenAI -> Z.AI")
        transformed = await transformer.transform_request_in(request_dict)

        logger.info(
            f"âœ… è¯·æ±‚è½¬æ¢å®Œæˆ - ä¸Šæ¸¸æ¨¡å‹: {transformed['body']['model']}, "
            f"chat_id: {transformed['body']['chat_id']}"
        )
        logger.debug(
            f"  ç‰¹æ€§é…ç½® - enable_thinking: {transformed['body']['features']['enable_thinking']}, "
            f"web_search: {transformed['body']['features']['web_search']}, "
            f"mcp_servers: {transformed['body'].get('mcp_servers', [])}"
        )
        # logger.debug(f"ğŸ”„ è½¬æ¢å Z.AI è¯·æ±‚ä½“: {json.dumps(transformed['body'], ensure_ascii=False, indent=2)}")

        # è°ƒç”¨ä¸Šæ¸¸API
        async def stream_response():
            """æµå¼å“åº”ç”Ÿæˆå™¨ï¼ˆåŒ…å«é‡è¯•æœºåˆ¶ï¼‰"""
            retry_count = 0
            last_error = None

            while retry_count <= settings.MAX_RETRIES:
                try:
                    # å¦‚æœæ˜¯é‡è¯•ï¼Œé‡æ–°è·å–ä»¤ç‰Œå¹¶æ›´æ–°è¯·æ±‚
                    if retry_count > 0:
                        delay = settings.RETRY_DELAY * (settings.RETRY_BACKOFF ** (retry_count - 1))
                        logger.warning(
                            f"ğŸ”„ é‡è¯•è¯·æ±‚ ({retry_count}/{settings.MAX_RETRIES}) - "
                            f"ç­‰å¾… {delay:.1f} ç§’åé‡è¯•..."
                        )
                        await asyncio.sleep(delay)

                        # åœ¨åŒ¿åæ¨¡å¼ä¸‹ï¼Œé‡æ–°è·å–ä»¤ç‰Œ
                        if settings.ANONYMOUS_MODE:
                            logger.info("ğŸ”‘ é‡æ–°è·å–è®¿å®¢ä»¤ç‰Œç”¨äºé‡è¯•...")
                            new_token = await transformer.get_token()
                            transformed["config"]["headers"]["Authorization"] = f"Bearer {new_token}"
                            logger.debug(f"  æ–°ä»¤ç‰Œ: {new_token[:20] if new_token else 'None'}...")

                    async with httpx.AsyncClient(timeout=60.0) as client:
                        # å‘é€è¯·æ±‚åˆ°ä¸Šæ¸¸
                        logger.info(f"ğŸ¯ å‘é€è¯·æ±‚åˆ° Z.AI: {transformed['config']['url']}")
                        logger.debug(f"  è¯·æ±‚å¤´æ•°é‡: {len(transformed['config']['headers'])}")

                        async with client.stream(
                            "POST",
                            transformed["config"]["url"],
                            json=transformed["body"],
                            headers=transformed["config"]["headers"],
                        ) as response:
                            # æ£€æŸ¥å“åº”çŠ¶æ€ç 
                            if response.status_code == 400:
                                # 400 é”™è¯¯ï¼Œè§¦å‘é‡è¯•
                                error_text = await response.aread()
                                error_msg = error_text.decode('utf-8', errors='ignore')
                                logger.warning(
                                    f"âš ï¸ ä¸Šæ¸¸è¿”å› 400 é”™è¯¯ (å°è¯• {retry_count + 1}/{settings.MAX_RETRIES + 1})"
                                )
                                logger.debug(f"  é”™è¯¯è¯¦æƒ…: {error_msg}")

                                retry_count += 1
                                last_error = f"400 Bad Request: {error_msg}"

                                # å¦‚æœè¿˜æœ‰é‡è¯•æœºä¼šï¼Œç»§ç»­å¾ªç¯
                                if retry_count <= settings.MAX_RETRIES:
                                    continue
                                else:
                                    # è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ŒæŠ›å‡ºé”™è¯¯
                                    logger.error(f"âŒ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({settings.MAX_RETRIES})ï¼Œè¯·æ±‚å¤±è´¥")
                                    error_response = {
                                        "error": {
                                            "message": f"Request failed after {settings.MAX_RETRIES} retries: {last_error}",
                                            "type": "upstream_error",
                                            "code": 400
                                        }
                                    }
                                    yield f"data: {json.dumps(error_response)}\n\n"
                                    yield "data: [DONE]\n\n"
                                    return

                            elif response.status_code != 200:
                                # å…¶ä»–é”™è¯¯ï¼Œç›´æ¥è¿”å›
                                logger.error(f"âŒ ä¸Šæ¸¸è¿”å›é”™è¯¯: {response.status_code}")
                                error_text = await response.aread()
                                error_msg = error_text.decode('utf-8', errors='ignore')
                                logger.error(f"é”™è¯¯è¯¦æƒ…: {error_msg}")

                                error_response = {
                                    "error": {
                                        "message": f"Upstream error: {response.status_code}",
                                        "type": "upstream_error",
                                        "code": response.status_code
                                    }
                                }
                                yield f"data: {json.dumps(error_response)}\n\n"
                                yield "data: [DONE]\n\n"
                                return

                            # 200 æˆåŠŸï¼Œå¤„ç†å“åº”
                            logger.info(f"âœ… Z.AI å“åº”æˆåŠŸï¼Œå¼€å§‹å¤„ç† SSE æµ")
                            if retry_count > 0:
                                logger.info(f"âœ¨ ç¬¬ {retry_count} æ¬¡é‡è¯•æˆåŠŸ")

                            # åˆå§‹åŒ–å·¥å…·å¤„ç†å™¨ï¼ˆå¦‚æœéœ€è¦ï¼‰
                            has_tools = transformed["body"].get("tools") is not None
                            tool_handler = None
                            if has_tools:
                                chat_id = transformed["body"]["chat_id"]
                                model = request.model
                                tool_handler = SSEToolHandler(chat_id, model)
                                logger.info(f"ğŸ”§ åˆå§‹åŒ–å·¥å…·å¤„ç†å™¨ - chat_id: {chat_id}, å·¥å…·æ•°: {len(transformed['body'].get('tools', []))}")

                            # å¤„ç†çŠ¶æ€
                            has_thinking = False
                            thinking_signature = None

                            # å¤„ç†SSEæµ
                            buffer = ""
                            line_count = 0
                            logger.debug("ğŸ“¡ å¼€å§‹æ¥æ”¶ SSE æµæ•°æ®...")

                            async for line in response.aiter_lines():
                                line_count += 1
                                if not line:
                                    # logger.debug(f"  è¡Œ[{line_count}]: ç©ºè¡Œï¼Œè·³è¿‡")
                                    continue

                                logger.debug(f"  è¡Œ[{line_count}]: æ¥æ”¶åˆ°æ•°æ® - {line[:1000]}..." if len(line) > 1000 else f"  è¡Œ[{line_count}]: æ¥æ”¶åˆ°æ•°æ® - {line}")

                                # ç´¯ç§¯åˆ°bufferå¤„ç†å®Œæ•´çš„æ•°æ®è¡Œ
                                buffer += line + "\n"

                                # æ£€æŸ¥æ˜¯å¦æœ‰å®Œæ•´çš„dataè¡Œ
                                while "\n" in buffer:
                                    current_line, buffer = buffer.split("\n", 1)
                                    if not current_line.strip():
                                        continue

                                    if current_line.startswith("data:"):
                                        chunk_str = current_line[5:].strip()
                                        if not chunk_str or chunk_str == "[DONE]":
                                            if chunk_str == "[DONE]":
                                                logger.debug("ğŸ æ”¶åˆ°ç»“æŸä¿¡å· [DONE]")
                                                yield "data: [DONE]\n\n"
                                            continue

                                        logger.debug(f"  ğŸ“¦ è§£ææ•°æ®å—: {chunk_str[:1000]}..." if len(chunk_str) > 1000 else f"  ğŸ“¦ è§£ææ•°æ®å—: {chunk_str}")

                                        try:
                                            chunk = json.loads(chunk_str)

                                            if chunk.get("type") == "chat:completion":
                                                data = chunk.get("data", {})
                                                phase = data.get("phase")

                                                # è®°å½•æ¯ä¸ªé˜¶æ®µï¼ˆåªåœ¨é˜¶æ®µå˜åŒ–æ—¶è®°å½•ï¼‰
                                                if phase and phase != getattr(stream_response, '_last_phase', None):
                                                    logger.info(f"ğŸ“ˆ SSE é˜¶æ®µå˜åŒ–: {getattr(stream_response, '_last_phase', 'None')} -> {phase}")
                                                    stream_response._last_phase = phase

                                                # å¤„ç†å·¥å…·è°ƒç”¨
                                                if phase == "tool_call" and tool_handler:
                                                    for output in tool_handler.process_tool_call_phase(data, True):
                                                        yield output

                                                # å¤„ç†å…¶ä»–é˜¶æ®µï¼ˆå·¥å…·ç»“æŸï¼‰
                                                elif phase == "other" and tool_handler:
                                                    for output in tool_handler.process_other_phase(data, True):
                                                        yield output

                                                # å¤„ç†æ€è€ƒå†…å®¹
                                                elif phase == "thinking":
                                                    if not has_thinking:
                                                        has_thinking = True
                                                        has_thinking = True
                                                        # å‘é€åˆå§‹è§’è‰²
                                                        role_chunk = {
                                                            "choices": [
                                                                {
                                                                    "delta": {"role": "assistant"},
                                                                    "finish_reason": None,
                                                                    "index": 0,
                                                                    "logprobs": None,
                                                                }
                                                            ],
                                                            "created": int(time.time()),
                                                            "id": transformed["body"]["chat_id"],
                                                            "model": request.model,
                                                            "object": "chat.completion.chunk",
                                                            "system_fingerprint": "fp_zai_001",
                                                        }
                                                        logger.debug("    â¡ï¸ å‘é€åˆå§‹è§’è‰²")
                                                        yield f"data: {json.dumps(role_chunk)}\n\n"

                                                    delta_content = data.get("delta_content", "")
                                                    if delta_content:
                                                        # å¤„ç†æ€è€ƒå†…å®¹æ ¼å¼
                                                        if delta_content.startswith("<details"):
                                                            content = (
                                                                delta_content.split("</summary>\n>")[-1].strip()
                                                                if "</summary>\n>" in delta_content
                                                                else delta_content
                                                            )
                                                        else:
                                                            content = delta_content

                                                        thinking_chunk = {
                                                            "choices": [
                                                                {
                                                                    "delta": {
                                                                        "role": "assistant",
                                                                        "thinking": {"content": content},
                                                                    },
                                                                    "finish_reason": None,
                                                                    "index": 0,
                                                                    "logprobs": None,
                                                                }
                                                            ],
                                                            "created": int(time.time()),
                                                            "id": transformed["body"]["chat_id"],
                                                            "model": request.model,
                                                            "object": "chat.completion.chunk",
                                                            "system_fingerprint": "fp_zai_001",
                                                        }
                                                        yield f"data: {json.dumps(thinking_chunk)}\n\n"

                                                # å¤„ç†ç­”æ¡ˆå†…å®¹
                                                elif phase == "answer":
                                                    edit_content = data.get("edit_content", "")
                                                    delta_content = data.get("delta_content", "")

                                                    # å¤„ç†æ€è€ƒç»“æŸå’Œç­”æ¡ˆå¼€å§‹
                                                    if edit_content and "</details>\n" in edit_content:
                                                        if has_thinking:
                                                            # å‘é€æ€è€ƒç­¾å
                                                            thinking_signature = str(int(time.time() * 1000))
                                                            sig_chunk = {
                                                                "choices": [
                                                                    {
                                                                        "delta": {
                                                                            "role": "assistant",
                                                                            "thinking": {
                                                                                "content": "",
                                                                                "signature": thinking_signature,
                                                                            },
                                                                        },
                                                                        "finish_reason": None,
                                                                        "index": 0,
                                                                        "logprobs": None,
                                                                    }
                                                                ],
                                                                "created": int(time.time()),
                                                                "id": transformed["body"]["chat_id"],
                                                                "model": request.model,
                                                                "object": "chat.completion.chunk",
                                                                "system_fingerprint": "fp_zai_001",
                                                            }
                                                            yield f"data: {json.dumps(sig_chunk)}\n\n"

                                                        # æå–ç­”æ¡ˆå†…å®¹
                                                        content_after = edit_content.split("</details>\n")[-1]
                                                        if content_after:
                                                            content_chunk = {
                                                                "choices": [
                                                                    {
                                                                        "delta": {
                                                                            "role": "assistant",
                                                                            "content": content_after,
                                                                        },
                                                                        "finish_reason": None,
                                                                        "index": 0,
                                                                        "logprobs": None,
                                                                    }
                                                                ],
                                                                "created": int(time.time()),
                                                                "id": transformed["body"]["chat_id"],
                                                                "model": request.model,
                                                                "object": "chat.completion.chunk",
                                                                "system_fingerprint": "fp_zai_001",
                                                            }
                                                            yield f"data: {json.dumps(content_chunk)}\n\n"

                                                    # å¤„ç†å¢é‡å†…å®¹
                                                    elif delta_content:
                                                        logger.debug(f"    ğŸ“ ç­”æ¡ˆå†…å®¹ç‰‡æ®µ: {delta_content[:1000]}...")
                                                        # å¦‚æœè¿˜æ²¡æœ‰å‘é€è§’è‰²
                                                        if not has_thinking:
                                                            role_chunk = {
                                                                "choices": [
                                                                    {
                                                                        "delta": {"role": "assistant"},
                                                                        "finish_reason": None,
                                                                        "index": 0,
                                                                        "logprobs": None,
                                                                    }
                                                                ],
                                                                "created": int(time.time()),
                                                                "id": transformed["body"]["chat_id"],
                                                                "model": request.model,
                                                                "object": "chat.completion.chunk",
                                                                "system_fingerprint": "fp_zai_001",
                                                            }
                                                            yield f"data: {json.dumps(role_chunk)}\n\n"

                                                        content_chunk = {
                                                            "choices": [
                                                                {
                                                                    "delta": {
                                                                        "role": "assistant",
                                                                        "content": delta_content,
                                                                    },
                                                                    "finish_reason": None,
                                                                    "index": 0,
                                                                    "logprobs": None,
                                                                }
                                                            ],
                                                            "created": int(time.time()),
                                                            "id": transformed["body"]["chat_id"],
                                                            "model": request.model,
                                                            "object": "chat.completion.chunk",
                                                            "system_fingerprint": "fp_zai_001",
                                                        }
                                                        output_data = f"data: {json.dumps(content_chunk)}\n\n"
                                                        logger.debug(f"    â¡ï¸ è¾“å‡ºå†…å®¹å—åˆ°å®¢æˆ·ç«¯: {output_data[:1000]}...")
                                                        yield output_data

                                                    # å¤„ç†å®Œæˆ
                                                    if data.get("usage"):
                                                        logger.info(f"ğŸ“¦ å®Œæˆå“åº” - ä½¿ç”¨ç»Ÿè®¡: {json.dumps(data['usage'])}")

                                                        # åªæœ‰åœ¨éå·¥å…·è°ƒç”¨æ¨¡å¼ä¸‹æ‰å‘é€æ™®é€šå®Œæˆä¿¡å·
                                                        if not tool_handler or not tool_handler.has_tool_call:
                                                            finish_chunk = {
                                                                "choices": [
                                                                    {
                                                                        "delta": {"role": "assistant", "content": ""},
                                                                        "finish_reason": "stop",
                                                                        "index": 0,
                                                                        "logprobs": None,
                                                                    }
                                                                ],
                                                                "usage": data["usage"],
                                                                "created": int(time.time()),
                                                                "id": transformed["body"]["chat_id"],
                                                                "model": request.model,
                                                                "object": "chat.completion.chunk",
                                                                "system_fingerprint": "fp_zai_001",
                                                            }
                                                            finish_output = f"data: {json.dumps(finish_chunk)}\n\n"
                                                            logger.debug(f"    â¡ï¸ å‘é€å®Œæˆä¿¡å·: {finish_output[:1000]}...")
                                                            yield finish_output
                                                            logger.debug("    â¡ï¸ å‘é€ [DONE]")
                                                            yield "data: [DONE]\n\n"

                                        except json.JSONDecodeError as e:
                                            logger.debug(f"JSONè§£æé”™è¯¯: {e}, å†…å®¹: {chunk_str[:1000]}")
                                        except Exception as e:
                                            logger.error(f"å¤„ç†chunké”™è¯¯: {e}")

                            # ç¡®ä¿å‘é€ç»“æŸä¿¡å·
                            if not tool_handler or not tool_handler.has_tool_call:
                                logger.debug("ğŸ“¤ å‘é€æœ€ç»ˆ [DONE] ä¿¡å·")
                                yield "data: [DONE]\n\n"

                            logger.info(f"âœ… SSE æµå¤„ç†å®Œæˆï¼Œå…±å¤„ç† {line_count} è¡Œæ•°æ®")
                            # æˆåŠŸå¤„ç†å®Œæˆï¼Œé€€å‡ºé‡è¯•å¾ªç¯
                            return

                except Exception as e:
                    logger.error(f"æµå¤„ç†é”™è¯¯: {e}")
                    import traceback
                    logger.error(traceback.format_exc())

                    # æ£€æŸ¥æ˜¯å¦è¿˜å¯ä»¥é‡è¯•
                    retry_count += 1
                    last_error = str(e)

                    if retry_count > settings.MAX_RETRIES:
                        # è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œè¿”å›é”™è¯¯
                        logger.error(f"âŒ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({settings.MAX_RETRIES})ï¼Œæµå¤„ç†å¤±è´¥")
                        error_response = {
                            "error": {
                                "message": f"Stream processing failed after {settings.MAX_RETRIES} retries: {last_error}",
                                "type": "stream_error"
                            }
                        }
                        yield f"data: {json.dumps(error_response)}\n\n"
                        yield "data: [DONE]\n\n"
                        return

        # è¿”å›æµå¼å“åº”
        logger.info("ğŸš€ å¯åŠ¨ SSE æµå¼å“åº”")
        
        # åˆ›å»ºä¸€ä¸ªåŒ…è£…çš„ç”Ÿæˆå™¨æ¥è¿½è¸ªæ•°æ®æµ
        async def logged_stream():
            chunk_count = 0
            try:
                logger.debug("ğŸ“¤ å¼€å§‹å‘å®¢æˆ·ç«¯æµå¼ä¼ è¾“æ•°æ®...")
                async for chunk in stream_response():
                    chunk_count += 1
                    logger.debug(f"  ğŸ“¤ å‘é€å—[{chunk_count}]: {chunk[:1000]}..." if len(chunk) > 1000 else f"  ğŸ“¤ å‘é€å—[{chunk_count}]: {chunk}")
                    yield chunk
                logger.info(f"âœ… æµå¼ä¼ è¾“å®Œæˆï¼Œå…±å‘é€ {chunk_count} ä¸ªæ•°æ®å—")
            except Exception as e:
                logger.error(f"âŒ æµå¼ä¼ è¾“ä¸­æ–­: {e}")
                raise
        
        return StreamingResponse(
            logged_stream(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
            },
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback

        logger.error(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")
