#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
æµ‹è¯•GLM-4.5-Searchæ¨¡å‹çš„deep-web-search MCPæœåŠ¡å™¨åŠŸèƒ½
"""

import asyncio
import json
import httpx
from app.core.config import settings
from app.core.zai_transformer import ZAITransformer
from app.utils.logger import setup_logger

# è®¾ç½®æ—¥å¿—
logger = setup_logger(log_dir="logs", debug_mode=True)

async def test_search_model_mcp():
    """æµ‹è¯•æœç´¢æ¨¡å‹çš„MCPæœåŠ¡å™¨é…ç½®"""
    
    # åˆ›å»ºè½¬æ¢å™¨å®ä¾‹
    transformer = ZAITransformer()
    
    # æ¨¡æ‹ŸOpenAIè¯·æ±‚ - ä½¿ç”¨GLM-4.5-Searchæ¨¡å‹
    openai_request = {
        "model": "GLM-4.5-Search",
        "messages": [
            {"role": "user", "content": "è¯·æœç´¢ä¸€ä¸‹ä»Šå¤©çš„æ–°é—»"}
        ],
        "stream": True
    }
    
    print(f"ğŸ§ª æµ‹è¯•è¯·æ±‚:")
    print(f"  æ¨¡å‹: {openai_request['model']}")
    print(f"  SEARCH_MODELé…ç½®: {settings.SEARCH_MODEL}")
    print(f"  æ¨¡å‹åŒ¹é…: {openai_request['model'] == settings.SEARCH_MODEL}")
    print()
    
    try:
        # è½¬æ¢è¯·æ±‚
        transformed = await transformer.transform_request_in(openai_request)
        
        print(f"âœ… è½¬æ¢æˆåŠŸ!")
        print(f"  ä¸Šæ¸¸æ¨¡å‹: {transformed['body']['model']}")
        print(f"  MCPæœåŠ¡å™¨: {transformed['body']['mcp_servers']}")
        print(f"  web_searchç‰¹æ€§: {transformed['body']['features']['web_search']}")
        print(f"  auto_web_searchç‰¹æ€§: {transformed['body']['features']['auto_web_search']}")
        print()
        
        # æ£€æŸ¥æ˜¯å¦æ­£ç¡®æ·»åŠ äº†deep-web-search
        mcp_servers = transformed['body']['mcp_servers']
        if "deep-web-search" in mcp_servers:
            print("âœ… deep-web-search MCPæœåŠ¡å™¨å·²æ­£ç¡®æ·»åŠ !")
        else:
            print("âŒ deep-web-search MCPæœåŠ¡å™¨æœªæ·»åŠ !")
            print(f"   å®é™…MCPæœåŠ¡å™¨åˆ—è¡¨: {mcp_servers}")
        
        return transformed
        
    except Exception as e:
        print(f"âŒ è½¬æ¢å¤±è´¥: {e}")
        return None

async def test_non_search_model():
    """æµ‹è¯•éæœç´¢æ¨¡å‹ä¸åº”è¯¥æ·»åŠ MCPæœåŠ¡å™¨"""
    
    transformer = ZAITransformer()
    
    # æ¨¡æ‹ŸOpenAIè¯·æ±‚ - ä½¿ç”¨æ™®é€šGLM-4.5æ¨¡å‹
    openai_request = {
        "model": "GLM-4.5",
        "messages": [
            {"role": "user", "content": "ä½ å¥½"}
        ],
        "stream": True
    }
    
    print(f"ğŸ§ª æµ‹è¯•æ™®é€šæ¨¡å‹:")
    print(f"  æ¨¡å‹: {openai_request['model']}")
    print()
    
    try:
        # è½¬æ¢è¯·æ±‚
        transformed = await transformer.transform_request_in(openai_request)
        
        print(f"âœ… è½¬æ¢æˆåŠŸ!")
        print(f"  ä¸Šæ¸¸æ¨¡å‹: {transformed['body']['model']}")
        print(f"  MCPæœåŠ¡å™¨: {transformed['body']['mcp_servers']}")
        print(f"  web_searchç‰¹æ€§: {transformed['body']['features']['web_search']}")
        print()
        
        # æ£€æŸ¥MCPæœåŠ¡å™¨åˆ—è¡¨åº”è¯¥ä¸ºç©º
        mcp_servers = transformed['body']['mcp_servers']
        if not mcp_servers:
            print("âœ… æ™®é€šæ¨¡å‹æ­£ç¡®åœ°æ²¡æœ‰æ·»åŠ MCPæœåŠ¡å™¨!")
        else:
            print(f"âŒ æ™®é€šæ¨¡å‹æ„å¤–æ·»åŠ äº†MCPæœåŠ¡å™¨: {mcp_servers}")
        
        return transformed
        
    except Exception as e:
        print(f"âŒ è½¬æ¢å¤±è´¥: {e}")
        return None

async def test_actual_request():
    """æµ‹è¯•å®é™…çš„HTTPè¯·æ±‚"""
    
    print(f"ğŸŒ æµ‹è¯•å®é™…HTTPè¯·æ±‚åˆ°æœ¬åœ°æœåŠ¡å™¨...")
    
    # æ£€æŸ¥æœåŠ¡å™¨æ˜¯å¦è¿è¡Œ
    try:
        async with httpx.AsyncClient() as client:
            # æµ‹è¯•æœåŠ¡å™¨æ˜¯å¦å¯è¾¾
            response = await client.get(f"http://localhost:{settings.LISTEN_PORT}/v1/models", timeout=5.0)
            if response.status_code != 200:
                print(f"âŒ æœåŠ¡å™¨æœªè¿è¡Œæˆ–ä¸å¯è¾¾: {response.status_code}")
                return
                
            print(f"âœ… æœåŠ¡å™¨è¿è¡Œæ­£å¸¸")
            
            # å‘é€æœç´¢æ¨¡å‹è¯·æ±‚
            search_request = {
                "model": "GLM-4.5-Search",
                "messages": [
                    {"role": "user", "content": "æœç´¢ä»Šå¤©çš„å¤©æ°”"}
                ],
                "stream": False
            }
            
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {settings.AUTH_TOKEN}"
            }
            
            print(f"ğŸ“¤ å‘é€æœç´¢è¯·æ±‚...")
            response = await client.post(
                f"http://localhost:{settings.LISTEN_PORT}/v1/chat/completions",
                json=search_request,
                headers=headers,
                timeout=30.0
            )
            
            print(f"ğŸ“¥ å“åº”çŠ¶æ€: {response.status_code}")
            if response.status_code == 200:
                print(f"âœ… è¯·æ±‚æˆåŠŸ!")
                # ä¸æ‰“å°å®Œæ•´å“åº”ï¼Œåªæ˜¾ç¤ºçŠ¶æ€
            else:
                print(f"âŒ è¯·æ±‚å¤±è´¥: {response.text}")
                
    except httpx.ConnectError:
        print(f"âŒ æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨ localhost:{settings.LISTEN_PORT}")
        print(f"   è¯·ç¡®ä¿æœåŠ¡å™¨æ­£åœ¨è¿è¡Œ: python main.py")
    except Exception as e:
        print(f"âŒ è¯·æ±‚å¼‚å¸¸: {e}")

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("=" * 60)
    print("GLM-4.5-Search MCPæœåŠ¡å™¨æµ‹è¯•")
    print("=" * 60)
    print()
    
    # æµ‹è¯•1: æœç´¢æ¨¡å‹åº”è¯¥æ·»åŠ MCPæœåŠ¡å™¨
    await test_search_model_mcp()
    print()
    
    # æµ‹è¯•2: æ™®é€šæ¨¡å‹ä¸åº”è¯¥æ·»åŠ MCPæœåŠ¡å™¨
    await test_non_search_model()
    print()
    
    # æµ‹è¯•3: å®é™…HTTPè¯·æ±‚ï¼ˆå¦‚æœæœåŠ¡å™¨è¿è¡Œï¼‰
    await test_actual_request()
    print()
    
    print("=" * 60)
    print("æµ‹è¯•å®Œæˆ")
    print("=" * 60)

if __name__ == "__main__":
    asyncio.run(main())
