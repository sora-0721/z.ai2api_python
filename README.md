# Z.AI OpenAI & Anthropic API ä»£ç†æœåŠ¡

![License: MIT](https://img.shields.io/badge/license-MIT-blue.svg)
![Python: 3.8+](https://img.shields.io/badge/python-3.8+-green.svg)
![FastAPI](https://img.shields.io/badge/framework-FastAPI-009688.svg)

ä¸º Z.AI æä¾› OpenAI å’Œ Anthropic API å…¼å®¹æ¥å£çš„è½»é‡çº§ä»£ç†æœåŠ¡ï¼Œæ”¯æŒ GLM-4.5 ç³»åˆ—æ¨¡å‹çš„å®Œæ•´åŠŸèƒ½ã€‚

## âœ¨ æ ¸å¿ƒç‰¹æ€§

- ğŸ”Œ **å®Œå…¨å…¼å®¹ OpenAI API** - æ— ç¼é›†æˆç°æœ‰åº”ç”¨
- ğŸ­ **å…¼å®¹ Anthropic API** - æ”¯æŒ Claude CLI å®¢æˆ·ç«¯ç›´æ¥æ¥å…¥
- ğŸš€ **é«˜æ€§èƒ½æµå¼å“åº”** - Server-Sent Events (SSE) æ”¯æŒ
- ğŸ› ï¸ **Function Call æ”¯æŒ** - å®Œæ•´çš„å·¥å…·è°ƒç”¨åŠŸèƒ½
- ğŸ§  **æ€è€ƒæ¨¡å¼æ”¯æŒ** - æ™ºèƒ½å¤„ç†æ¨¡å‹æ¨ç†è¿‡ç¨‹
- ğŸ” **æœç´¢æ¨¡å‹é›†æˆ** - GLM-4.5-Search ç½‘ç»œæœç´¢èƒ½åŠ›
- ğŸ³ **Docker éƒ¨ç½²** - ä¸€é”®å®¹å™¨åŒ–éƒ¨ç½²
- ğŸ›¡ï¸ **ä¼šè¯éš”ç¦»** - åŒ¿åæ¨¡å¼ä¿æŠ¤éšç§
- ğŸ”§ **é«˜åº¦å¯é…ç½®** - ç¯å¢ƒå˜é‡çµæ´»é…ç½®

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

- Python 3.8+
- pip æˆ– uv (æ¨è)

### å®‰è£…è¿è¡Œ

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/ZyphrZero/z.ai2api_python.git
cd z.ai2api_python

# ä½¿ç”¨ uv (æ¨è)
curl -LsSf https://astral.sh/uv/install.sh | sh
uv sync
uv run python main.py

# æˆ–ä½¿ç”¨ pip (æ¨èä½¿ç”¨æ¸…åæº)
pip install -r requirement.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
python main.py
```

æœåŠ¡å¯åŠ¨åè®¿é—®ï¼šhttp://localhost:8080/docs

### åŸºç¡€ä½¿ç”¨

#### OpenAI API å®¢æˆ·ç«¯

```python
import openai

# åˆå§‹åŒ–å®¢æˆ·ç«¯
client = openai.OpenAI(
    base_url="http://localhost:8080/v1",
    api_key="your-auth-token"  # æ›¿æ¢ä¸ºä½ çš„ AUTH_TOKEN
)

# æ™®é€šå¯¹è¯
response = client.chat.completions.create(
    model="GLM-4.5",
    messages=[{"role": "user", "content": "ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹ Python"}],
    stream=False
)

print(response.choices[0].message.content)
```

#### Anthropic API å®¢æˆ·ç«¯

```python
import anthropic

# åˆå§‹åŒ–å®¢æˆ·ç«¯
client = anthropic.Anthropic(
    base_url="http://localhost:8080/v1",
    api_key="your-anthropic-token"  # æ›¿æ¢ä¸ºä½ çš„ ANTHROPIC_API_KEY
)

# æ™®é€šå¯¹è¯
message = client.messages.create(
    model="GLM-4.5",
    max_tokens=1024,
    messages=[
        {"role": "user", "content": "ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹ Python"}
    ]
)

print(message.content[0].text)
```

### Docker éƒ¨ç½²

```bash
cd deploy
docker-compose up -d
```

## ğŸ“– è¯¦ç»†æŒ‡å—

### æ”¯æŒçš„æ¨¡å‹

| æ¨¡å‹ | æè¿° | ç‰¹æ€§ |
|------|------|------|
| `GLM-4.5` | æ ‡å‡†æ¨¡å‹ | é€šç”¨å¯¹è¯ï¼Œå¹³è¡¡æ€§èƒ½ |
| `GLM-4.5-Thinking` | æ€è€ƒæ¨¡å‹ | æ˜¾ç¤ºæ¨ç†è¿‡ç¨‹ï¼Œé€æ˜åº¦é«˜ |
| `GLM-4.5-Search` | æœç´¢æ¨¡å‹ | å®æ—¶ç½‘ç»œæœç´¢ï¼Œä¿¡æ¯æ›´æ–° |

### Function Call åŠŸèƒ½

```python
# å®šä¹‰å·¥å…·
tools = [{
    "type": "function",
    "function": {
        "name": "get_weather",
        "description": "è·å–å¤©æ°”ä¿¡æ¯",
        "parameters": {
            "type": "object",
            "properties": {
                "city": {"type": "string", "description": "åŸå¸‚åç§°"}
            },
            "required": ["city"]
        }
    }
}]

# ä½¿ç”¨å·¥å…·
response = client.chat.completions.create(
    model="GLM-4.5",
    messages=[{"role": "user", "content": "åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"}],
    tools=tools,
    tool_choice="auto"
)
```

### æµå¼å“åº”

```python
response = client.chat.completions.create(
    model="GLM-4.5-Thinking",
    messages=[{"role": "user", "content": "è§£é‡Šé‡å­è®¡ç®—"}],
    stream=True
)

for chunk in response:
    content = chunk.choices[0].delta.content
    reasoning = chunk.choices[0].delta.reasoning_content
    
    if content:
        print(content, end="")
    if reasoning:
        print(f"\nğŸ¤” æ€è€ƒ: {reasoning}\n")
```

## âš™ï¸ é…ç½®è¯´æ˜

### ç¯å¢ƒå˜é‡é…ç½®

| å˜é‡å | é»˜è®¤å€¼ | è¯´æ˜ |
|--------|--------|------|
| `AUTH_TOKEN` | `sk-your-api-key` | å®¢æˆ·ç«¯è®¤è¯å¯†é’¥ï¼ˆOpenAI å’Œ Anthropic å…±ç”¨ï¼‰ |
| `API_ENDPOINT` | `https://chat.z.ai/api/chat/completions` | ä¸Šæ¸¸ API åœ°å€ |
| `LISTEN_PORT` | `8080` | æœåŠ¡ç›‘å¬ç«¯å£ |
| `DEBUG_LOGGING` | `true` | è°ƒè¯•æ—¥å¿—å¼€å…³ |
| `THINKING_PROCESSING` | `think` | æ€è€ƒå†…å®¹å¤„ç†ç­–ç•¥ |
| `ANONYMOUS_MODE` | `true` | åŒ¿åæ¨¡å¼å¼€å…³ |
| `TOOL_SUPPORT` | `true` | Function Call åŠŸèƒ½å¼€å…³ |

### æ€è€ƒå†…å®¹å¤„ç†ç­–ç•¥

- `think` - è½¬æ¢ä¸º `<thinking>` æ ‡ç­¾ï¼ˆOpenAI å…¼å®¹ï¼‰
- `strip` - ç§»é™¤æ€è€ƒå†…å®¹
- `raw` - ä¿ç•™åŸå§‹æ ¼å¼

## ğŸ¯ ä½¿ç”¨åœºæ™¯

### 1. AI åº”ç”¨å¼€å‘

```python
# é›†æˆåˆ°ç°æœ‰åº”ç”¨
from openai import OpenAI

client = OpenAI(
    base_url="http://localhost:8080/v1",
    api_key="your-token"
)

# æ™ºèƒ½å®¢æœ
def chat_with_ai(message):
    response = client.chat.completions.create(
        model="GLM-4.5",
        messages=[{"role": "user", "content": message}]
    )
    return response.choices[0].message.content
```

### 2. å¤šæ¨¡å‹å¯¹æ¯”æµ‹è¯•

```python
models = ["GLM-4.5", "GLM-4.5-Thinking", "GLM-4.5-Search"]

for model in models:
    response = client.chat.completions.create(
        model=model,
        messages=[{"role": "user", "content": "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ"}]
    )
    print(f"\n=== {model} ===")
    print(response.choices[0].message.content)
```

### 3. å·¥å…·è°ƒç”¨é›†æˆ

```python
# ç»“åˆå¤–éƒ¨ API
def call_external_api(tool_name, arguments):
    # æ‰§è¡Œå®é™…å·¥å…·è°ƒç”¨
    return result

# å¤„ç†å·¥å…·è°ƒç”¨
if response.choices[0].message.tool_calls:
    for tool_call in response.choices[0].message.tool_calls:
        result = call_external_api(
            tool_call.function.name,
            json.loads(tool_call.function.arguments)
        )
        # å°†ç»“æœè¿”å›ç»™æ¨¡å‹ç»§ç»­å¯¹è¯
```

## â“ å¸¸è§é—®é¢˜

**Q: å¦‚ä½•è·å– AUTH_TOKENï¼Ÿ**
A: `AUTH_TOKEN` ä¸ºè‡ªå·±è‡ªå®šä¹‰çš„api keyï¼Œåœ¨ç¯å¢ƒå˜é‡ä¸­é…ç½®ï¼Œéœ€è¦ä¿è¯å®¢æˆ·ç«¯ä¸æœåŠ¡ç«¯ä¸€è‡´ã€‚

**Q: ANTHROPIC_API_KEY å¦‚ä½•é…ç½®ï¼Ÿ**
A: é»˜è®¤ä½¿ç”¨ `AUTH_TOKEN` çš„å€¼ï¼Œä¸¤ä¸ª API ä½¿ç”¨ç›¸åŒçš„è®¤è¯å¯†é’¥ã€‚å¦‚éœ€åˆ†å¼€é…ç½®ï¼Œå¯å•ç‹¬è®¾ç½® `ANTHROPIC_API_KEY` ç¯å¢ƒå˜é‡ã€‚

**Q: åŒ¿åæ¨¡å¼æ˜¯ä»€ä¹ˆï¼Ÿ**
A: åŒ¿åæ¨¡å¼ä½¿ç”¨ä¸´æ—¶ tokenï¼Œé¿å…å¯¹è¯å†å²å…±äº«ï¼Œä¿æŠ¤éšç§ã€‚

**Q: Function Call å¦‚ä½•å·¥ä½œï¼Ÿ**
A: é€šè¿‡æ™ºèƒ½æç¤ºæ³¨å…¥å®ç°ï¼Œå°†å·¥å…·å®šä¹‰è½¬æ¢ä¸ºç³»ç»Ÿæç¤ºã€‚

**Q: æ”¯æŒå“ªäº› OpenAI åŠŸèƒ½ï¼Ÿ**
A: æ”¯æŒèŠå¤©å®Œæˆã€æ¨¡å‹åˆ—è¡¨ã€æµå¼å“åº”ã€å·¥å…·è°ƒç”¨ç­‰æ ¸å¿ƒåŠŸèƒ½ã€‚

**Q: æ”¯æŒ Anthropic API çš„å“ªäº›åŠŸèƒ½ï¼Ÿ**
A: æ”¯æŒ messages åˆ›å»ºã€æµå¼å“åº”ã€ç³»ç»Ÿæç¤ºç­‰æ ¸å¿ƒåŠŸèƒ½ã€‚

**Q: å¦‚ä½•è‡ªå®šä¹‰é…ç½®ï¼Ÿ**
A: é€šè¿‡ç¯å¢ƒå˜é‡é…ç½®ï¼Œæ¨èä½¿ç”¨ `.env` æ–‡ä»¶ã€‚

## ğŸ—ï¸ æŠ€æœ¯æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   OpenAI     â”‚     â”‚             â”‚     â”‚             â”‚
â”‚  Client      â”‚â”€â”€â”€â”€â–¶â”‚   Proxy     â”‚â”€â”€â”€â”€â–¶â”‚    Z.AI     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚   Server    â”‚     â”‚    API      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚             â”‚     â”‚             â”‚
â”‚  Anthropic    â”‚â”€â”€â”€â”€â–¶â”‚             â”‚     â”‚             â”‚
â”‚  Client      â”‚     â”‚             â”‚     â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- **FastAPI** - é«˜æ€§èƒ½ Web æ¡†æ¶
- **Pydantic** - æ•°æ®éªŒè¯å’Œåºåˆ—åŒ–
- **Uvicorn** - ASGI æœåŠ¡å™¨
- **Requests** - HTTP å®¢æˆ·ç«¯

## ğŸ¤ è´¡çŒ®æŒ‡å—

æˆ‘ä»¬æ¬¢è¿æ‰€æœ‰å½¢å¼çš„è´¡çŒ®ï¼
è¯·ç¡®ä¿ä»£ç ç¬¦åˆ PEP 8 è§„èŒƒï¼Œå¹¶æ›´æ–°ç›¸å…³æ–‡æ¡£ã€‚

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚

## âš ï¸ å…è´£å£°æ˜

- æœ¬é¡¹ç›®ä¸ Z.AI å®˜æ–¹æ— å…³
- ä½¿ç”¨å‰è¯·ç¡®ä¿éµå®ˆ Z.AI æœåŠ¡æ¡æ¬¾
- è¯·å‹¿ç”¨äºå•†ä¸šç”¨é€”æˆ–è¿åä½¿ç”¨æ¡æ¬¾çš„åœºæ™¯
- é¡¹ç›®ä»…ä¾›å­¦ä¹ å’Œç ”ç©¶ä½¿ç”¨

---

<div align="center">
Made with â¤ï¸ by the community
</div>